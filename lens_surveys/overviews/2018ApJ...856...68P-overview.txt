{"Action": "Scanned and processed all tables", "Inspection status": "Complete", "ADS link": "https://ui.adsabs.harvard.edu/abs/2018ApJ...856...68P", "Tables status": "Complete", "Publisher link via ADS gateway": "https://ui.adsabs.harvard.edu/link_gateway/2018ApJ...856...68P/PUB_HTML", "Paper text": "<!DOCTYPE html>\n<html lang=\"en\">\n\t<head>\n\t\t<meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\">\n\t\t\n\t\t\n<script type=\"text/javascript\">(window.NREUM||(NREUM={})).loader_config={licenseKey:\"b2bfaae1b6\",applicationID:\"723879338\"};window.NREUM||(NREUM={}),__nr_require=function(e,t,n){function r(n){if(!t[n]){var i=t[n]={exports:{}};e[n][0].call(i.exports,function(t){var i=e[n][1][t];return r(i||t)},i,i.exports)}return t[n].exports}if(\"function\"==typeof __nr_require)return __nr_require;for(var i=0;i<n.length;i++)r(n[i]);return r}({1:[function(e,t,n){function r(){}function i(e,t,n){return function(){return o(e,[u.now()].concat(c(arguments)),t?null:this,n),t?void 0:this}}var o=e(\"handle\"),a=e(6),c=e(7),f=e(\"ee\").get(\"tracer\"),u=e(\"loader\"),s=NREUM;\"undefined\"==typeof window.newrelic&&(newrelic=s);var d=[\"setPageViewName\",\"setCustomAttribute\",\"setErrorHandler\",\"finished\",\"addToTrace\",\"inlineHit\",\"addRelease\"],p=\"api-\",l=p+\"ixn-\";a(d,function(e,t){s[t]=i(p+t,!0,\"api\")}),s.addPageAction=i(p+\"addPageAction\",!0),s.setCurrentRouteName=i(p+\"routeName\",!0),t.exports=newrelic,s.interaction=function(){return(new r).get()};var m=r.prototype={createTracer:function(e,t){var n={},r=this,i=\"function\"==typeof t;return o(l+\"tracer\",[u.now(),e,n],r),function(){if(f.emit((i?\"\":\"no-\")+\"fn-start\",[u.now(),r,i],n),i)try{return t.apply(this,arguments)}catch(e){throw f.emit(\"fn-err\",[arguments,this,e],n),e}finally{f.emit(\"fn-end\",[u.now()],n)}}}};a(\"actionText,setName,setAttribute,save,ignore,onEnd,getContext,end,get\".split(\",\"),function(e,t){m[t]=i(l+t)}),newrelic.noticeError=function(e,t){\"string\"==typeof e&&(e=new Error(e)),o(\"err\",[e,u.now(),!1,t])}},{}],2:[function(e,t,n){function r(){return c.exists&&performance.now?Math.round(performance.now()):(o=Math.max((new Date).getTime(),o))-a}function i(){return o}var o=(new Date).getTime(),a=o,c=e(8);t.exports=r,t.exports.offset=a,t.exports.getLastTimestamp=i},{}],3:[function(e,t,n){function r(e,t){var n=e.getEntries();n.forEach(function(e){\"first-paint\"===e.name?d(\"timing\",[\"fp\",Math.floor(e.startTime)]):\"first-contentful-paint\"===e.name&&d(\"timing\",[\"fcp\",Math.floor(e.startTime)])})}function i(e,t){var n=e.getEntries();n.length>0&&d(\"lcp\",[n[n.length-1]])}function o(e){e.getEntries().forEach(function(e){e.hadRecentInput||d(\"cls\",[e])})}function a(e){if(e instanceof m&&!g){var t=Math.round(e.timeStamp),n={type:e.type};t<=p.now()?n.fid=p.now()-t:t>p.offset&&t<=Date.now()?(t-=p.offset,n.fid=p.now()-t):t=p.now(),g=!0,d(\"timing\",[\"fi\",t,n])}}function c(e){d(\"pageHide\",[p.now(),e])}if(!(\"init\"in NREUM&&\"page_view_timing\"in NREUM.init&&\"enabled\"in NREUM.init.page_view_timing&&NREUM.init.page_view_timing.enabled===!1)){var f,u,s,d=e(\"handle\"),p=e(\"loader\"),l=e(5),m=NREUM.o.EV;if(\"PerformanceObserver\"in window&&\"function\"==typeof window.PerformanceObserver){f=new PerformanceObserver(r);try{f.observe({entryTypes:[\"paint\"]})}catch(v){}u=new PerformanceObserver(i);try{u.observe({entryTypes:[\"largest-contentful-paint\"]})}catch(v){}s=new PerformanceObserver(o);try{s.observe({type:\"layout-shift\",buffered:!0})}catch(v){}}if(\"addEventListener\"in document){var g=!1,y=[\"click\",\"keydown\",\"mousedown\",\"pointerdown\",\"touchstart\"];y.forEach(function(e){document.addEventListener(e,a,!1)})}l(c)}},{}],4:[function(e,t,n){function r(e,t){if(!i)return!1;if(e!==i)return!1;if(!t)return!0;if(!o)return!1;for(var n=o.split(\".\"),r=t.split(\".\"),a=0;a<r.length;a++)if(r[a]!==n[a])return!1;return!0}var i=null,o=null,a=/Version\\/(\\S+)\\s+Safari/;if(navigator.userAgent){var c=navigator.userAgent,f=c.match(a);f&&c.indexOf(\"Chrome\")===-1&&c.indexOf(\"Chromium\")===-1&&(i=\"Safari\",o=f[1])}t.exports={agent:i,version:o,match:r}},{}],5:[function(e,t,n){function r(e){function t(){e(a&&document[a]?document[a]:document[i]?\"hidden\":\"visible\")}\"addEventListener\"in document&&o&&document.addEventListener(o,t,!1)}t.exports=r;var i,o,a;\"undefined\"!=typeof document.hidden?(i=\"hidden\",o=\"visibilitychange\",a=\"visibilityState\"):\"undefined\"!=typeof document.msHidden?(i=\"msHidden\",o=\"msvisibilitychange\"):\"undefined\"!=typeof document.webkitHidden&&(i=\"webkitHidden\",o=\"webkitvisibilitychange\",a=\"webkitVisibilityState\")},{}],6:[function(e,t,n){function r(e,t){var n=[],r=\"\",o=0;for(r in e)i.call(e,r)&&(n[o]=t(r,e[r]),o+=1);return n}var i=Object.prototype.hasOwnProperty;t.exports=r},{}],7:[function(e,t,n){function r(e,t,n){t||(t=0),\"undefined\"==typeof n&&(n=e?e.length:0);for(var r=-1,i=n-t||0,o=Array(i<0?0:i);++r<i;)o[r]=e[t+r];return o}t.exports=r},{}],8:[function(e,t,n){t.exports={exists:\"undefined\"!=typeof window.performance&&window.performance.timing&&\"undefined\"!=typeof window.performance.timing.navigationStart}},{}],ee:[function(e,t,n){function r(){}function i(e){function t(e){return e&&e instanceof r?e:e?f(e,c,o):o()}function n(n,r,i,o){if(!p.aborted||o){e&&e(n,r,i);for(var a=t(i),c=v(n),f=c.length,u=0;u<f;u++)c[u].apply(a,r);var d=s[w[n]];return d&&d.push([b,n,r,a]),a}}function l(e,t){h[e]=v(e).concat(t)}function m(e,t){var n=h[e];if(n)for(var r=0;r<n.length;r++)n[r]===t&&n.splice(r,1)}function v(e){return h[e]||[]}function g(e){return d[e]=d[e]||i(n)}function y(e,t){u(e,function(e,n){t=t||\"feature\",w[n]=t,t in s||(s[t]=[])})}var h={},w={},b={on:l,addEventListener:l,removeEventListener:m,emit:n,get:g,listeners:v,context:t,buffer:y,abort:a,aborted:!1};return b}function o(){return new r}function a(){(s.api||s.feature)&&(p.aborted=!0,s=p.backlog={})}var c=\"nr@context\",f=e(\"gos\"),u=e(6),s={},d={},p=t.exports=i();p.backlog=s},{}],gos:[function(e,t,n){function r(e,t,n){if(i.call(e,t))return e[t];var r=n();if(Object.defineProperty&&Object.keys)try{return Object.defineProperty(e,t,{value:r,writable:!0,enumerable:!1}),r}catch(o){}return e[t]=r,r}var i=Object.prototype.hasOwnProperty;t.exports=r},{}],handle:[function(e,t,n){function r(e,t,n,r){i.buffer([e],r),i.emit(e,t,n)}var i=e(\"ee\").get(\"handle\");t.exports=r,r.ee=i},{}],id:[function(e,t,n){function r(e){var t=typeof e;return!e||\"object\"!==t&&\"function\"!==t?-1:e===window?0:a(e,o,function(){return i++})}var i=1,o=\"nr@id\",a=e(\"gos\");t.exports=r},{}],loader:[function(e,t,n){function r(){if(!E++){var e=b.info=NREUM.info,t=p.getElementsByTagName(\"script\")[0];if(setTimeout(u.abort,3e4),!(e&&e.licenseKey&&e.applicationID&&t))return u.abort();f(h,function(t,n){e[t]||(e[t]=n)});var n=a();c(\"mark\",[\"onload\",n+b.offset],null,\"api\"),c(\"timing\",[\"load\",n]);var r=p.createElement(\"script\");r.src=\"https://\"+e.agent,t.parentNode.insertBefore(r,t)}}function i(){\"complete\"===p.readyState&&o()}function o(){c(\"mark\",[\"domContent\",a()+b.offset],null,\"api\")}var a=e(2),c=e(\"handle\"),f=e(6),u=e(\"ee\"),s=e(4),d=window,p=d.document,l=\"addEventListener\",m=\"attachEvent\",v=d.XMLHttpRequest,g=v&&v.prototype;NREUM.o={ST:setTimeout,SI:d.setImmediate,CT:clearTimeout,XHR:v,REQ:d.Request,EV:d.Event,PR:d.Promise,MO:d.MutationObserver};var y=\"\"+location,h={beacon:\"bam.nr-data.net\",errorBeacon:\"bam.nr-data.net\",agent:\"js-agent.newrelic.com/nr-1184.min.js\"},w=v&&g&&g[l]&&!/CriOS/.test(navigator.userAgent),b=t.exports={offset:a.getLastTimestamp(),now:a,origin:y,features:{},xhrWrappable:w,userAgent:s};e(1),e(3),p[l]?(p[l](\"DOMContentLoaded\",o,!1),d[l](\"load\",r,!1)):(p[m](\"onreadystatechange\",i),d[m](\"onload\",r)),c(\"mark\",[\"firstbyte\",a.getLastTimestamp()],null,\"api\");var E=0},{}],\"wrap-function\":[function(e,t,n){function r(e){return!(e&&e instanceof Function&&e.apply&&!e[a])}var i=e(\"ee\"),o=e(7),a=\"nr@original\",c=Object.prototype.hasOwnProperty,f=!1;t.exports=function(e,t){function n(e,t,n,i){function nrWrapper(){var r,a,c,f;try{a=this,r=o(arguments),c=\"function\"==typeof n?n(r,a):n||{}}catch(u){p([u,\"\",[r,a,i],c])}s(t+\"start\",[r,a,i],c);try{return f=e.apply(a,r)}catch(d){throw s(t+\"err\",[r,a,d],c),d}finally{s(t+\"end\",[r,a,f],c)}}return r(e)?e:(t||(t=\"\"),nrWrapper[a]=e,d(e,nrWrapper),nrWrapper)}function u(e,t,i,o){i||(i=\"\");var a,c,f,u=\"-\"===i.charAt(0);for(f=0;f<t.length;f++)c=t[f],a=e[c],r(a)||(e[c]=n(a,u?c+i:i,o,c))}function s(n,r,i){if(!f||t){var o=f;f=!0;try{e.emit(n,r,i,t)}catch(a){p([a,n,r,i])}f=o}}function d(e,t){if(Object.defineProperty&&Object.keys)try{var n=Object.keys(e);return n.forEach(function(n){Object.defineProperty(t,n,{get:function(){return e[n]},set:function(t){return e[n]=t,t}})}),t}catch(r){p([r])}for(var i in e)c.call(e,i)&&(t[i]=e[i]);return t}function p(t){try{e.emit(\"internal-error\",t)}catch(n){}}return e||(e=i),n.inPlace=u,n.flag=a,n}},{}]},{},[\"loader\"]);</script><script>\n\t\t\tfunction DeferJS(src) {\n\t\t\tfunction downloadJSAtOnload() {\n\t\t\tvar element = document.createElement(\"script\");\n\t\t\telement.src = src;\n\t\t\tdocument.body.appendChild(element);\n\t\t\t}\n\t\t\tif (window.addEventListener)\n\t\t\twindow.addEventListener(\"load\", downloadJSAtOnload, false);\n\t\t\telse if (window.attachEvent)\n\t\t\twindow.attachEvent(\"onload\", downloadJSAtOnload);\n\t\t\telse window.onload = downloadJSAtOnload;\n\t\t\t}\n\t\t</script>\n\t\t<script>\n\t\t\tDeferJS(\"https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js\");\n\t\t</script>\n\t\t<script>\n\t\t\tDeferJS(\"https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js\");\n\t\t</script>\n\t\t<script>\n                DeferJS(\"https://badge.dimensions.ai/badge.js\");\n\t\t\t</script>\n\t\t<script>\n                DeferJS(\"https://badge.dimensions.ai/badge.js\");\n\t\t\t</script>\n\t\t<script>\n                DeferJS(\"https://badge.dimensions.ai/badge.js\");\n\t\t\t</script>\n\t\t<script>\n\t\t\tvar _urconfig = { sid: \"defc3a7d-4b34-4b6f-ad1c-0716e0a05a65\", aip: 0, usePageProtocol: false };\n\t\t\t(function (d, s)\n\t\t\t\n\t\t\t{ var js = d.createElement(s), sc = d.getElementsByTagName(s)[0]; js.src = \"https://hit.uptrendsdata.com/rum.min.js\"; js.async = \"async\"; sc.parentNode.insertBefore(js, sc); }\n\t\t\t(document, \"script\"));\n\t\t</script>\n\t\t<meta charset=\"utf-8\">\n\t\t<meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n\t\t<meta name=\"robots\" content=\"noarchive\">\n\t\t<title>LensFlow: A Convolutional Neural Network in Search of Strong Gravitational Lenses - IOPscience</title>\n\t\t\t<meta name=\"citation_journal_title\" content=\"The Astrophysical Journal\"></meta><meta name=\"citation_journal_abbrev\" content=\"ApJ\"></meta><meta name=\"citation_issn\" content=\"0004-637X\"></meta><meta name=\"citation_publisher\" content=\"IOP Publishing\"></meta><meta name=\"citation_author\" content=\"Milad Pourrahmani\"></meta><meta name=\"citation_author\" content=\"Hooshang Nayyeri\"></meta><meta name=\"citation_author\" content=\"Asantha Cooray\"></meta><meta name=\"citation_title\" content=\"LensFlow: A Convolutional Neural Network in Search of Strong Gravitational Lenses\"></meta><meta name=\"citation_online_date\" content=\"2018-03-26\"></meta><meta name=\"citation_publication_date\" content=\"2018-03-26\"></meta><meta name=\"citation_volume\" content=\"856\"></meta><meta name=\"citation_issue\" content=\"1\"></meta><meta name=\"citation_firstpage\" content=\"68\"></meta><meta name=\"citation_doi\" content=\"10.3847/1538-4357/aaae6a\"></meta><meta name=\"citation_abstract_html_url\" content=\"https://iopscience.iop.org/article/10.3847/1538-4357/aaae6a/meta\"></meta><meta name=\"citation_pdf_url\" content=\"https://iopscience.iop.org/article/10.3847/1538-4357/aaae6a/pdf\"></meta><meta name=\"citation_xml_url\" content=\"https://iopscience.iop.org/article/10.3847/1538-4357/aaae6a/xml\"></meta><meta name=\"citation_fulltext_html_url\" content=\"https://iopscience.iop.org/article/10.3847/1538-4357/aaae6a\"></meta><meta name=\"citation_language\" content=\"en\"></meta><meta name=\"citation_reference\" content=\"Abadi M., Agarwal A., Barham P. et al 2016 arXiv:1603.04467\"/><meta name=\"citation_reference\" content=\"Agnello A., Lin H., Buckley-Geer L. et al 2017 MNRAS 472 4038\"/><meta name=\"citation_reference\" content=\"Alard C. 2006 arXiv:astro-ph/0606757\"/><meta name=\"citation_reference\" content=\"Atek H., Richard J., Kneib J.-P. et al 2015 ApJ 800 18\"/><meta name=\"citation_reference\" content=\"Blandford R. and Narayan R. 1992 ARA&amp;A 30 311\"/><meta name=\"citation_reference\" content=\"Bolton A. S., Burles S., Koopmans L. V., Treu T. and Moustakas L. A. 2006 ApJ 638 703\"/><meta name=\"citation_reference\" content=\"Broadhurst T., Ben&#237;tez N., Coe D. et al 2005 ApJ 621 53\"/><meta name=\"citation_reference\" content=\"Calanog J. A., Fu H., Cooray A. et al 2014 ApJ 797 138\"/><meta name=\"citation_reference\" content=\"Capak P., Aussel H., Ajiki M. et al 2007 ApJS 172 99\"/><meta name=\"citation_reference\" content=\"Coe D., Zitrin A., Carrasco M. et al 2012 ApJ 762 32\"/><meta name=\"citation_reference\" content=\"Eigenbrod A., Courbin F., Vuissoz C. et al 2005 A&amp;A 436 25\"/><meta name=\"citation_reference\" content=\"Faure C., Kneib J.-P., Covone G. et al 2008 ApJS 176 19\"/><meta name=\"citation_reference\" content=\"Fu H., Jullo E., Cooray A. et al 2012 ApJ 753 134\"/><meta name=\"citation_reference\" content=\"Gavazzi R., Marshall P. J., Treu T. and Sonnenfeld A. 2014 ApJ 785 144\"/><meta name=\"citation_reference\" content=\"Glorot X. and Bengio Y. 2010 Proc. Machine Learning Research 9, Proc. 13th Int. Conf. Artificial Intelligence and Statistics ed Y. W. Teh and M. Titterington (Chia Laguna Resort, Sardinia: PMLR) 249\"/><meta name=\"citation_reference\" content=\"Goobar A., Amanullah R., Kulkarni S. R. et al 2017 Sci 356 291\"/><meta name=\"citation_reference\" content=\"Grogin N. A., Kocevski D. D., Faber S. et al 2011 ApJS 197 35\"/><meta name=\"citation_reference\" content=\"He K., Zhang X., Ren S. and Sun J. 2016 Proc. IEEE Conf. Computer Vision and Pattern Recognition ed R. Bajcsy (Washington, DC: IEEE) 770\"/><meta name=\"citation_reference\" content=\"Heymans C., Van Waerbeke L., Miller L. et al 2012 MNRAS 427 146\"/><meta name=\"citation_reference\" content=\"Jacobs C., Glazebrook K., Collett T., More A. and McCarthy C. 2017 MNRAS 471 167\"/><meta name=\"citation_reference\" content=\"Jullo E., Kneib J.-P., Limousin M. et al 2007 NJPh 9 447\"/><meta name=\"citation_reference\" content=\"Kaiser N. and Squires G. 1993 ApJ 404 441\"/><meta name=\"citation_reference\" content=\"Kingma D. P. and Ba J. 2014 arXiv:1412.6980\"/><meta name=\"citation_reference\" content=\"Koekemoer A. M., Faber S., Ferguson H. C. et al 2011 ApJS 197 36\"/><meta name=\"citation_reference\" content=\"Komatsu E., Dunkley J., Nolta M. et al 2009 ApJS 180 330\"/><meta name=\"citation_reference\" content=\"Krizhevsky A. and Hinton G. 2009 Learning Multiple Layers of Features from Tiny Images (State College, PA: Citeseer)\"/><meta name=\"citation_reference\" content=\"Krizhevsky A., Sutskever I. and Hinton G. E. 2012 Proc. Advances Neural Information Processing Systems 25 Conf. ed F. Pereira et al (La Jolla, CA: NIPS Foundation) https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks\"/><meta name=\"citation_reference\" content=\"Lanusse F., Ma Q., Li N. et al 2018 MNRAS 473 3895\"/><meta name=\"citation_reference\" content=\"Lenzen F., Schindler S. and Scherzer O. 2004 A&amp;A 416 391\"/><meta name=\"citation_reference\" content=\"Lotz J., Koekemoer A., Coe D. et al 2017 ApJ 837 97\"/><meta name=\"citation_reference\" content=\"Marshall P. J., Lintott C. J. and Fletcher L. N. 2015 ARA&amp;A 53 247\"/><meta name=\"citation_reference\" content=\"More A., Cabanac R., More S. et al 2012 ApJ 749 38\"/><meta name=\"citation_reference\" content=\"More A., Suyu S. H., Oguri M., More S. and Lee C.-H. 2017 ApJL 835 L25\"/><meta name=\"citation_reference\" content=\"More A., Verma A., Marshall P. J. et al 2016 MNRAS 455 1191\"/><meta name=\"citation_reference\" content=\"Nayyeri H., Cooray A., Jullo E. et al 2017 ApJ 844 82\"/><meta name=\"citation_reference\" content=\"Nayyeri H., Keele M., Cooray A. et al 2016 ApJ 823 17\"/><meta name=\"citation_reference\" content=\"Nielsen M. 2016 Neural Networks and Deep Learning http://neuralnetworksanddeeplearning.com/chap3.html\"/><meta name=\"citation_reference\" content=\"Oesch P., Bouwens R., Illingworth G. et al 2015 ApJ 808 104\"/><meta name=\"citation_reference\" content=\"Oke J. and Gunn J. 1983 ApJ 266 713\"/><meta name=\"citation_reference\" content=\"Pedersen M. E. H. 2016 Hvass-Labs https://github.com/Hvass-Labs/TensorFlow-Tutorials\"/><meta name=\"citation_reference\" content=\"Peng C. Y., Impey C. D., Rix H.-W. et al 2006 ApJ 649 616\"/><meta name=\"citation_reference\" content=\"Petrillo C. E., Tortora C., Chatterjee S. et al 2017 MNRAS 472 1129\"/><meta name=\"citation_reference\" content=\"Postman M., Coe D., Ben&#237;tez N. et al 2012 ApJS 199 25\"/><meta name=\"citation_reference\" content=\"Pourrahmani M., Nayyeri H. and Cooray A. 2018 LensFlow Zenodo, doi:10.5281/zenodo.1163024\"/><meta name=\"citation_reference\" content=\"Refsdal S. and Bondi H. 1964 MNRAS 128 295\"/><meta name=\"citation_reference\" content=\"Rodney S. A., Strolger L.-G., Kelly P. L. et al 2016 ApJ 820 50\"/><meta name=\"citation_reference\" content=\"Scoville N., Abraham R., Aussel H. et al 2007 ApJS 172 38\"/><meta name=\"citation_reference\" content=\"Spilker J. S., Marrone D. P., Aravena M. et al 2016 ApJ 826 112\"/><meta name=\"citation_reference\" content=\"Suyu S., Auger M., Hilbert S. et al 2013 ApJ 766 70\"/><meta name=\"citation_reference\" content=\"Suyu S., Treu T., Hilbert S. et al 2014 ApJL 788 L35\"/><meta name=\"citation_reference\" content=\"Tegmark M., Strauss M. A., Blanton M. R. et al 2004 PhRvD 69 103501\"/><meta name=\"citation_reference\" content=\"Timmons N., Cooray A., Riechers D. A. et al 2016 ApJ 829 21\"/><meta name=\"citation_reference\" content=\"Treu T. 2010 ARA&amp;A 48 87\"/><meta name=\"citation_reference\" content=\"Treu T. and Marshall P. J. 2016 A&amp;ARv 24 11\"/><meta name=\"citation_reference\" content=\"Treu T., Schmidt K., Brammer G. et al 2015 ApJ 812 114\"/><meta name=\"citation_reference\" content=\"Velander M., van Uitert E., Hoekstra H. et al 2014 MNRAS 437 2111\"/><meta name=\"citation_reference\" content=\"Wardlow J. L., Cooray A., De Bernardis F. et al 2012 ApJ 762 59\"/><meta name=\"citation_reference\" content=\"Weinberg D. H., Mortonson M. J., Eisenstein D. J. et al 2013 PhR 530 87\"/><meta name=\"citation_reference\" content=\"Wilson D., Cooray A., Nayyeri H. et al 2017 ApJ 848 30\"/><meta name=\"dc.publisher\" content=\"IOP Publishing\" lang=\"en\"></meta><meta name=\"dc.date\" content=\"2018 March 20\" scheme=\"W3CDTF\"></meta><meta name=\"dc.type\" content=\"Text\" scheme=\"DCMIType\"></meta><meta name=\"dc.format\" content=\"text/html\" scheme=\"IMT\"></meta><meta name=\"dc.identifier\" content=\"doi:10.3847/1538-4357/aaae6a\"></meta><meta name=\"dc.language\" content=\"en\"></meta><meta name=\"dc.creator\" content=\"Milad Pourrahmani\"></meta><meta name=\"dc.creator\" content=\"Hooshang Nayyeri\"></meta><meta name=\"dc.creator\" content=\"Asantha Cooray\"></meta><meta name=\"viewport\" content=\"width=device-width, initial-scale=1, minimum-scale=1.0\">\n\t\t<!-- Note Gridset ref 35089 -->\n<link rel=\"stylesheet\" href=\"https://static.iopscience.com/2.44.0/css/critical-styles.min.css\" type=\"text/css\" />\n<link rel=\"stylesheet\" href=\"https://static.iopscience.com/2.44.0/css/all-styles.min.css\" media=\"print\" onload=\"this.media='all'\">\n\n<!--[if lte IE 10]>\n<link rel=\"stylesheet\" href=\"https://static.iopscience.com/2.44.0/css/gridset-ie-lte8.css\" type=\"text/css\" />\n<![endif]-->\n<!-- Google Tag Manager -->\n<script type=\"text/javascript\">\n        (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push(\n        {'gtm.start': new Date().getTime(),event:'gtm.js'}\n        );var f=d.getElementsByTagName(s)[0],\n        j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=\n        'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);\n        })(window,document,'script','dataLayer','GTM-M73Z4W');\n    </script>\n<!-- End Google Tag Manager --><!-- Google Scholar Universal Casa -->\n    <script src=\"https://scholar.google.com/scholar_js/casa.js\" async></script>\n    <!-- End Google Scholar Universal Casa -->\n<script>\n\t\t/*  Cutting the mustard - http://responsivenews.co.uk/post/18948466399/cutting-the-mustard */\n\t\t\n\t\t/* Below is the original if statement, from the link above. I have amended it to turn of JS on all IE browsers less than 10.\n\t\tThis is due to a function in the iop.jquery.toolbar line 35/36. Uses .remove which is not native js supported in IE9 or lower */\n\t\t/*if('querySelector' in document\n\t\t&& 'localStorage' in window\n\t\t&& 'addEventListener' in window)*/\n\t\t\n\t\t/* This is the updated selector, taken from: https://justmarkup.com/log/2015/02/26/cut-the-mustard-revisited/ */\n\t\tif('visibilityState' in document) {\n\t\t\n\t\t/*! loadJS: load a JS. We are loading this command straight away, before the body loads, so that IF a user has JS enabled, their show hide panels will automatically be closed. */\n\t\t/* If this isn't here, then these panels appear open while the page is loading, then when the js loads at the bottom of the page, they are shut. So the users sees open content, then hidden after a second or 2 when the js is loaded. Not nice */\n\t\tdocument.write(\"<style>.reveal-content{display:none;}.search-res-filter .reveal-content{display:block;}</style>\");\n\t\t}\n\t\t</script>\n\t\t<script>var __uzdbm_1 = \"3c1c769b-cc1f-4878-8c52-d7f85411c6e4\";var __uzdbm_2 = \"NzEwY2ZmNjMtODQyNy00MjYzLWFjOTAtMTE3N2VkNzkxNTgxJDE1NS4xMDEuMjYuNjY=\";</script> <script>(function(w, d, e, u, c, g, a, b){ w[\"SSJSConnectorObj\"] = {ss_cid : c, domain_info: \"auto\"}; a = d.createElement(e); a.async = true; a.src = u; b = d.getElementsByTagName(e)[0]; b.parentNode.insertBefore(a, b); })(window,document,\"script\",\"https://cdn.perfdrive.com/aperture/aperture.js\",\"a1c3\",\"ssConf\");</script></head>\n\t<body itemscope itemtype=\"http://schema.org/Organization\" class=\"issn-0004-637X\">\n    <a id=\"back-to-top-target\" tabindex=\"-1\"></a>\n    <!-- Google Tag Manager (noscript) -->\n<noscript><iframe src=\"https://www.googletagmanager.com/ns.html?id=GTM-M73Z4W\"\n    height=\"0\" width=\"0\" style=\"display:none;visibility:hidden\"></iframe></noscript>\n<!-- End Google Tag Manager (noscript) --><div class=\"cookies-banner-wrap\" id=\"cookieBanner\">\n    <div class=\"cookies-banner cf\">\n        This site uses cookies. By continuing to use this site you agree to our use of cookies. To find out more, see our\n        <a href=\"http://ioppublishing.org/privacyPolicy\">Privacy and Cookies</a> policy.\n        <div class=\"cookies-banner-close\">\n            <span role=\"button\" tabindex=\"0\" class=\"icon-close large\"><span class=\"offscreen-hidden\">Close this notification</span></span>\n        </div>\n    </div>\n</div><!-- Start Production toolbar -->\n<!-- End Production toolbar --><!-- Start Downtime Banner -->\n<!-- End Downtime Banner --><!-- Header tile starts -->\n<header role=\"banner\" data-nav-group>\n\t<div class=\"accessibility\" style=\"display: none;\">\n\t    <p><strong>Accessibility Links</strong></p>\n\t    <ul>\n\t        <li><a href=\"#page-content\">Skip to content</a></li>\n\t        <li><a href=\"/search#contentCol\">Skip to search IOPscience</a></li>\n\t        <li><a href=\"/journals#contentCol\">Skip to Journals list</a></li>\n\t        <li><a href=\"/page/accessibility#contentCol\">Accessibility help</a></li>\n\t    </ul>\n\t</div>\n    <div class=\"wrapper dgh-showgrid tgh-showgrid cf\" name=\"contentCol\">\n\n        <div id=\"mobile-header\" class=\"ta-hide da-hide wd-mobile-nav\">\n            <a title=\"Menu\" href=\"#sidr-main\" id=\"simple-menu\" class=\"icon-menu\"></a>\n        </div>\n\n        <a href=\"/\" itemprop=\"url\" class=\"header-logo wd-header-graphic\">\n            <meta itemprop=\"name\" content=\"IOPscience\">\n            <svg height=\"15\" width=\"100\">\n                <image xlink:href=\"https://static.iopscience.com/2.44.0/img/iops-logo.svg\" src=\"https://static.iopscience.com/2.44.0/img/iops-logo.png\" height=\"15\" width=\"100\" border=\"0\" itemprop=\"logo\" />\n            </svg>\n            <span class=\"offscreen-hidden\">IOP Science home</span>\n        </a>\n\n        <section role=\"region\" aria-label=\"Accessibility links\">\n            <div class=\"accessibility-skip-links\">\n                <ul>\n                    <li>\n                        <a class=\"btn btn-default\" href=\"#skip-to-content-link-target\">Skip to content</a>\n                    </li>\n                    <li>\n                        <a class=\"btn btn-default\" id=\"accessibility-help\" href=\"/page/accessibility#skip-to-content-link-target\">Accessibility Help</a>\n                    </li>\n                </ul>\n            </div>\n        </section>\n\n        <nav role=\"navigation\" id=\"sidr\" class=\"m-hide wd-main-nav\" aria-label=\"Site\">\n            <button class=\"nav-top-link-drop-down nav-item nav-search\" data-nav-trigger=\"articlelookup\" aria-expanded=\"false\" aria-controls=\"nav-dropdown-articlelookup\">\n                <img src=\"https://static.iopscience.com/2.44.0/img/icon-search.svg\" alt=\"\">\n                <span class=\"offscreen-hidden\">Search</span>\n            </button>\n            <div class=\"nav-journals nav-item wd-nav-journal\">\n                <a class=\"nav-top-link-drop-down\" href=\"/journals\" data-nav-trigger=\"journals\">Journals<span class=\"icon-arrow-down\"></span></a>\n\n                <div class=\"nav-drop-down wd-nav-journal-dd\" data-nav-item=\"journals\">\n                    <a href=\"/journals\">\n                        Journals list\n                        <div class=\"m-hide\">Browse more than 100 science journal titles</div>\n                    </a>\n\n                    <a href=\"/page/subjects\">\n                        Subject collections\n                        <div class=\"m-hide\">Read the very best research published in IOP journals</div>\n                    </a>\n\n                    <a href=\"/journals?type=partner#js-tab-pubpart\">\n                        Publishing partners\n                        <div class=\"m-hide\">Partner organisations and publications</div>\n                    </a>\n\n                    <a href=\"/info/page/openaccess\">\n                        Open access\n                        <div class=\"m-hide\">IOP Publishing open access policy guide</div>\n                    </a>\n\n                    <a href=\"http://conferenceseries.iop.org/\">\n                        IOP Conference Series\n                        <div class=\"m-hide\">Read open access proceedings from science conferences worldwide</div>\n                    </a>\n                </div>\n            </div>\n\n            <div class=\"nav-books nav-item wd-nav-books\">\n                <a href=\"/books\" class=\"nav-top-link\">Books</a>\n            </div>\n\n            <div class=\"nav-publishing-support nav-item wd-publishing-support\">\n                    <a href=\"https://publishingsupport.iopscience.iop.org\" class=\"nav-top-link\">Publishing Support</a>\n                </div>\n            <!-- Header Login tile starts here -->\n           <div class=\"nav-login nav-item wd-nav-login\">\n<a class=\"nav-top-link-drop-down\" id=\"login-drop-down-user\" href=\"https://myiopscience.iop.org/signin?origin=a0&return=https%3A%2F%2Fiopscience.iop.org%2Farticle%2F10.3847%2F1538-4357%2Faaae6a\" data-nav-trigger=\"login\"><span class=\"nav-top-username\">Login</span><span class=\"icon-arrow-down\"></span></a>\n<div class=\"nav-drop-down wd-nav-login-dd\" data-nav-item=\"login\">\n\n    <div class='CMS-content'><p id=\"wd-login-dropdown__heading\" class=\"replica-h3 mt-0\">Reset your password</p>\n            <p id=\"wd-login-dropdown__body\" class=\"small\">If you have a user account, you will need to reset your password the next time you login. You will only need to do this once. <a href=\"/page/improvement-to-the-iopscience-login-process\" aria-label=\"Find out more about the new I O P science login\">Find out more</a>.</p></div><a class=\"btn btn-default mt-05 mb-05 d-b\" href=\"https://myiopscience.iop.org/signin?origin=a0&return=https%3A%2F%2Fiopscience.iop.org%2Farticle%2F10.3847%2F1538-4357%2Faaae6a\" id=\"wd-login-link\">IOPscience login / Sign Up</a>\n        <div class=\"bdt-1\">\n\n        <div class='CMS-content'><div class=\"eyebrow eyebrow--small eyebrow--marg-top-05\"><span class=\"red\">Please note:</span></div>\n<p id=\"wd-login-dropdown__athens-info\" class=\"small mb-0\">You do not need to reset your password if you login via Athens or an Institutional login.</p></div><a class=\"btn btn-primary mt-05 mb-05 d-b\" href=\"https://ticket.iop.org/inst_login?return=https%3A%2F%2Fiopscience.iop.org%2Farticle%2F10.3847%2F1538-4357%2Faaae6a\">Athens / Institution login</a>\n    </div>\n</div>\n</div><!-- Header Login tile ends here -->\n        </nav>\n    </div>\n\n    <div class=\"art-lookup-panel m-hide nav-drop-down\" data-nav-item=\"articlelookup\">\n    <div class=\"wrapper wrapper--search cf\">\n        <a title=\"Close\" class=\"close-icon art-lookup__close\" tabindex=\"0\" role=\"button\" aria-describedby=\"close-search-description\">\n            <span class=\"icon-close\"></span>\n        </a>\n        <p id=\"close-search-description\" class=\"offscreen-hidden\">Click here to close this panel.</p>\n\n        <div id=\"search\" class=\"wd-header-search art-lookup__search\">\n    <form accept-charset=\"utf-8,iso-8859-1\" class=\"primary-search\" method=\"get\" action=\"/nsearch\" role=\"search\">\n        <fieldset aria-labelledby=\"search-legend\">\n            <div class=\"art-lookup__fields-wrapper\">\n                <div id=\"search-legend\" class=\"offscreen-hidden\">Primary search</div>\n                <label for=\"quickSearch\">Search all IOPscience content</label>\n\n            <input type=\"text\" x-webkit-speech=\"\" name=\"terms\" id=\"quickSearch\" class=\"art-lookup__field--grow\"\n                   placeholder=\"Search all IOPscience content\" value=\"\"/>\n            <input type=\"submit\" x-webkit-speech=\"\" value=\"Search\" class=\"btn btn-default hdr-search-btn bd-0 art-lookup__submit\">\n\n            </div>\n        </fieldset>\n    </form>\n</div>\n<div id=\"wd-content-finder\" class=\"art-lookup__content-finder\">\n            <form accept-charset=\"utf-8,iso-8859-1\" method=\"get\" action=\"/findcontent\" name=\"contentFinderForm\"\n      id=\"wd-find-art-form\" class=\"cf find-article-issue-display\" autocomplete=\"OFF\">\n    <fieldset aria-labelledby=\"content-finder-legend\">\n        <div id=\"content-finder-legend\" class=\"eyebrow eyebrow--blue\">Article Lookup</div>\n        <div class=\"art-lookup__fields-wrapper\">\n\n            <label for=\"CF_JOURNAL\" class=\"offscreen-hidden\">Select journal (required)</label>\n            <select name=\"CF_JOURNAL\"\n        id=\"CF_JOURNAL\"class=\"find-article-select art-lookup__content-finder-field art-lookup__field--grow art-lookup__content-finder-field--first\" >\n    <option value=\"none\"  hidden disabled>Select journal (required)</option>\n<option value=\"2053-1583\"   >2D Mater. (2014 - present)</option>\n<option value=\"1004-423X\"   >Acta Phys. Sin. (Overseas Edn) (1992 - 1999)</option>\n<option value=\"2043-6262\"   >Adv. Nat. Sci: Nanosci. Nanotechnol. (2010 - present)</option>\n<option value=\"1882-0786\"   >Appl. Phys. Express (2008 - present)</option>\n<option value=\"1758-5090\"   >Biofabrication (2009 - present)</option>\n<option value=\"1748-3190\"   >Bioinspir. Biomim. (2006 - present)</option>\n<option value=\"1748-605X\"   >Biomed. Mater. (2006 - present)</option>\n<option value=\"2057-1976\"   >Biomed. Phys. Eng. Express (2015 - present)</option>\n<option value=\"0508-3443\"   >Br. J. Appl. Phys. (1950 - 1967)</option>\n<option value=\"1009-9271\"   >Chin. J. Astron. Astrophys. (2001 - 2008)</option>\n<option value=\"1003-7713\"   >Chin. J. Chem. Phys. (1987 - 2007)</option>\n<option value=\"1674-0068\"   >Chin. J. Chem. Phys. (2008 - 2012)</option>\n<option value=\"1009-1963\"   >Chinese Phys. (2000 - 2007)</option>\n<option value=\"1674-1056\"   >Chinese Phys. B (2008 - present)</option>\n<option value=\"1674-1137\"   >Chinese Phys. C (2008 - present)</option>\n<option value=\"0256-307X\"   >Chinese Phys. Lett. (1984 - present)</option>\n<option value=\"0264-9381\"   >Class. Quantum Grav. (1984 - present)</option>\n<option value=\"0143-0815\"   >Clin. Phys. Physiol. Meas. (1980 - 1992)</option>\n<option value=\"0253-6102\"   >Commun. Theor. Phys. (1982 - present)</option>\n<option value=\"1749-4699\"   >Comput. Sci. Disc. (2008 - 2015)</option>\n<option value=\"2057-1739\"   >Converg. Sci. Phys. Oncol. (2015 - 2018)</option>\n<option value=\"0967-1846\"   >Distrib. Syst. Engng. (1993 - 1999)</option>\n<option value=\"2162-8734\"   >ECS Electrochem. Lett. (2012 - 2015)</option>\n<option value=\"2162-8777\"   >ECS J. Solid State Sci. Technol. (2012 - present)</option>\n<option value=\"2162-8750\"   >ECS Solid State Lett. (2012 - 2015)</option>\n<option value=\"1938-5862\"   >ECS Trans. (2005 - present)</option>\n<option value=\"0295-5075\"   >EPL (1986 - present)</option>\n<option value=\"1944-8783\"   >Electrochem. Soc. Interface (1992 - present)</option>\n<option value=\"1944-8775\"   >Electrochem. Solid-State Lett. (1998 - 2012)</option>\n<option value=\"2516-1075\"   >Electron. Struct. (2019 - present)</option>\n<option value=\"2631-8695\"   >Eng. Res. Express (2019 - present)</option>\n<option value=\"2515-7620\"   >Environ. Res. Commun. (2018 - present)</option>\n<option value=\"1748-9326\"   >Environ. Res. Lett. (2006 - present)</option>\n<option value=\"2634-4505\"   >Environ. Res.: Infrastruct. Sustain. (2021 - present)</option>\n<option value=\"0143-0807\"   >Eur. J. Phys. (1980 - present)</option>\n<option value=\"2058-8585\"   >Flex. Print. Electron. (2015 - present)</option>\n<option value=\"1873-7005\"   >Fluid Dyn. Res. (1986 - present)</option>\n<option value=\"2631-6331\"   >Funct. Compos. Struct. (2018 - present)</option>\n<option value=\"1755-1315\"   >IOP Conf. Ser.: Earth Environ. Sci. (2008 - present)</option>\n<option value=\"1757-899X\"   >IOP Conf. Ser.: Mater. Sci. Eng. (2009 - present)</option>\n<option value=\"2633-1357\"   >IOP SciNotes (2020 - present)</option>\n<option value=\"2631-7990\"   >Int. J. Extrem. Manuf. (2019 - present)</option>\n<option value=\"0266-5611\"   >Inverse Problems (1985 - present)</option>\n<option value=\"1064-5632\"   >Izv. Math. (1995 - present)</option>\n<option value=\"1752-7163\"   >J. Breath Res. (2007 - present)</option>\n<option value=\"1475-7516\"   >J. Cosmol. Astropart. Phys. (2003 - present)</option>\n<option value=\"1945-7111\"   >J. Electrochem. Soc. (1902 - present)</option>\n<option value=\"1742-2140\"   >J. Geophys. Eng. (2004 - 2018)</option>\n<option value=\"1126-6708\"   >J. High Energy Phys. (1997 - 2009)</option>\n<option value=\"1748-0221\"   >J. Inst. (2006 - present)</option>\n<option value=\"0960-1317\"   >J. Micromech. Microeng. (1991 - present)</option>\n<option value=\"1741-2552\"   >J. Neural Eng. (2004 - present)</option>\n<option value=\"0368-3281\"   >J. Nucl. Energy, Part C Plasma Phys. (1959 - 1966)</option>\n<option value=\"0150-536X\"   >J. Opt. (1977 - 1998)</option>\n<option value=\"2040-8986\"   >J. Opt. (2010 - present)</option>\n<option value=\"1464-4258\"   >J. Opt. A: Pure Appl. Opt. (1999 - 2009)</option>\n<option value=\"1464-4266\"   >J. Opt. B: Quantum Semiclass. Opt. (1999 - 2005)</option>\n<option value=\"0022-3689\"   >J. Phys. A: Gen. Phys. (1968 - 1972)</option>\n<option value=\"0305-4470\"   >J. Phys. A: Math. Gen. (1975 - 2006)</option>\n<option value=\"0301-0015\"   >J. Phys. A: Math. Nucl. Gen. (1973 - 1974)</option>\n<option value=\"1751-8121\"   >J. Phys. A: Math. Theor. (2007 - present)</option>\n<option value=\"0953-4075\"   >J. Phys. B: At. Mol. Opt. Phys. (1988 - present)</option>\n<option value=\"0022-3700\"   >J. Phys. B: At. Mol. Phys. (1968 - 1987)</option>\n<option value=\"0022-3719\"   >J. Phys. C: Solid State Phys. (1968 - 1988)</option>\n<option value=\"2399-6528\"   >J. Phys. Commun. (2017 - present)</option>\n<option value=\"2632-072X\"   >J. Phys. Complex. (2019 - present)</option>\n<option value=\"0022-3727\"   >J. Phys. D: Appl. Phys. (1968 - present)</option>\n<option value=\"0022-3735\"   >J. Phys. E: Sci. Instrum. (1968 - 1989)</option>\n<option value=\"2515-7655\"   >J. Phys. Energy (2018 - present)</option>\n<option value=\"0305-4608\"   >J. Phys. F: Met. Phys. (1971 - 1988)</option>\n<option value=\"0954-3899\"   >J. Phys. G: Nucl. Part. Phys. (1989 - present)</option>\n<option value=\"0305-4616\"   >J. Phys. G: Nucl. Phys. (1975 - 1988)</option>\n<option value=\"2515-7639\"   >J. Phys. Mater. (2018 - present)</option>\n<option value=\"2515-7647\"   >J. Phys. Photonics (2018 - present)</option>\n<option value=\"0953-8984\"   >J. Phys.: Condens. Matter (1989 - present)</option>\n<option value=\"1742-6596\"   >J. Phys.: Conf. Ser. (2004 - present)</option>\n<option value=\"0952-4746\"   >J. Radiol. Prot. (1988 - present)</option>\n<option value=\"0950-7671\"   >J. Sci. Instrum. (1923 - 1967)</option>\n<option value=\"1674-4926\"   >J. Semicond. (2009 - present)</option>\n<option value=\"0260-2814\"   >J. Soc. Radiol. Prot. (1981 - 1987)</option>\n<option value=\"1742-5468\"   >J. Stat. Mech. (2004 - present)</option>\n<option value=\"1347-4065\"   >Jpn. J. Appl. Phys. (1962 - present)</option>\n<option value=\"1555-6611\"   >Laser Phys. (2013 - present)</option>\n<option value=\"1612-202X\"   >Laser Phys. Lett. (2004 - present)</option>\n<option value=\"2632-2153\"   >Mach. Learn.: Sci. Technol. (2019 - present)</option>\n<option value=\"2633-4356\"   >Mater. Quantum Technol. (2020 - present)</option>\n<option value=\"2053-1591\"   >Mater. Res. Express (2014 - present)</option>\n<option value=\"0025-5726\"   >Math. USSR Izv. (1967 - 1992)</option>\n<option value=\"0025-5734\"   >Math. USSR Sb. (1967 - 1993)</option>\n<option value=\"0957-0233\"   >Meas. Sci. Technol. (1990 - present)</option>\n<option value=\"2151-2043\"   >Meet. Abstr. (2002 - present)</option>\n<option value=\"2050-6120\"   >Methods Appl. Fluoresc. (2013 - present)</option>\n<option value=\"0026-1394\"   >Metrologia (1965 - present)</option>\n<option value=\"0965-0393\"   >Modelling Simul. Mater. Sci. Eng. (1992 - present)</option>\n<option value=\"2399-7532\"   >Multifunct. Mater. (2018 - present)</option>\n<option value=\"2632-959X\"   >Nano Express (2020 - present)</option>\n<option value=\"2399-1984\"   >Nano Futures (2017 - present)</option>\n<option value=\"0957-4484\"   >Nanotechnology (1990 - present)</option>\n<option value=\"2634-4386\"   >Neuromorph. Comput. Eng. (2021 - present)</option>\n<option value=\"1367-2630\"   >New J. Phys. (1998 - present)</option>\n<option value=\"0951-7715\"   >Nonlinearity (1988 - present)</option>\n<option value=\"0335-7368\"   >Nouvelle Revue d'Optique (1973 - 1976)</option>\n<option value=\"0029-4780\"   >Nouvelle Revue d'Optique Appliqu\u00e9e (1970 - 1972)</option>\n<option value=\"0029-5515\"   >Nucl. Fusion (1960 - present)</option>\n<option value=\"1538-3873\"   >PASP (1889 - present)</option>\n<option value=\"1478-3975\"   >Phys. Biol. (2004 - present)</option>\n<option value=\"0031-9112\"   >Phys. Bull. (1950 - 1988)</option>\n<option value=\"0031-9120\"   >Phys. Educ. (1966 - present)</option>\n<option value=\"0031-9155\"   >Phys. Med. Biol. (1956 - present)</option>\n<option value=\"1402-4896\"   >Phys. Scr. (1970 - present)</option>\n<option value=\"2058-7058\"   >Phys. World (1988 - present)</option>\n<option value=\"1063-7869\"   >Phys.-Usp. (1993 - present)</option>\n<option value=\"0305-4624\"   >Physics in Technology (1973 - 1988)</option>\n<option value=\"0967-3334\"   >Physiol. Meas. (1993 - present)</option>\n<option value=\"0032-1028\"   >Plasma Phys. (1967 - 1983)</option>\n<option value=\"0741-3335\"   >Plasma Phys. Control. Fusion (1984 - present)</option>\n<option value=\"2516-1067\"   >Plasma Res. Express (2018 - present)</option>\n<option value=\"1009-0630\"   >Plasma Sci. Technol. (1999 - present)</option>\n<option value=\"0963-0252\"   >Plasma Sources Sci. Technol. (1992 - present)</option>\n<option value=\"2576-1579\"   >Proc. - Electrochem. Soc. (1967 - 2005)</option>\n<option value=\"0959-5309\"   >Proc. Phys. Soc. (1926 - 1948)</option>\n<option value=\"0370-1328\"   >Proc. Phys. Soc. (1958 - 1967)</option>\n<option value=\"0370-1298\"   >Proc. Phys. Soc. A (1949 - 1957)</option>\n<option value=\"0370-1301\"   >Proc. Phys. Soc. B (1949 - 1957)</option>\n<option value=\"1478-7814\"   >Proc. Phys. Soc. London (1874 - 1925)</option>\n<option value=\"2516-1091\"   >Prog. Biomed. Eng. (2018 - present)</option>\n<option value=\"2516-1083\"   >Prog. Energy (2018 - present)</option>\n<option value=\"0963-9659\"   >Pure Appl. Opt. (1992 - 1998)</option>\n<option value=\"1063-7818\"   >Quantum Electron. (1993 - present)</option>\n<option value=\"0954-8998\"   >Quantum Opt. (1989 - 1994)</option>\n<option value=\"2058-9565\"   >Quantum Sci. Technol. (2015 - present)</option>\n<option value=\"1355-5111\"   >Quantum Semiclass. Opt. (1995 - 1998)</option>\n<option value=\"0034-4885\"   >Rep. Prog. Phys. (1934 - present)</option>\n<option value=\"1674-4527\"   >Res. Astron. Astrophys. (2009 - present)</option>\n<option value=\"2515-5172\"   >Research Notes of the AAS (2017 - present)</option>\n<option value=\"0034-6683\"   >Review of Physics in Technology (1970 - 1972)</option>\n<option value=\"1468-4802\"   >Russ. Acad. Sci. Sb. Math. (1993 - 1995)</option>\n<option value=\"0036-021X\"   >Russ. Chem. Rev. (1960 - present)</option>\n<option value=\"0036-0279\"   >Russ. Math. Surv. (1960 - present)</option>\n<option value=\"1468-4810\"   >Russian Acad. Sci. Izv. Math. (1993 - 1995)</option>\n<option value=\"1064-5616\"   >Sb. Math. (1995 - present)</option>\n<option value=\"1468-6996\"   >Sci. Technol. Adv. Mater. (2000 - 2015)</option>\n<option value=\"0268-1242\"   >Semicond. Sci. Technol. (1986 - present)</option>\n<option value=\"0964-1726\"   >Smart Mater. Struct. (1992 - present)</option>\n<option value=\"0049-1748\"   >Sov. J. Quantum Electron. (1971 - 1992)</option>\n<option value=\"0038-5670\"   >Sov. Phys. Usp. (1958 - 1992)</option>\n<option value=\"0953-2048\"   >Supercond. Sci. Technol. (1988 - present)</option>\n<option value=\"2051-672X\"   >Surf. Topogr.: Metrol. Prop. (2013 - present)</option>\n<option value=\"1538-3881\"   >The Astronomical Journal (1849 - present)</option>\n<option value=\"0004-637X\" selected  >The Astrophysical Journal (1996 - present)</option>\n<option value=\"1538-4357\"   >The Astrophysical Journal Letters (1995 - 2009)</option>\n<option value=\"2041-8205\"   >The Astrophysical Journal Letters (2010 - present)</option>\n<option value=\"0067-0049\"   >The Astrophysical Journal Supplement Series (1996 - present)</option>\n<option value=\"2632-3338\"   >The Planetary Science Journal (2020 - present)</option>\n<option value=\"2156-7395\"   >Trans. Am. Electrochem. Soc. (1930 - 1930)</option>\n<option value=\"1945-6859\"   >Trans. Electrochem. Soc. (1931 - 1948)</option>\n<option value=\"1475-4878\"   >Trans. Opt. Soc. (1899 - 1932)</option>\n<option value=\"2053-1613\"   >Transl. Mater. Res. (2014 - 2018)</option>\n</select>\n<label for=\"CF_VOLUME\" class=\"offscreen-hidden\">Volume number:</label>\n            <input type=\"text\" name=\"CF_VOLUME\" id=\"CF_VOLUME\" class=\"art-lookup__content-finder-field\" placeholder=\"Volume\" x-webkit-speech=\"\">\n            <label for=\"CF_ISSUE\" class=\"offscreen-hidden\">Issue number (if known):</label>\n            <input type=\"text\" name=\"CF_ISSUE\" id=\"CF_ISSUE\" class=\"art-lookup__content-finder-field\" placeholder=\"Issue\" x-webkit-speech=\"\">\n            <label for=\"CF_PAGE\" class=\"offscreen-hidden\">Article or page number:</label>\n            <input type=\"text\" name=\"CF_PAGE\" id=\"CF_PAGE\" class=\"art-lookup__content-finder-field art-lookup__content-finder-field--last\" placeholder=\"Article or page\" x-webkit-speech=\"\">\n\n            <input type=\"submit\" class=\"btn btn-default art-lookup__submit\" value=\"Lookup\" name=\"submit\">\n        </div>\n    </fieldset>\n</form></div>\n    </div>\n</div></header>\n<!-- Header tile ends -->\n<div class=\"page-body\" itemscope itemtype=\"http://schema.org/Periodical\">\n        <a name=\"\" id=\"skip-to-content-link-target\" tabindex=\"-1\"></a>\n        <div class=\"wrapper grid-3-col da-showgrid ta-showgrid cf\">\n    <main role=\"main\">\n        <!-- Secondary header starts -->\n<div class=\"secondary-header cf\" id=\"wd-secondary-header\">\n    <!-- Branded journal header starts -->\n<div class=\"big-branded\">\n\n    <div class=\"publication-name\" id=\"wd-pub-name\">\n\t<div class=\"publication-title\" itemprop=\"name\" itemid=\"periodical\">\n\t\t\t\t<!-- Journal image link tile starts -->\n<!-- Logo tile starts -->\n<a href=\"/journal/0004-637X\" itemprop=\"url\">\n    <img src=\"https://cms.iopscience.org/8febf88b-d09c-11e5-b0b6-759f86a2008e/apj-2016.png?guest=true\" alt=\"The Astrophysical Journal\">\n</a>\n<!-- Logo tile ends -->\n<!-- Journal image link tile ends -->\n</div>\n\t\t</div>\n    <div class=\"partner-logos m-hide\" id=\"wd-partner-logos\">\n            <div class=\"partner-logo-alignment\">\n                <!-- Partner logo tile starts -->\n<a href=\"\" class=\"overlay-launch\">\n    <img border=\"0\" src=\"https://cms.iopscience.org/8a2230b8-d09c-11e5-b0b6-759f86a2008e/aas-2018.png?guest=true\" alt=\"The American Astronomical Society, find out more\">\n</a>\n<span class=\"overlay-set\">\n    <div class=\"tint-screen\"></div>\n    <div class=\"overlay-panel\">\n        <a title=\"Close\"  class=\"close-icon close-overlay\" tabindex=\"0\" role=\"button\" aria-describedby=\"close-icon-description\"><span class=\"icon-close\"></span></a>\n        <p id=\"close-icon-description\" class=\"offscreen-hidden\">Click here to close this overlay, or press the \"Escape\" key on your keyboard.</p>\n        <div class=\"overlay-img\">\n            <a href=\"\">\n                <img border=\"0\" src=\"https://cms.iopscience.org/8a2230b8-d09c-11e5-b0b6-759f86a2008e/aas-2018.png?guest=true\" alt=\"The American Astronomical Society, find out more\">\n            </a>\n        </div>\n        <div class=\"overlay-text\">\n            <p>The American Astronomical Society (AAS), established in 1899 and based in Washington, DC, is the major organization of professional astronomers in North America. Its membership of about 7,000 individuals also includes physicists, mathematicians, geologists, engineers, and others whose research and educational interests lie within the broad spectrum of subjects comprising contemporary astronomy. The mission of the AAS is to enhance and share humanity's scientific understanding of the universe.</p> <p><a href=\"https://aas.org/\">https://aas.org/</a></div>\n        <p class=\"ta-c mt-1 mb-2\"><a href=\"\"></a></p>\n    </div>\n</span>\n<!-- Partner logo tile ends -->\n\n<!-- Partner logo tile starts -->\n<a href=\"\" class=\"overlay-launch\">\n    <img border=\"0\" src=\"https://cms.iopscience.org/7ebd1b32-0439-11e9-b401-cfe9679c40e3/iop-2016.png?guest=true\" alt=\"The Institute of Physics, find out more\">\n</a>\n<span class=\"overlay-set\">\n    <div class=\"tint-screen\"></div>\n    <div class=\"overlay-panel\">\n        <a title=\"Close\"  class=\"close-icon close-overlay\" tabindex=\"0\" role=\"button\" aria-describedby=\"close-icon-description\"><span class=\"icon-close\"></span></a>\n        <p id=\"close-icon-description\" class=\"offscreen-hidden\">Click here to close this overlay, or press the \"Escape\" key on your keyboard.</p>\n        <div class=\"overlay-img\">\n            <a href=\"\">\n                <img border=\"0\" src=\"https://cms.iopscience.org/7ebd1b32-0439-11e9-b401-cfe9679c40e3/iop-2016.png?guest=true\" alt=\"The Institute of Physics, find out more\">\n            </a>\n        </div>\n        <div class=\"overlay-text\">\n            <p>The Institute of Physics (IOP) is a leading scientific society promoting physics and bringing physicists together for the benefit of all. It has a worldwide membership of around 50 000 comprising physicists from all sectors, as well as those with an interest in physics. It works to advance physics research, application and education; and engages with policy makers and the public to develop awareness and understanding of physics. Its publishing company, IOP Publishing, is a world leader in professional scientific communications.</p> <p><a href=\"https://www.iop.org\">https://www.iop.org</a></p></div>\n        <p class=\"ta-c mt-1 mb-2\"><a href=\"\"></a></p>\n    </div>\n</span>\n<!-- Partner logo tile ends -->\n\n<p></p>\n                </div>\n        </div>\n    </div>\n<!-- Branded journal header ends -->\n</div> <!-- end secondary-header -->\n<!-- Secondary header ends --><div class=\"da1-da2\" itemscope=\"\" itemtype=\"http://schema.org/ScholarlyArticle\" id=\"page-content\">\n            <div class=\"da1 ta1 article-head\">\n                <!-- Start Eyebrow block, containing Surtitle and Labels -->\n<div class=\"eyebrow\">\n\t<!-- Start Collection Labels -->\n    <!-- End Collection Labels --> </div>\n<!-- End Eyebrow block -->\n\n<h1 itemprop=\"headline\" class=\"wd-jnl-art-title\">LensFlow: A Convolutional Neural Network in Search of Strong Gravitational Lenses</h1>\n\n<p class=\"mb-0\">\n\t<span data-authors=\"\">\n\t\t<span itemtype=\"http://schema.org/Person\" itemprop=\"author\" class=\"nowrap\"><span itemprop=\"name\">Milad Pourrahmani</span><sup>1</sup><a xmlns:xlink=\"http://www.w3.org/1999/xlink\" target=\"_blank\" href=\"https://orcid.org/0000-0003-3351-5986\" title=\"https://orcid.org/0000-0003-3351-5986\"><svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 256 256\" width=\"20\" class=\"orcid-logo\"><path class=\"st0\" d=\"M256 128c0 70.7-57.3 128-128 128C57.3 256 0 198.7 0 128 0 57.3 57.3 0 128 0 198.7 0 256 57.3 256 128z\"></path><path class=\"st1\" d=\"M86.3 186.2H70.9V79.1h15.4v48.4V186.2z\"></path><path class=\"st1\" d=\"M108.9 79.1h41.6c39.6 0 57 28.3 57 53.6 0 27.5-21.5 53.6-56.8 53.6h-41.8V79.1zM124.3 172.4h24.5c34.9 0 42.9-26.5 42.9-39.7 0-21.5-13.7-39.7-43.7-39.7h-23.7V172.4z\"></path><path class=\"st1\" d=\"M88.7 56.8c0 5.5-4.5 10.1-10.1 10.1 -5.6 0-10.1-4.6-10.1-10.1 0-5.6 4.5-10.1 10.1-10.1C84.2 46.7 88.7 51.3 88.7 56.8z\"></path></svg></a></span>, <span itemtype=\"http://schema.org/Person\" itemprop=\"author\" class=\"nowrap\"><span itemprop=\"name\">Hooshang Nayyeri</span><a xmlns:xlink=\"http://www.w3.org/1999/xlink\" target=\"_blank\" href=\"https://orcid.org/0000-0001-8242-9983\" title=\"https://orcid.org/0000-0001-8242-9983\"><svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 256 256\" width=\"20\" class=\"orcid-logo\"><path class=\"st0\" d=\"M256 128c0 70.7-57.3 128-128 128C57.3 256 0 198.7 0 128 0 57.3 57.3 0 128 0 198.7 0 256 57.3 256 128z\"></path><path class=\"st1\" d=\"M86.3 186.2H70.9V79.1h15.4v48.4V186.2z\"></path><path class=\"st1\" d=\"M108.9 79.1h41.6c39.6 0 57 28.3 57 53.6 0 27.5-21.5 53.6-56.8 53.6h-41.8V79.1zM124.3 172.4h24.5c34.9 0 42.9-26.5 42.9-39.7 0-21.5-13.7-39.7-43.7-39.7h-23.7V172.4z\"></path><path class=\"st1\" d=\"M88.7 56.8c0 5.5-4.5 10.1-10.1 10.1 -5.6 0-10.1-4.6-10.1-10.1 0-5.6 4.5-10.1 10.1-10.1C84.2 46.7 88.7 51.3 88.7 56.8z\"></path></svg></a></span>, and <span itemtype=\"http://schema.org/Person\" itemprop=\"author\" class=\"nowrap\"><span itemprop=\"name\">Asantha Cooray</span><a xmlns:xlink=\"http://www.w3.org/1999/xlink\" target=\"_blank\" href=\"https://orcid.org/0000-0002-3892-0190\" title=\"https://orcid.org/0000-0002-3892-0190\"><svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 256 256\" width=\"20\" class=\"orcid-logo\"><path class=\"st0\" d=\"M256 128c0 70.7-57.3 128-128 128C57.3 256 0 198.7 0 128 0 57.3 57.3 0 128 0 198.7 0 256 57.3 256 128z\"></path><path class=\"st1\" d=\"M86.3 186.2H70.9V79.1h15.4v48.4V186.2z\"></path><path class=\"st1\" d=\"M108.9 79.1h41.6c39.6 0 57 28.3 57 53.6 0 27.5-21.5 53.6-56.8 53.6h-41.8V79.1zM124.3 172.4h24.5c34.9 0 42.9-26.5 42.9-39.7 0-21.5-13.7-39.7-43.7-39.7h-23.7V172.4z\"></path><path class=\"st1\" d=\"M88.7 56.8c0 5.5-4.5 10.1-10.1 10.1 -5.6 0-10.1-4.6-10.1-10.1 0-5.6 4.5-10.1 10.1-10.1C84.2 46.7 88.7 51.3 88.7 56.8z\"></path></svg></a></span></span>\n</p>\n\n<p class=\"small\" itemprop=\"isPartOf\" itemscope=\"\" itemtype=\"http://schema.org/PublicationIssue\">\n\t<!--Article Breadcrumb Tile Start-->\n<span class=\"wd-jnl-art-pub-date\">Published 2018 March 26</span> &bull; <!-- Start Copyright-->\n    <span itemprop=\"copyrightHolder\" class=\"wd-jnl-art-copyright\">\n       \t  \u00a9 2018. The American Astronomical Society. All rights reserved.</span><br />\n    <!-- end Copyright -->\n<span itemscope itemtype=\"http://schema.org/Periodical\" itemid=\"periodical\" class=\"wd-jnl-art-breadcrumb-title article-toolbar-anchor\">\n\t<span itemprop=\"name\">\n\t\t<a href=\"/journal/0004-637X\" itemprop=\"url\">The Astrophysical Journal</a></span></span>,\n\t<span itemprop=\"isPartOf\" itemscope itemtype=\"http://schema.org/PublicationVolume\" class=\"wd-jnl-art-breadcrumb-vol nowrap\">\n\t<link itemprop=\"isPartOf\" itemid=\"periodical\" itemscope/>\n\t<span itemprop=\"volumeNumber\"><a href=\"/volume/0004-637X/856\" itemprop=\"url\">Volume 856</a></span></span>,\n<span itemprop=\"issueNumber\" class=\"wd-jnl-art-breadcrumb-issue\"><a href=\"/issue/0004-637X/856/1\" itemprop=\"url\"><!--Issue Number Tile Start-->\nNumber 1<!--Issue Number Tile End--></a></span>\n<!--Article Breadcrumb Tile End-->\n<!-- Start Focus issue title -->\n\t<!-- End focus issue title -->\n\t<span style=\"display: block\"><b>Citation</b> Milad Pourrahmani <em>et al</em> 2018 <em>ApJ</em> <b>856</b> 68</span>\n    </p>\n\n<div class=\"btn-multi-block mb-1\">\n\t\t<a href=\"/article/10.3847/1538-4357/aaae6a/pdf\" class=\"btn btn-large btn-primary content-download btn-full-w-mobile wd-jnl-art-pdf-button-main dupe-buttons\" title=\"LensFlow: A Convolutional Neural Network in Search of Strong Gravitational Lenses\" itemprop=\"sameAs\" target = \"_blank\"><span class=\"icon-file-pdf\"></span><span class=\"offscreen-hidden\"> Download </span><span>Article</span> PDF</a>\n<div class=\"hover-trigger\">\n\t\t<a target=\"_blank\" href=\"/article/10.3847/1538-4357/aaae6a/epub\" class=\"btn btn-large btn-primary content-download btn-full-w-mobile dupe-buttons\" id=\"wd-article-epub-but\">\n\t\t\t<span class=\"icon-epub\"></span><span class=\"offscreen-hidden\">Download</span><span>Article</span> ePub <span></span>\n\t\t\t</a>\n\t\t<div class=\"epub-label hover-item bd-1\">\n\t\t\t<p class=\"small\">You need an eReader or compatible software to experience <a href=\"http://iopscience.iop.org/page/ePub3\">the benefits of the ePub3 file format</a>.</p>\n\t\t</div>\n\t</div>\n</div>\n<!-- Start toolbar -->\n<div class=\"in-page-nav-wrapper\">\n\t<div class=\"nav-in-page m-hide wd-in-pg-toolbar in-page-toolbar-anchor\">\n\t\t<div class=\"nav-in-page-active-wrapper\">\n\t\t\t<div class=\"\">\n\t\t\t\t<div class=\"nav-in-page-active-grid-1\">\n\t\t\t\t\t<nav data-nav-group>\n\t\t\t\t\t\t<div class=\"nav-item wd-in-pg-toolbar-fig\">\n\t\t\t\t\t\t\t<a href=\"\" class=\"nav-top-link-drop-down article-toolbar-dropdown\" data-toolbar-action=\"figures\" data-nav-trigger=\"figures\">Figures<span class=\"icon-arrow-down\"></span></a>\n\t\t\t\t\t\t\t<div class=\"nav-drop-down\" data-nav-item=\"figures\">\n\t\t\t\t\t\t\t\t<div class=\"overflow-x\" data-toolbar-container=\"figures\"></div>\n\t\t\t\t\t\t\t</div>\n\t\t\t\t\t\t</div>\n\t\t\t\t\t\t<div class=\"nav-item wd-in-pg-toolbar-tables\">\n\t\t\t\t\t\t\t<a href=\"\" class=\"nav-top-link-drop-down article-toolbar-dropdown\" data-toolbar-action=\"table\" data-nav-trigger=\"table\">Tables<span class=\"icon-arrow-down\"></span></a>\n\t\t\t\t\t\t\t<div class=\"nav-drop-down\" data-nav-item=\"table\">\n\t\t\t\t\t\t\t\t<div class=\"overflow-x\" data-toolbar-container=\"table\"></div>\n\t\t\t\t\t\t\t</div>\n\t\t\t\t\t\t</div>\n\t\t\t\t\t\t<div class=\"nav-item wd-in-pg-toolbar-ref\">\n\t\t\t\t\t\t\t<a href=\"\" class=\"nav-top-link-drop-down article-toolbar-dropdown\" data-toolbar-action=\"references\" data-nav-trigger=\"references\">References<span class=\"icon-arrow-down\"></span></a>\n\t\t\t\t\t\t\t<div class=\"nav-drop-down\" data-nav-item=\"references\">\n\t\t\t\t\t\t\t\t<div class=\"overflow-y\" data-toolbar-container=\"references\"></div>\n\t\t\t\t\t\t\t</div>\n\t\t\t\t\t\t</div>\n\t\t\t\t\t\t<div class=\"nav-item wd-in-pg-toolbar-artdata\">\n\t\t\t\t\t\t\t\t<a href=\"\" class=\"nav-top-link-drop-down article-toolbar-dropdown\" data-toolbar-action=\"artdata\" data-nav-trigger=\"artdata\">Article data<span class=\"icon-arrow-down\"></span></a>\n\t\t\t\t\t\t\t\t<div class=\"nav-drop-down\" data-nav-item=\"artdata\">\n\t\t\t\t\t\t\t\t\t<div class=\"overflow-x mb-05\" data-toolbar-container=\"artdata\"></div>\n\t\t\t\t\t\t\t\t\t<p class=\"small\"><a target=\"_blank\" href=\"/journal/0004-637X/page/article-data\">What is article data?</a></p>\n\t\t\t\t\t\t\t\t</div>\n\t\t\t\t\t\t\t</div>\n\t\t\t\t\t\t</nav>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"nav-in-page-active-grid-2 d-n\">\n\t\t\t\t\t<aside>\n\t\t\t\t\t\t<div class=\"pdf-button-2nd\">\n\t\t\t\t\t\t</div>\n\t\t\t\t\t</aside>\n\t\t\t\t</div>\n\t\t\t</div>\n\t\t</div>\n\t</div>\n</div>\n<!-- End toolbar --></div>\n            <div class=\"da2 ta2\">\n                <div class=\"print-hide content-tools\">\n\t\t\t<div>\n\t<p>\n\t\t<span id=\"total-downloads\" class=\"wd-jnl-art-total-dwnlds\"><b>1303</b> Total downloads</span>\n\t\t\t<br />\n\t\t</p>\n\t</div>\n\t\n<div class=\"dimensions-altmetric-li\">\n\n        <!-- Start Dimensions display -->\n        <!-- Start Dimensions display -->\n    <span class=\"__dimensions_badge_embed__ dimensions-embed\" data-doi=\"10.3847/1538-4357/aaae6a\" data-style=\"small_rectangle\" data-hide-zero-citations=\"true\" data-legend=\"never\"></span>\n    <!-- End Dimensions display -->\n<!-- End Dimensions display -->\n        <div class=\"clear-fl\"></div>\n    </div>\n<!-- Start MathJax links -->\n\t\t<div>\n\t\t  <a href=\"#\" id=\"mathJaxOff\" style=\"display: none;\">Turn off MathJax</a>\n\t\t  <a href=\"#\" id=\"mathJaxOn\" style=\"display: none;\">Turn on MathJax</a>\n\t\t</div>\t\n\t<!-- End MathJax links -->\n<!-- Start Permission Link -->\n\t<div>\n\t\t\t<p class=\"wd-jnl-art-get-permisssion print-hide\">\n\t\t\t\t<a href=\"https://journals.aas.org/article-charges-and-copyright/#AAS_material\" target=\"_blank\">Get permission to re-use this article</a>\n\t\t\t</p>\n\t\t</div>\n\t<!-- End Permission Link --><div id=\"wd-share-icons\">\n<p>Share this article</p>\n<ul class=\"share-icon-links\">\n\t\t<li id=\"wd-share-icon-email\" class=\"share-icon-link\">\n\t<a href=\"mailto:?subject=LensFlow: A Convolutional Neural Network in Search of Strong Gravitational Lenses&amp;body=LensFlow: A Convolutional Neural Network in Search of Strong Gravitational Lenses - https://doi.org/10.3847/1538-4357/aaae6a\" title=\"Share this content via email. Clicking this link will open your default email client.\" class=\"share-icon-link\">\n\t\t\t<img src=\"https://static.iopscience.com/2.44.0/img/icon-email.svg\" alt=\"Share this content via email\">\n\t</a>\n\t</li>\n\t<li id=\"wd-share-icon-facebook\" class=\"share-icon-link\">\n\t<a href=\"http://www.facebook.com/sharer.php?u=https%3A%2F%2Fdoi.org%2F10.3847%2F1538-4357%2Faaae6a\" title=\"Share a link to this content on your Facebook profile\" class=\"share-icon-link\">\n\t\t\t<img src=\"https://static.iopscience.com/2.44.0/img/icon-facebook.svg\" alt=\"Share on Facebook\">\n\t</a>\n\t</li>\n\t<li id=\"wd-share-icon-twitter\" class=\"share-icon-link\">\t\t\t\t\t\t\t\n\t<a href=\"http://twitter.com/share?url=https%3A%2F%2Fdoi.org%2F10.3847%2F1538-4357%2Faaae6a&amp;text=LensFlow%3A+A+Convolutional+Neural+Network+in+Search+of+Strong+Gravitational+Lenses&amp;via=IOPscience\" title=\"Share a link to this content on your Twitter profile\" class=\"share-icon-link\">\n\t\t\t<img src=\"https://static.iopscience.com/2.44.0/img/icon-twitter.svg\" alt=\"Share on Twitter\">\n\t</a>\n\t</li>\n\t<li id=\"wd-share-icon-google-plus\" class=\"share-icon-link\">\n\t<a href=\"https://plus.google.com/share?url=https%3A%2F%2Fdoi.org%2F10.3847%2F1538-4357%2Faaae6a\" title=\"Share a link to this content on your Google+ profile\" class=\"share-icon-link\">\n\t\t\t<img src=\"https://static.iopscience.com/2.44.0/img/icon-google-plus.svg\" alt=\"Share on Google+\">\n\t</a>\n\t</li>\n\t<li id=\"wd-share-icon-mendeley\" class=\"share-icon-link\">\n\t<a href=\"https://www.mendeley.com/import/?doi=10.3847%2F1538-4357%2Faaae6a\" title=\"Share on Mendeley\" class=\"share-icon-link\">\n\t\t\t<img src=\"https://static.iopscience.com/2.44.0/img/icon-mendeley.svg\" alt=\"Share on Mendeley\">\n\t</a>\n\t</li>\n</ul>\n<div class=\"clear-fl\"></div>\n</div>\n\n</div>\n</div>\n            <div class=\"da1 ta1\">\n                <!-- Start Linked Articles note -->\n\t<!-- End Linked Articles note -->\n<!-- Article information starts. This includes author emails, affiliations, article published date, doi etc. -->\n\t<div class=\"reveal-container reveal-closed reveal-plus-icon bdt-1 wd-jnl-art-article-info-wrapper\">\n      \t<div class=\"replica-h3 mt-0\">\n        \t<a id=\"wd-article-info-accordion\" href=\"#\" class=\"reveal-trigger\" data-reveal-label-alt=\"Hide article information\">Article information</a>\n      \t</div>\n      \t<div class=\"reveal-content\">\n        \t<div class=\"article-meta\">\n          \t\t<!-- Start Affiliations --><div class=\"wd-jnl-art-author-affiliations\"><div class=\"replica-h4\">Author affiliations</div><p class=\"mb-05\">Department of Physics and Astronomy, University of California Irvine, Irvine, CA, USA</p><p class=\"mb-05\"><sup>1</sup> Corresponding author.</p></div><!-- End Affiliations --><!-- Start ORCIDs --><div class=\"wd-jnl-art-author-orcid-list\"><div class=\"replica-h4\">ORCID iDs</div><p class=\"mb-05\"><span itemtype=\"http://schema.org/Person\" itemprop=\"author\" class=\"nowrap\"><span itemprop=\"name\">Milad Pourrahmani</span><a xmlns:xlink=\"http://www.w3.org/1999/xlink\" target=\"_blank\" href=\"https://orcid.org/0000-0003-3351-5986\" title=\"https://orcid.org/0000-0003-3351-5986\"><svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 256 256\" width=\"20\" class=\"orcid-logo\"><path class=\"st0\" d=\"M256 128c0 70.7-57.3 128-128 128C57.3 256 0 198.7 0 128 0 57.3 57.3 0 128 0 198.7 0 256 57.3 256 128z\"></path><path class=\"st1\" d=\"M86.3 186.2H70.9V79.1h15.4v48.4V186.2z\"></path><path class=\"st1\" d=\"M108.9 79.1h41.6c39.6 0 57 28.3 57 53.6 0 27.5-21.5 53.6-56.8 53.6h-41.8V79.1zM124.3 172.4h24.5c34.9 0 42.9-26.5 42.9-39.7 0-21.5-13.7-39.7-43.7-39.7h-23.7V172.4z\"></path><path class=\"st1\" d=\"M88.7 56.8c0 5.5-4.5 10.1-10.1 10.1 -5.6 0-10.1-4.6-10.1-10.1 0-5.6 4.5-10.1 10.1-10.1C84.2 46.7 88.7 51.3 88.7 56.8z\"></path></svg> https://orcid.org/0000-0003-3351-5986</a></span></p><p class=\"mb-05\"><span itemtype=\"http://schema.org/Person\" itemprop=\"author\" class=\"nowrap\"><span itemprop=\"name\">Hooshang Nayyeri</span><a xmlns:xlink=\"http://www.w3.org/1999/xlink\" target=\"_blank\" href=\"https://orcid.org/0000-0001-8242-9983\" title=\"https://orcid.org/0000-0001-8242-9983\"><svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 256 256\" width=\"20\" class=\"orcid-logo\"><path class=\"st0\" d=\"M256 128c0 70.7-57.3 128-128 128C57.3 256 0 198.7 0 128 0 57.3 57.3 0 128 0 198.7 0 256 57.3 256 128z\"></path><path class=\"st1\" d=\"M86.3 186.2H70.9V79.1h15.4v48.4V186.2z\"></path><path class=\"st1\" d=\"M108.9 79.1h41.6c39.6 0 57 28.3 57 53.6 0 27.5-21.5 53.6-56.8 53.6h-41.8V79.1zM124.3 172.4h24.5c34.9 0 42.9-26.5 42.9-39.7 0-21.5-13.7-39.7-43.7-39.7h-23.7V172.4z\"></path><path class=\"st1\" d=\"M88.7 56.8c0 5.5-4.5 10.1-10.1 10.1 -5.6 0-10.1-4.6-10.1-10.1 0-5.6 4.5-10.1 10.1-10.1C84.2 46.7 88.7 51.3 88.7 56.8z\"></path></svg> https://orcid.org/0000-0001-8242-9983</a></span></p><p class=\"mb-05\"><span itemtype=\"http://schema.org/Person\" itemprop=\"author\" class=\"nowrap\"><span itemprop=\"name\">Asantha Cooray</span><a xmlns:xlink=\"http://www.w3.org/1999/xlink\" target=\"_blank\" href=\"https://orcid.org/0000-0002-3892-0190\" title=\"https://orcid.org/0000-0002-3892-0190\"><svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 256 256\" width=\"20\" class=\"orcid-logo\"><path class=\"st0\" d=\"M256 128c0 70.7-57.3 128-128 128C57.3 256 0 198.7 0 128 0 57.3 57.3 0 128 0 198.7 0 256 57.3 256 128z\"></path><path class=\"st1\" d=\"M86.3 186.2H70.9V79.1h15.4v48.4V186.2z\"></path><path class=\"st1\" d=\"M108.9 79.1h41.6c39.6 0 57 28.3 57 53.6 0 27.5-21.5 53.6-56.8 53.6h-41.8V79.1zM124.3 172.4h24.5c34.9 0 42.9-26.5 42.9-39.7 0-21.5-13.7-39.7-43.7-39.7h-23.7V172.4z\"></path><path class=\"st1\" d=\"M88.7 56.8c0 5.5-4.5 10.1-10.1 10.1 -5.6 0-10.1-4.6-10.1-10.1 0-5.6 4.5-10.1 10.1-10.1C84.2 46.7 88.7 51.3 88.7 56.8z\"></path></svg> https://orcid.org/0000-0002-3892-0190</a></span></p></div><!-- End ORCIDs --><!-- Start Dates -->\n<div class=\"col-no-break wd-jnl-art-dates\">\n        <div class=\"replica-h4\">Dates</div>\n        <p>\n            \n                Received <span itemprop=\"dateReceived\">2017 May 23</span><br />\n            \n                Accepted <span itemprop=\"dateAccepted\">2018 February 7</span><br />\n            \n                    Published <span itemprop=\"datePublished\">2018 March 26</span><br />\n                </p>\n    </div>\n<!-- End Dates -->\n\n<!-- Start Crossmark -->\n\t\t\t\t<p class=\"wd-jnl-art-crossmark\">\n\t\t\t\t\t\t<a target=\"_blank\" href=\"http://crossmark.crossref.org/dialog/?doi=10.3847/1538-4357/aaae6a&domain=pdf\">\n\t\t\t\t\t\t\t<img src=\"https://static.iopscience.com/2.44.0/img/CROSSMARK_Color_horizontal.svg\" width=\"130\" alt=\"Check for updates using Crossmark\">\n\t\t\t\t\t\t</a>\n\t\t\t\t\t</p>\n\t\t\t\t<!-- End Crossmark -->\n\n\t\t\t\t<!-- Start Peer Review Metrics -->\n<!-- End Peer Review Metrics -->\n\n<!--  Start Citation -->\n                    <!--  End Citation -->\n\t\t\t\t\n\t\t\t\t<!-- Start DOI -->\n\t\t\t\t<div class=\"col-no-break wd-jnl-art-doi\">\n\t\t\t\t\t<div class=\"replica-h4\">\n\t\t\t\t\t<abbr title=\"digital object identifier\">DOI</abbr>\n\t\t\t\t\t</div>\n\t\t\t\t\t<p><a itemprop=\"sameAs\" href=\"https://doi.org/10.3847/1538-4357/aaae6a\">https://doi.org/10.3847/1538-4357/aaae6a</a></p>\n\t\t\t\t</div>\n\t\t\t\t<!-- End DOI -->\n\t\t\t\t\n\t\t\t\t<!-- Start Accepted manuscript Link -->\n<!-- End Accepted manuscript Link -->\n<!-- Start Annotations -->\n <!-- End Annotations --><div class=\"col-no-break wd-jnl-aas-keywords\">\n\t\t<div class=\"replica-h4\">Keywords</div>\n\t\t<p><a href=\"/searchaaskeyword?source=aas&amp;type=kwd_group&amp;code=2%2F46&amp;code_desc=gravitational+lensing%3A+strong\">gravitational lensing: strong</a>; <a href=\"/searchaaskeyword?source=aas&amp;type=kwd_group&amp;code=3%2F14&amp;code_desc=methods%3A+data+analysis\">methods: data analysis</a>; <a href=\"/searchaaskeyword?source=aas&amp;type=kwd_group&amp;code=3%2F23&amp;code_desc=techniques%3A+image+processing\">techniques: image processing</a></p>\n\t</div>\n<!-- Start Reprint Link -->\n\t<!-- End Reprint Link --><!-- Start Journal RSS feed -->\n                    <div class=\"jnl-notifications-wrapper jnl-notifications-wrapper--rss\">\n                        <a class=\"wd-jnl-rss\" href=\"/journal/rss/0004-637X\"><span\n                                class=\"icon-feed icon-feed--jhp\"></span>Journal RSS</a>\n                    </div>\n\t\t\t\t\t<!-- End Journal RSS feed -->\n\t\t\t\t\t<!-- Start Email Alert -->\n    <!-- Start Email Alert -->\n        <div class=\"jnl-notifications-wrapper\">\n            <a class=\"wd-jnl-email-alert loginRequired\"\n               href=\"https://myiopscience.iop.org/signin?origin=a0&return=https%3A%2F%2Fiopscience.iop.org%2Farticle%2F10.3847%2F1538-4357%2Faaae6a\"\n               id=\"corridors-create-manage\" title=\"Create or edit your corridor alerts\">\n                <span class=\"icon-alarm icon-alarm--jhp\"></span>Create or edit your corridor alerts\n            </a>\n\n<!-- Start TOC Subjects Popup -->\n<span class=\"overlay-set\" id=\"corridor-alerts-overlay\">\n    <div class=\"tint-screen\"></div>\n    <div class=\"overlay-panel two-columns\">\n        <div id=\"innerContainer\">\n            <a class=\"close-icon close-overlay\" title=\"Close\" tabindex=\"0\" role=\"button\" aria-describedby=\"close-icon-description\">\n                <span class=\"icon-close\"></span>\n            </a>\n            <p id=\"close-icon-description\" class=\"offscreen-hidden\">\n                Click here to close this overlay, or press the \"Escape\" key on your keyboard.\n            </p>\n            <form id=\"alertsForm\" class=\"overlay-panel__form\" method=\"post\" action=\"\" role=\"form\" aria-labelledby=\"alerts-box-title\">\n                <div class=\"overlay-panel__header\">\n                    <div class=\"overlay-panel__logo\"></div>\n                    <span id=\"alerts-box-title\" class=\"replica-h2\">Corridor alerts</span>\n                    <p id=\"alerts-box-desc\">\n                        Receive alerts on all new research papers in American Astronomical Society\n                        (<span class=\"abbr__aas\">A&nbsp;A&nbsp;S&nbsp;</span>) journals as soon as they are published.\n                        Select your desired journals and corridors below. You will need to select a minimum of one corridor.\n                    </p>\n                </div>\n                <div class=\"overlay-panel__container\">\n                    <div class=\"overlay-panel__col\">\n                        <fieldset id=\"alerts-corridors-list\">\n                            <legend id=\"corridors-title\" class=\"overlay-panel__heading replica-h3 mb-05\">Corridors</legend>\n                        </fieldset>\n                    </div>\n                    <div class=\"overlay-panel__col\">\n                        <fieldset id=\"alerts-journals-list\">\n                            <legend id=\"journals-title\" class=\"overlay-panel__heading replica-h3 mb-05\">Journals</legend>\n                        </fieldset>\n                    </div>\n                    <div class=\"boxout-bg-blue-light overlay-panel__extra-info\">\n                        <p>\n                            Please note, The Astrophysical Journal Letters (ApJL) and Research Notes of the AAS (RNAAS)\n                            do not currently use the corridors.\n                        </p>\n                    </div>\n                </div>\n                <div class=\"overlay-panel__footer\">\n                    <div class=\"overlay-panel__inner-footer\">\n                        <input id=\"update-alerts\" type=\"submit\" value=\"Create alert\" class=\"btn btn-default overlay-panel__btn\" role=\"button\">\n                        <div class=\"icon-spinner spinner overlay-panel__loading\"></div>\n                    </div>\n                </div>\n            </form>\n        </div>\n    </div>\n</span>\n<!-- End TOC Subjects Popup -->\n            <p class=\"mb-0\"><a class=\"wd-jnl-email-alert jnl-email-alert--corridors-info\" href=\"https://journals.aas.org/corridors.html\"\n               target=\"_blank\" title=\"Find out more about AAS corridors.\">\n                What are corridors? <span class=\"icon-newtab\">\n            </a></p>\n        </div>\n\n    <!-- End Email Alert -->\n<!-- End Email Alert --><!-- Start Citation Alert Link -->\n                        <p>\n<div class=\"jnl-notifications-wrapper\">\n    <a class=\"wd-jnl-email-alert\" href=\"https://myiopscience.iop.org/signin?origin=a0&return=https%3A%2F%2Fiopscience.iop.org%2Fmyiopscience%2Falerts%2Fsubscribe%3FarticleID%3D0004-637X%2F856%2F1%2F68\"><span\n            class=\"icon-alarm icon-alarm--jhp\"></span>Create citation alert</a>\n</div><!-- End Citation Alert Link -->\n                    </div>\n\t\t</div>\n    </div>\n    <!-- Article information ends -->\n<!-- Start Info top-->\n    <!-- end Info top --><div class=\"article-content\">\n\t<span id=\"articleId\" class=\"hide\">0004-637X/856/1/68</span>\n<!-- Start Abstract -->\n    <h2 id=\"artAbst\" class=\"collapse-blocked\">Abstract</h2>\n        <!-- Start article video abstract -->\n\t<!-- End article video abstract -->\n\t<div class=\"article-text wd-jnl-art-abstract cf\" itemprop=\"description\">\n             <P>In this work, we present our machine learning classification algorithm for identifying strong gravitational lenses from wide-area surveys using convolutional neural networks; <span class=\"small-caps\">LensFlow</span>. We train and test the algorithm using a wide variety of strong gravitational lens configurations from simulations of lensing events. Images are processed through multiple convolutional layers that extract feature maps necessary to assign a lens probability to each image. <span class=\"small-caps\">LensFlow</span> provides a ranking scheme for all sources that could be used to identify potential gravitational lens candidates by significantly reducing the number of images that have to be visually inspected. We apply our algorithm to the <I>HST</I>/ACS i-band observations of the COSMOS field and present our sample of identified lensing candidates. The developed machine learning algorithm is more computationally efficient and complimentary to classical lens identification algorithms and is ideal for discovering such events across wide areas from current and future surveys such as LSST and <I>WFIRST</I>.</P> </div>\n    <!-- End abstract -->\n<!-- Start Export citation and abstract tools -->\n\t<p>\n\t\t<small>Export citation and abstract</small>\n\t\t<span class=\"btn-multi-block\">\n\t\t\t<a href=\"/export?articleId=0004-637X/856/1/68&doi=10.3847/1538-4357/aaae6a&exportFormat=iopexport_bib&exportType=abs&navsubmit=Export+abstract\" class=\"btn btn-primary wd-btn-cit-abs-bib\" title=\"Export BibTex\">BibTeX</a>\n\t\t\t<a href=\"/export?articleId=0004-637X/856/1/68&doi=10.3847/1538-4357/aaae6a&exportFormat=iopexport_ris&exportType=abs&navsubmit=Export+abstract\" class=\"btn btn-primary wd-btn-cit-abs-ris\" title=\"Export RIS\">RIS</a>\n\t\t</span>\n\t</p>\n<!-- End Export citation and abstract tools -->\n<!-- Start AAS Related Links -->\n<div class=\"reveal-container reveal-closed reveal-plus-icon bdt-1 mt-2 mb-2 wd-jnl-art-article-aas-related-links\">\n  <div class=\"replica-h3 mt-0\">\n    <a href=\"#\" class=\"reveal-trigger\" data-reveal-label-alt=\"Hide related links\">Related links</a>\n  </div>\n  <div class=\"reveal-content\">\n    <div class=\"article-meta\"> \n      <ul>\n      \t<li><a href=\"http://adsabs.harvard.edu/abs/2018ApJ...856...68P\" target=\"_blank\">NASA ADS Record <span class=\"icon-newtab\"></span></a></li>\n      \t<li><a href=\"http://simbad.u-strasbg.fr/simbad/sim-ref?querymethod=bib&simbo=on&bibcode=2018ApJ...856...68P\" target=\"_blank\">Simbad Objects <span class=\"icon-newtab\"></span></a></li>\n      \t<li><a href=\"/journal/0004-637X/page/About%20Related%20Links\" target=\"_blank\">About Related Links</a></li>\n      \t</ul>\n    </div>\n  </div>\n</div>\n<!-- Start info bottom -->\n    <!-- End info bottom -->\n<!-- Start article full text -->\n\t<div xmlns:book=\"http://api.iop.org/Book/1.0/\" itemprop=\"articleBody\" class=\"wd-jnl-art-full-text article-text\">\n<h2 class=\"header-anchor\" id=\"apjaaae6as1\" name=\"apjaaae6as1\">1.\u00a0Introduction</h2><div class=\"article-text\" data-mobile-collapse=\"\"><p>Gravitational lensing, a prediction of Einstein's general theory of relativity, is a very powerful tool in cosmological studies. It has been used extensively to understand various aspects of galaxy formation and evolution (e.g., Refsdal &amp; Bondi <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib45\" id=\"fnref-apjaaae6abib45\">1964</a>; Blandford &amp; Narayan <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib5\" id=\"fnref-apjaaae6abib5\">1992</a>; Postman et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib43\" id=\"fnref-apjaaae6abib43\">2012</a>; Atek et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib4\" id=\"fnref-apjaaae6abib4\">2015</a>; Nayyeri et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib36\" id=\"fnref-apjaaae6abib36\">2016</a>). This involves accurate cosmological parameter estimation (Treu <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib53\" id=\"fnref-apjaaae6abib53\">2010</a>), studies of dark matter distribution from weak gravitational lensing events (Kaiser &amp; Squires <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib22\" id=\"fnref-apjaaae6abib22\">1993</a>; Velander et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib56\" id=\"fnref-apjaaae6abib56\">2014</a>), black hole physics (Peng et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib41\" id=\"fnref-apjaaae6abib41\">2006</a>), and searches for the most distant galaxies (Coe et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib10\" id=\"fnref-apjaaae6abib10\">2012</a>; Oesch et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib38\" id=\"fnref-apjaaae6abib38\">2015</a>), among others.</p><p>One of the main goals of observational cosmology is to constrain the main cosmological parameters that dictate the evolution of the universe (Tegmark et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib51\" id=\"fnref-apjaaae6abib51\">2004</a>; Komatsu et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib25\" id=\"fnref-apjaaae6abib25\">2009</a>; Weinberg et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib58\" id=\"fnref-apjaaae6abib58\">2013</a>). Strong gravitational lensing has been utilized over the past few years to estimate and constrain these cosmological parameters (Broadhurst et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib7\" id=\"fnref-apjaaae6abib7\">2005</a>; Suyu et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib49\" id=\"fnref-apjaaae6abib49\">2013</a>, <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib50\" id=\"fnref-apjaaae6abib50\">2014</a>; Agnello et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib2\" id=\"fnref-apjaaae6abib2\">2017</a>; Goobar et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib16\" id=\"fnref-apjaaae6abib16\">2017</a>; More et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib33\" id=\"fnref-apjaaae6abib33\">2017</a>). This is achieved through accurate lens modeling of such events and comparing the model predictions with observations (such as with observations of lensing induced time delays (Eigenbrod et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib11\" id=\"fnref-apjaaae6abib11\">2005</a>; Treu <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib53\" id=\"fnref-apjaaae6abib53\">2010</a>; Suyu et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib50\" id=\"fnref-apjaaae6abib50\">2014</a>; Rodney et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib46\" id=\"fnref-apjaaae6abib46\">2016</a>; Treu &amp; Marshall <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib54\" id=\"fnref-apjaaae6abib54\">2016</a>). In a recent study, for example, Suyu et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib49\" id=\"fnref-apjaaae6abib49\">2013</a>) used combined WMAP, Keck, and <em>HST</em> data on gravitational time delays in two lensed sources to constrain the Hubble constant within 4% in a \u039bCDM cosmological framework.</p><p>One of the key aspects of gravitational lensing is its use as natural telescopes through boosting the observed signal and increasing the spatial resolution (Treu <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib53\" id=\"fnref-apjaaae6abib53\">2010</a>). This is quite advantageous in searches for distant and/or faint objects at moderate observing costs and has been utilized extensively in various surveys in searches for such objects, the identification of which would not have been possible without it (Bolton et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib6\" id=\"fnref-apjaaae6abib6\">2006</a>; Heymans et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib19\" id=\"fnref-apjaaae6abib19\">2012</a>). Given that the number of identified lenses for different classes of galaxies rises sufficiently due to better lens finding algorithms, one could study the intrinsic properties of distant galaxies from such searches to understand the physics of star formation and mass assembly (Fu et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib13\" id=\"fnref-apjaaae6abib13\">2012</a>; Timmons et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib52\" id=\"fnref-apjaaae6abib52\">2016</a>; Nayyeri et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib35\" id=\"fnref-apjaaae6abib35\">2017</a>; Wilson et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib59\" id=\"fnref-apjaaae6abib59\">2017</a>). In the past few years, deep diffraction limited observations have also taken advantage of gravitational lensing to extend the faint end of the luminosity function of galaxies by a few orders of magnitude (Atek et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib4\" id=\"fnref-apjaaae6abib4\">2015</a>) to produce the deepest images of the sky ever taken across multiple bands. Strong gravitational lensing events have been observed extensively in such surveys as galaxy\u2013galaxy lensing in field surveys such as the Cosmic Assembly Near-infrared Deep Extragalactic Legacy Survey (CANDELS; Grogin et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib17\" id=\"fnref-apjaaae6abib17\">2011</a>; Koekemoer et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib24\" id=\"fnref-apjaaae6abib24\">2011</a>) and the Cosmological Evolution Survey (COSMOS; Capak et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib9\" id=\"fnref-apjaaae6abib9\">2007</a>; Scoville et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib47\" id=\"fnref-apjaaae6abib47\">2007</a>) or as cluster lensing from observations of nearby massive clusters (Postman et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib43\" id=\"fnref-apjaaae6abib43\">2012</a>; Treu et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib55\" id=\"fnref-apjaaae6abib55\">2015</a>; Lotz et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib30\" id=\"fnref-apjaaae6abib30\">2017</a>) with the <em>Hubble</em> Space Telescope leading to the identification of the first generations of galaxies (out to <em>z</em>\u00a0~\u00a011; Oesch et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib38\" id=\"fnref-apjaaae6abib38\">2015</a>) and studies of galaxy formation and evolution at the epoch of reionization. This was, in fact, one of the main motivations behind <em>Hubble</em> cluster lensing studies such as Cluster Lensing and Supernova Survey with Hubble (CLASH; Postman et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib43\" id=\"fnref-apjaaae6abib43\">2012</a>) and the <em>Hubble</em> Frontier Fields (Lotz et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib30\" id=\"fnref-apjaaae6abib30\">2017</a>). The power of gravitational lensing could also be used in the detection of low surface brightness emission from extended objects such as millimeter and radio emissions from dust and molecular gas at <em>z</em>\u00a0~\u00a02\u22123 as observed with ALMA used to study the physics of the cold ISM (Spilker et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib48\" id=\"fnref-apjaaae6abib48\">2016</a>).</p><p>Strongly lensed galaxies are normally targeted and identified from dedicated surveys (Bolton et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib6\" id=\"fnref-apjaaae6abib6\">2006</a>). Traditionally, these lens identifications are either catalog-based, in which lensing events are identified by looking for objects in a lensing configuration, or pixel based, with the search starting from a set of pixels. These lensing searches are normally computationally challenging in that individual pixels are constantly compared with adjacent ones and they could be biased toward a given population and/or brighter objects. Recent far-infrared wide area observations (such as those with <em>Herschel</em>) advanced searches for lensed galaxies by adopting a simple efficient selection technique of lensed candidates through observations of excessive flux in the far-infrared (as an indication of strong lensing events supported by number count distributions; Wardlow et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib57\" id=\"fnref-apjaaae6abib57\">2012</a>; Nayyeri et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib36\" id=\"fnref-apjaaae6abib36\">2016</a>). However, such surveys are also biased toward populations of red dusty star-forming galaxies (missing any blue lenses) and are not always available across the full sky (the <em>Herschel</em> surveys that were targeted had <span xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"inline-eqn\"><span class=\"tex\"><span class=\"texImage\"><img src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6aieqn1.gif\" alt=\"$\\sim 0.2\\mbox{--}0.4\\,{\\deg }^{-2}$\" align=\"top\"></img></span><script type=\"math/tex\">\\sim 0.2\\mbox{--}0.4\\,{\\deg }^{-2}</script></span></span> lensing events, much lower than expected from optical surveys). Given that tests of cosmological models require simple unbiased selection functions, it is important to have a complete unbiased catalog of lensing events.</p><p>We have entered the era of big data astronomy. Sky surveys such as the LSST, <em>Euclid</em>, and <em>WFIRST</em> will produce more imaging data than humans can ever analyze by eye. The challenges of designing such surveys are no longer merely instrumentational, but they also demand powerful data analysis and classification tools that can identify astronomical objects autonomously. Fortunately, computer vision has drastically improved in the last decade making autonomous astronomy possible. The past couple of years has been the most exciting era in the field of machine learning (ML). Researchers from both the public and the private sectors have achieved landmarks in developing image recognition/classification techniques. One of the most exciting recent events in the ML community was the release of <span class=\"small-caps\">TensorFlow</span> by Google, a parallel processing platform designed for development of fast deep learning algorithms (Abadi et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib1\" id=\"fnref-apjaaae6abib1\">2016</a>). Packages and software, such as <span class=\"small-caps\">Mathematica</span>, <span class=\"small-caps\">TensorFlow</span>, <span class=\"small-caps\">Caffe</span>, and others, alongside cheaper and more powerful Graphics Processing Units (GPUs) have enabled researchers to develop very complex and fast classification algorithms. Among these deep learning programs, ConvNets have deservingly received a lot of attention in many fields of science and industry in the past few years (Krizhevsky et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib27\" id=\"fnref-apjaaae6abib27\">2012</a>). Complex ConvNets such as <span class=\"small-caps\">GoogleNet</span> and <span class=\"small-caps\">AlexNet</span>, which are publicly available, have achieved superhuman performance on the task of image classification. Google's <span class=\"small-caps\">TensorFlow</span> has made it possible to easily develop parallelized deep learning algorithms, which, if integrated with Google's Tensor Processing Units (TPUs), could address the data mining challenges in the field of astronomy. In this work, we introduce and image classification algorithm, <span class=\"small-caps\">LensFlow</span>, which is a ConvNet that can be used to search for strong gravitational lenses with the final version of the code publicly available on Github.<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6afn2\">2</a></sup>\n\n</p><p>This paper is organized as follow. In Section <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"secref\" href=\"#apjaaae6as2\">2</a>, we will explain the principal concepts underlying neural networks, supervised learning, and ConvNets. Before feeding the images to a ConvNet, they must be normalized and should be enhanced. The details data extraction and normalization are discussed in Section <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"secref\" href=\"#apjaaae6as3-1\">3.1</a>. As discussed in Section <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"secref\" href=\"#apjaaae6as3-3\">3.3</a>, we explain the architecture of <span class=\"small-caps\">LensFlow</span> and its pretraining process on CIFAR data (Krizhevsky &amp; Hinton <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib26\" id=\"fnref-apjaaae6abib26\">2009</a>). In Sections <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"secref\" href=\"#apjaaae6as3-4\">3.4</a> and <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"secref\" href=\"#apjaaae6as3-5\">3.5</a>, we discuss training <span class=\"small-caps\">LensFlow</span> on COSMOS data and show its performance on recovering known tracer lenses. In Section <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"secref\" href=\"#apjaaae6as3-6\">3.6</a>, we share a set of new lenses found by <span class=\"small-caps\">LensFlow</span> and we conclude our results in Section <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"secref\" href=\"#apjaaae6as4\">4</a>. Throughout this paper, we assume a standard cosmology with <span xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"inline-eqn\"><span class=\"tex\"><span class=\"texImage\"><img src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6aieqn3.gif\" alt=\"${H}_{0}=70\\,{\\mathrm{kms}}^{-1}\\,{\\mathrm{Mpc}}^{-1}$\" align=\"top\"></img></span><script type=\"math/tex\">{H}_{0}=70\\,{\\mathrm{kms}}^{-1}\\,{\\mathrm{Mpc}}^{-1}</script></span></span>, <span xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"inline-eqn\"><span class=\"tex\"><span class=\"texImage\"><img src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6aieqn4.gif\" alt=\"${{\\rm{\\Omega }}}_{m}=0.3$\" align=\"top\"></img></span><script type=\"math/tex\">{{\\rm{\\Omega }}}_{m}=0.3</script></span></span>, and <span xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"inline-eqn\"><span class=\"tex\"><span class=\"texImage\"><img src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6aieqn5.gif\" alt=\"${{\\rm{\\Omega }}}_{{\\rm{\\Lambda }}}=0.7$\" align=\"top\"></img></span><script type=\"math/tex\">{{\\rm{\\Omega }}}_{{\\rm{\\Lambda }}}=0.7</script></span></span>. Magnitudes are in the AB system where <span xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"inline-eqn\"><span class=\"tex\"><span class=\"texImage\"><img src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6aieqn6.gif\" alt=\"${m}_{\\mathrm{AB}}=23.9-2.5\\times \\mathrm{log}({f}_{\\nu }/1\\mu \\mathrm{Jy})$\" align=\"top\"></img></span><script type=\"math/tex\">{m}_{\\mathrm{AB}}=23.9-2.5\\times \\mathrm{log}({f}_{\\nu }/1\\mu \\mathrm{Jy})</script></span></span> (Oke &amp; Gunn <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib39\" id=\"fnref-apjaaae6abib39\">1983</a>).</p></div>\n<h2 class=\"header-anchor\" id=\"apjaaae6as2\" name=\"apjaaae6as2\">2.\u00a0Deep Learning Algorithms</h2><div class=\"article-text\" data-mobile-collapse=\"\"><p>Artificial neural networks are inspired by biological neurons. Just like biological neurons, artificial neurons receive input signals and send out an output signal to other neurons (see Figure <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" href=\"#apjaaae6af1\">1</a>). The synaptic connections between neurons are known as weights and the output of a neuron is known as its activation. To reduce the computational time and simplify neural network models, neurons are placed in consecutive layers rather than having a connection with every other neuron. This neural network setup is known as the Multi-layer Perception where neurons from one layer cannot talk to each other or to the neurons in arbitrary layers; they may only send their signal to the neurons in the succeeding layer. A neuron receives the weighted sum of the activation of all the neurons in the previous layer, adds an internal parameter known as the bias, and maps this sum to a value computed by an activation function (e.g., sigmoid, hyperbolic tangent, rectilinear, softmax). This model can be stated mathematically by the following equation:</p><div xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"display-eqn\" id=\"apjaaae6aeqn1\"><span class=\"tex\"><span class=\"texImage\"><img src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6aeqn1.gif\" alt=\"Equation (1)\"></img></span><script type=\"math/tex; mode=display\">\\begin{eqnarray}&&{a}_{i}^{l}=f\\left(\\displaystyle \\sum _{j}{a}_{j}^{l-1}{w}_{j\\to i}^{l}+{b}_{i}^{l}\\right).\\end{eqnarray}\n\t\t\t\t\\tag{\n\t\t\t\t1\n\t\t\t\t}\n\t\t\t</script></span></div><p>Here, <em>a</em><sub><em>i</em></sub><sup><em>l</em></sup> is the activation of the neuron in hand (i.e., the <em>i</em>th neuron in the <em>l</em>th layer), <em>f</em> is the activation function of this neuron, <span xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"inline-eqn\"><span class=\"tex\"><span class=\"texImage\"><img src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6aieqn7.gif\" alt=\"${a}_{j}^{l-1}$\" align=\"top\"></img></span><script type=\"math/tex\">{a}_{j}^{l-1}</script></span></span> is the activation of the neuron <em>j</em> in layer <em>l</em>\u00a0\u2212\u00a01 (the previous layer), <span xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"inline-eqn\"><span class=\"tex\"><span class=\"texImage\"><img src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6aieqn8.gif\" alt=\"${w}_{j\\to i}^{l}$\" align=\"top\"></img></span><script type=\"math/tex\">{w}_{j\\to i}^{l}</script></span></span> is the synaptic weight connecting the <em>i</em>th neuron in layer <em>l</em> to the <em>j</em>th neuron in layer <em>l</em>\u00a0\u2212\u00a01, and <em>b</em><sub><em>i</em></sub><sup><em>l</em></sup> is the bias of the neuron to adjust its activation sensitivity. The first layer, i.e., the input layer, in a deep learning neural net acts as a sensory layer, analogous to the retina. As it gets analyzed, the information from the input layer travels through multiple layers until it reaches the final layer, called the classification layer. Each class of images corresponds to a classifying neuron. In our case, we have a neuron corresponding to non-lens and another to lens images. The neuron with the highest output determines which class an input image is placed in.</p><figure xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"apjaaae6af1\" tabindex=\"-1\" role=\"group\" class=\"boxout boxout-bdr-grey keyboard-focus-only\" data-toolbar-type=\"figure\" data-toolbar-link=\"apjaaae6af1\" data-toolbar-img=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6af1_lr.jpg\" data-toolbar-title=\"Figure 1.\"><figure><div class=\"panzoom-container\"><div class=\"panzoom-parent\" style=\"overflow: hidden; position: relative;\"><img class=\"panzoom\" alt=\"Figure 1.\" src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6af1_lr.jpg\" style=\"transform: matrix(1, 0, 0, 1, 0, 0); backface-visibility: hidden; transform-origin: 50% 50% 0px; cursor: move; transition: transform 200ms ease-in-out 0s;\"></img></div><div class=\"buttons zoom-tools\"><button class=\"zoom-in\"><span class=\"icon-zoomin\"></span>\n\t                 Zoom In\n\t\t\t\t</button><button class=\"zoom-out\"><span class=\"icon-zoomout\"></span>\n\t                 Zoom Out\n\t\t\t\t</button><span class=\"mobile-block\"><button class=\"reset\"><span class=\"icon-loop\"></span>\n\t                     Reset image size\n\t\t\t\t\t</button></span></div></div><figcaption><div class=\"article-text figure-caption\"><p><strong>Figure 1.</strong>\u00a0Schematic representation of an artificial neuron. The weighted sum of the neurons in the previous layer (green circles), plus the internal bias of the neuron, are mapped as the output of the neuron by an activation function. This model is captured by Equation (<a class=\"eqnref\" href=\"#apjaaae6aeqn1\">1</a>). During the learning process, weights and biases of the neurons will be adjusted to achieve the desired network output.</p></div><p class=\"mb-05 print-hide\">Download figure:</p><span class=\"btn-multi-block print-hide\"><a class=\"btn btn-primary fig-dwnld-std-img\" id=\"wd-jnl-art-btn-std-img-apjaaae6af1\" href=\"/0004-637X/856/1/68/downloadFigure/figure/apjaaae6af1\"><span class=\"icon-image\"></span> Standard image\n\t\t\t\t\t</a><a class=\"btn btn-primary fig-dwnld-hi-img\" id=\"wd-jnl-art-btn-hires-img-apjaaae6af1\" href=\"/0004-637X/856/1/68/downloadHRFigure/figure/apjaaae6af1\"><span class=\"icon-image\"></span> High-resolution image\n\t\t\t\t\t</a></span></figcaption></figure></figure><p>A neural net learns how to classify images by adjusting the weights between its neurons and the biases within them, having one goal in mind: minimizing the loss function <span xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"inline-eqn\"><span class=\"tex\"><span class=\"texImage\"><img src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6aieqn9.gif\" alt=\"$C({\\boldsymbol{x}},{\\boldsymbol{y}})$\" align=\"top\"></img></span><script type=\"math/tex\">C({\\boldsymbol{x}},{\\boldsymbol{y}})</script></span></span>. The loss function, sometimes called the cost function, can take many forms but it has to capture the misfiring of the classification neurons, i.e., the deviation between the target class versus the predicted class. This is why such algorithms are known as supervised learning algorithms, in contrast to unsupervised techniques. A common choice for the loss function is the cross-entropy loss function with the following form (Nielsen <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib37\" id=\"fnref-apjaaae6abib37\">2016</a>):</p><div xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"display-eqn\" id=\"apjaaae6aeqn2\"><span class=\"tex\"><span class=\"texImage\"><img src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6aeqn2.gif\" alt=\"Equation (2)\"></img></span><script type=\"math/tex; mode=display\">\\begin{eqnarray}&&C({\\boldsymbol{x}},{\\boldsymbol{y}})={\\sum }_{j=\\text{non-lens},\\mathrm{lens}}{y}_{j}\\mathrm{ln}{a}_{j}^{L}+(1-{y}_{j})\\mathrm{ln}(1-{a}_{j}^{L}).\\end{eqnarray}\n\t\t\t\t\\tag{\n\t\t\t\t2\n\t\t\t\t}\n\t\t\t</script></span></div><p><em>a</em><sub><em>j</em></sub><sup><em>L</em></sup> is the activation of neurons in the final (classifying) layer, <span xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"inline-eqn\"><span class=\"tex\"><span class=\"texImage\"><img src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6aieqn10.gif\" alt=\"${\\boldsymbol{x}}$\" align=\"top\"></img></span><script type=\"math/tex\">{\\boldsymbol{x}}</script></span></span> is the input data in the vector form, and <span xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"inline-eqn\"><span class=\"tex\"><span class=\"texImage\"><img src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6aieqn11.gif\" alt=\"${\\boldsymbol{y}}$\" align=\"top\"></img></span><script type=\"math/tex\">{\\boldsymbol{y}}</script></span></span> represents the desired activations of the two classifying neurons. Of course, this function depends on the architecture of the neural net, weights, and biases, but they have not been expressed explicitly. As an example, if an image is a lens, its target output has to be (0.0, 1.0), meaning the activation of the non-lens neuron should be zero and the activation of the lens neuron should be unity. During the training process of a neural net, images from a training data set are presented to the network and the weights and the biases are adjusted to minimize the loss function for those images. The parameter space is massive and a change in one of the parameters of a neuron will affect the activation of a series of neurons in other layers. The first challenge is solved by minimizing algorithms such as the stochastic gradient descent (SGD) and the second one is solved via back-propagation. Since optimizing over the whole training set at once is not possible, because the training data would not fit in memory, stochastic optimization algorithms provide guaranteed convergence even if the gradients are evaluated on a randomly (stochastically) selected subset (batch) of the training data set. They provide a practical way to optimize a model over extremely large data sets. Batches yield noisy approximations to the true gradient, and larger batches can better approximate this quantity while if the batch size is too small, that approximation would be too poor and the algorithm may never converge in practice.</p><p>ConvNets are a class of neural networks with multiple convolutional layers. A convolutional layer consists of a set of convolving neurons (on the order of 10 neurons) that can be connected to a small rectangular region of an image. The set of weights of a convolving neuron is known as a filter and is subject to change as the ConvNet learns. A filter scans an entire image by striding (convolving with specified steps) over the image and assembling its output into an image, which is known as a feature map. Feature maps contain information such as texture and edges. See Figure <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" href=\"#apjaaae6af2\">2</a> as an example of a set of filters in a <span class=\"small-caps\">LensFlow</span> convolutional layer. A few examples of feature maps have been shown in Figure <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" href=\"#apjaaae6af3\">3</a>. These feature maps are bundled together as an image with the same number of channels as the number of feature maps. In this image, we have selected three feature maps and represent them with different colors to display what the neural network sees as the image passes through the layers.</p><figure xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"apjaaae6af2\" tabindex=\"-1\" role=\"group\" class=\"boxout boxout-bdr-grey keyboard-focus-only\" data-toolbar-type=\"figure\" data-toolbar-link=\"apjaaae6af2\" data-toolbar-img=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6af2_lr.jpg\" data-toolbar-title=\"Figure 2.\"><figure><div class=\"panzoom-container\"><div class=\"panzoom-parent\" style=\"overflow: hidden; position: relative;\"><img class=\"panzoom\" alt=\"Figure 2.\" src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6af2_lr.jpg\" style=\"transform: matrix(1, 0, 0, 1, 0, 0); backface-visibility: hidden; transform-origin: 50% 50% 0px; cursor: move; transition: transform 200ms ease-in-out 0s;\"></img></div><div class=\"buttons zoom-tools\"><button class=\"zoom-in\"><span class=\"icon-zoomin\"></span>\n\t                 Zoom In\n\t\t\t\t</button><button class=\"zoom-out\"><span class=\"icon-zoomout\"></span>\n\t                 Zoom Out\n\t\t\t\t</button><span class=\"mobile-block\"><button class=\"reset\"><span class=\"icon-loop\"></span>\n\t                     Reset image size\n\t\t\t\t\t</button></span></div></div><figcaption><div class=\"article-text figure-caption\"><p><strong>Figure 2.</strong>\u00a0Examples of filters used in a convolutional layer. The pixels in each box represent the weights of a convolving neuron that are connected to a 5\u00a0<b>&#x00d7;</b>\u00a05 region input image. As these filters convolve over the entire input image, they generate feature maps. Red pixels have a positive contribution and blue pixels have a negative contribution toward the activation of the convolving neuron. These filters are helpful for edge and texture recognition.</p></div><p class=\"mb-05 print-hide\">Download figure:</p><span class=\"btn-multi-block print-hide\"><a class=\"btn btn-primary fig-dwnld-std-img\" id=\"wd-jnl-art-btn-std-img-apjaaae6af2\" href=\"/0004-637X/856/1/68/downloadFigure/figure/apjaaae6af2\"><span class=\"icon-image\"></span> Standard image\n\t\t\t\t\t</a><a class=\"btn btn-primary fig-dwnld-hi-img\" id=\"wd-jnl-art-btn-hires-img-apjaaae6af2\" href=\"/0004-637X/856/1/68/downloadHRFigure/figure/apjaaae6af2\"><span class=\"icon-image\"></span> High-resolution image\n\t\t\t\t\t</a></span></figcaption></figure></figure><figure xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"apjaaae6af3\" tabindex=\"-1\" role=\"group\" class=\"boxout boxout-bdr-grey keyboard-focus-only\" data-toolbar-type=\"figure\" data-toolbar-link=\"apjaaae6af3\" data-toolbar-img=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6af3_lr.jpg\" data-toolbar-title=\"Figure 3.\"><figure><div class=\"panzoom-container\"><div class=\"panzoom-parent\" style=\"overflow: hidden; position: relative;\"><img class=\"panzoom\" alt=\"Figure 3.\" src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6af3_lr.jpg\" style=\"transform: matrix(1, 0, 0, 1, 0, 0); backface-visibility: hidden; transform-origin: 50% 50% 0px; cursor: move; transition: transform 200ms ease-in-out 0s;\"></img></div><div class=\"buttons zoom-tools\"><button class=\"zoom-in\"><span class=\"icon-zoomin\"></span>\n\t                 Zoom In\n\t\t\t\t</button><button class=\"zoom-out\"><span class=\"icon-zoomout\"></span>\n\t                 Zoom Out\n\t\t\t\t</button><span class=\"mobile-block\"><button class=\"reset\"><span class=\"icon-loop\"></span>\n\t                     Reset image size\n\t\t\t\t\t</button></span></div></div><figcaption><div class=\"article-text figure-caption\"><p><strong>Figure 3.</strong>\u00a0Examples of a convolutional layer feature maps. An image of a normalized physical lens has been shown in (1). ((2)\u2013(4)) Three outputs of the second convolution layer of <span class=\"small-caps\">LensFlow</span>. (5) The superposition of these three maps. As can be seen in (5), these feature maps create a contrast between the upper arc and the foreground source, making it possible for the fully connected layers to decide whether an imaged is a lens or a non-lens.</p></div><p class=\"mb-05 print-hide\">Download figure:</p><span class=\"btn-multi-block print-hide\"><a class=\"btn btn-primary fig-dwnld-std-img\" id=\"wd-jnl-art-btn-std-img-apjaaae6af3\" href=\"/0004-637X/856/1/68/downloadFigure/figure/apjaaae6af3\"><span class=\"icon-image\"></span> Standard image\n\t\t\t\t\t</a><a class=\"btn btn-primary fig-dwnld-hi-img\" id=\"wd-jnl-art-btn-hires-img-apjaaae6af3\" href=\"/0004-637X/856/1/68/downloadHRFigure/figure/apjaaae6af3\"><span class=\"icon-image\"></span> High-resolution image\n\t\t\t\t\t</a></span></figcaption></figure></figure></div>\n<h2 class=\"header-anchor\" id=\"apjaaae6as3\" name=\"apjaaae6as3\">3.\u00a0Methodology</h2><div class=\"article-text\" data-mobile-collapse=\"\"><p>This section covers the image normalization process, simulation of gravitational lenses and training and testing data set creation, architecture of <span class=\"small-caps\">LensFlow</span>, its pretraining on CIFAR data set, and its training on COSMOS data in two sequential steps: course and fine classification phases.</p><h3 id=\"apjaaae6as3-1\" name=\"apjaaae6as3-1\">3.1.\u00a0Data Extraction and Normalization</h3><div class=\"article-text\"><p>We used <em>HST</em>/ACS i-band observations in the full COSMOS field to search for candidate gravitationally lensed sources. In order to prepare the survey data for the neural network, we created 200\u00a0<b>&#x00d7;</b>\u00a0200 pixel cutouts around sources identified by <span class=\"small-caps\">SExtractor</span>, which corresponds to roughly 3\u00a0<b>&#x00d7;</b>\u00a03 square arcseconds. We ignored sources that extended less than 200 pixels total (not to be confused with our cutout size) and were not 1.5<em>\u03c3</em> brighter than the background, totaling 236,000 images. These images were then downsampled to 100\u00a0<b>&#x00d7;</b>\u00a0100 pixels to speed up the training and scanning process.</p><p>Before inputting the images to <span class=\"small-caps\">LensFlow</span>, we normalized and enhanced them, which is a necessary step to ensure a stable training and prevents activation saturation issues. For deep learning purposes, there are different methods of image normalization to choose from. This is due to the fact that raw image pixels come in a wide range of values. As we will discuss in the next section, when lenses are produced by superposing simulated arcs on top of actual sources, it is crucially important to ensure that superposed images are renormalized after the superposition process. If lens images are not renormalized, the net will become sensitive to the total sum of the pixels and achieve a meaningless perfect classification on the training and test data sets with no application for searching for real lens images.</p><p>There are different methods of image normalization used that often involve shifting the mean, normalizing the standard deviation, and bounding the pixels between two fixed values. Though sufficient for classification of daily object photos, we did not find these methods helpful to our algorithm since astronomical images require gamma correction to adjust the image contrast. Gamma correction introduces a nonlinearity according to the following equation:</p><div xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"display-eqn\" id=\"apjaaae6aeqn3\"><span class=\"tex\"><span class=\"texImage\"><img src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6aeqn3.gif\" alt=\"Equation (3)\"></img></span><script type=\"math/tex; mode=display\">\\begin{eqnarray}&&{p}_{\\mathrm{out}}={{Ap}}_{\\mathrm{in}}^{\\gamma },\\end{eqnarray}\n\t\t\t\t\\tag{\n\t\t\t\t3\n\t\t\t\t}\n\t\t\t</script></span></div><p>where <em>A</em> and <em>\u03b3</em> are constants and <em>p</em><sub>in</sub> and <em>p</em><sub>out</sub> are the initial and corrected pixel values. However, applying the same gamma function to different sources is not practical. For instance, the arcs in some lens images might get enhanced, while they are obscured by the foreground in other images. Similar problems happen when cutting off bright and dim pixels. To overcome these issue, we have selected one dim real lens image and have adjusted its brightness, its contrast, and have performed gamma correction so the foreground source and the arcs are clearly separated and visible, while keeping all pixel values between 0 and 1. The image histogram (the histogram of pixel values) of this modified lens image was extracted (See Figure <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" href=\"#apjaaae6af4\">4</a>) and was used as a template histogram to transform the image histogram of all the extracted sources. This method not only enhances the arcs for all the previously known lenses from COSMOS, but it also automates the process of gamma correction and normalization since all pixel values fall between 0 and 1 and their mean and their standard deviation are roughly the same.</p><figure xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"apjaaae6af4\" tabindex=\"-1\" role=\"group\" class=\"boxout boxout-bdr-grey keyboard-focus-only\" data-toolbar-type=\"figure\" data-toolbar-link=\"apjaaae6af4\" data-toolbar-img=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6af4_lr.jpg\" data-toolbar-title=\"Figure 4.\"><figure><div class=\"panzoom-container\"><div class=\"panzoom-parent\" style=\"overflow: hidden; position: relative;\"><img class=\"panzoom\" alt=\"Figure 4.\" src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6af4_lr.jpg\" style=\"transform: matrix(1, 0, 0, 1, 0, 0); backface-visibility: hidden; transform-origin: 50% 50% 0px; cursor: move; transition: transform 200ms ease-in-out 0s;\"></img></div><div class=\"buttons zoom-tools\"><button class=\"zoom-in\"><span class=\"icon-zoomin\"></span>\n\t                 Zoom In\n\t\t\t\t</button><button class=\"zoom-out\"><span class=\"icon-zoomout\"></span>\n\t                 Zoom Out\n\t\t\t\t</button><span class=\"mobile-block\"><button class=\"reset\"><span class=\"icon-loop\"></span>\n\t                     Reset image size\n\t\t\t\t\t</button></span></div></div><figcaption><div class=\"article-text figure-caption\"><p><strong>Figure 4.</strong>\u00a0Template image histogram for image normalization. The histograms of all sources were transformed to match this template histogram, which was obtained by adjusting the brightness and the contrast and by performing gamma correction for a known dim lens image displayed above. This transformation not only normalizes images, but it will also enhance the contrast between the arcs and the foreground source.</p></div><p class=\"mb-05 print-hide\">Download figure:</p><span class=\"btn-multi-block print-hide\"><a class=\"btn btn-primary fig-dwnld-std-img\" id=\"wd-jnl-art-btn-std-img-apjaaae6af4\" href=\"/0004-637X/856/1/68/downloadFigure/figure/apjaaae6af4\"><span class=\"icon-image\"></span> Standard image\n\t\t\t\t\t</a><a class=\"btn btn-primary fig-dwnld-hi-img\" id=\"wd-jnl-art-btn-hires-img-apjaaae6af4\" href=\"/0004-637X/856/1/68/downloadHRFigure/figure/apjaaae6af4\"><span class=\"icon-image\"></span> High-resolution image\n\t\t\t\t\t</a></span></figcaption></figure></figure></div><h3 id=\"apjaaae6as3-2\" name=\"apjaaae6as3-2\">3.2.\u00a0Lens Simulation</h3><div class=\"article-text\"><p>In order to train a neural network, typically a few thousand examples are needed per class. Since the number of known lenses are far more limited than the required number, these lenses have to be simulated. For these simulations, we used <span class=\"small-caps\">lenstool</span> (Jullo et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib21\" id=\"fnref-apjaaae6abib21\">2007</a>) to generate image plane models of lensing systems using realistic models of randomly selected elliptical galaxies within the COSMOS field as deflectors and coadded these to the selected elliptical galaxies to generate the training set. Here, we focus on elliptical galaxies as foreground deflectors. Although known examples of spiral galaxy lensing exist (Calanog et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib8\" id=\"fnref-apjaaae6abib8\">2014</a>), most galaxy\u2013galaxy lensing events occur around massive elliptical galaxies as foreground deflectors. We generated a training set of 200 galaxies using this method. Figure <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" href=\"#apjaaae6af5\">5</a> shows several examples from the generated training set used by <span class=\"small-caps\">LensFlow</span>.</p><figure xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"apjaaae6af5\" tabindex=\"-1\" role=\"group\" class=\"boxout boxout-bdr-grey keyboard-focus-only\" data-toolbar-type=\"figure\" data-toolbar-link=\"apjaaae6af5\" data-toolbar-img=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6af5_lr.jpg\" data-toolbar-title=\"Figure 5.\"><figure><div class=\"panzoom-container\"><div class=\"panzoom-parent\" style=\"overflow: hidden; position: relative;\"><img class=\"panzoom\" alt=\"Figure 5.\" src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6af5_lr.jpg\" style=\"transform: matrix(1, 0, 0, 1, 0, 0); backface-visibility: hidden; transform-origin: 50% 50% 0px; cursor: move; transition: transform 200ms ease-in-out 0s;\"></img></div><div class=\"buttons zoom-tools\"><button class=\"zoom-in\"><span class=\"icon-zoomin\"></span>\n\t                 Zoom In\n\t\t\t\t</button><button class=\"zoom-out\"><span class=\"icon-zoomout\"></span>\n\t                 Zoom Out\n\t\t\t\t</button><span class=\"mobile-block\"><button class=\"reset\"><span class=\"icon-loop\"></span>\n\t                     Reset image size\n\t\t\t\t\t</button></span></div></div><figcaption><div class=\"article-text figure-caption\"><p><strong>Figure 5.</strong>\u00a0Examples of simulated lenses.</p></div><p class=\"mb-05 print-hide\">Download figure:</p><span class=\"btn-multi-block print-hide\"><a class=\"btn btn-primary fig-dwnld-std-img\" id=\"wd-jnl-art-btn-std-img-apjaaae6af5\" href=\"/0004-637X/856/1/68/downloadFigure/figure/apjaaae6af5\"><span class=\"icon-image\"></span> Standard image\n\t\t\t\t\t</a><a class=\"btn btn-primary fig-dwnld-hi-img\" id=\"wd-jnl-art-btn-hires-img-apjaaae6af5\" href=\"/0004-637X/856/1/68/downloadHRFigure/figure/apjaaae6af5\"><span class=\"icon-image\"></span> High-resolution image\n\t\t\t\t\t</a></span></figcaption></figure></figure><p>As discussed in the previous section, simulated lenses must be renormalized to prevent the net from classifying lenses based on the total sum of the pixels since without normalization, the total pixel sum of lens images will always be higher than non-lens images.</p><p>The number of generated lenses is still very low for training purposes. To overcome this, we can use image augmentation to artificially boost the number of training examples. We do this by rotating and reflecting images. In more detail, we use eight transformations that come from eight elements of the symmetry group of the square, namely: 0\u00b0, 90\u00b0, 180\u00b0, and 270\u00b0 rotations, and horizontal, vertical, diagonal, and anti-diagonal reflections. In addition to rotation and to reflection, we take eight 90\u00a0<b>&#x00d7;</b>\u00a090 pixel cutouts at random positions and rescale them to 100\u00a0<b>&#x00d7;</b>\u00a0100 pixels. We will refer to these two processes as image augmentation.</p></div><h3 id=\"apjaaae6as3-3\" name=\"apjaaae6as3-3\">3.3.\u00a0Architecture of <span class=\"small-caps\">LensFlow</span> ConvNet and Pretraining (Phase 0)</h3><div class=\"article-text\"><p>The architecture of the data determines the dimensionality of the ConvNet layers. We use 1\u00a0<b>&#x00d7;</b>\u00a0100\u00a0<b>&#x00d7;</b>\u00a0100 images, where 1 indicates the number of color channels.<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6afn3\">3</a></sup>\n Classifying lenses with multiple color bands will be easier and more accurate since foreground and background sources have a color contrast. However, we have chosen to use one color channel so our algorithm can be sensitive to geometry rather than color contrast in order to expand its applicability to a wider range of bands as well as eliminating its need for multiband images when unavailable. The results of galaxy lens identification from wide-area surveys with color information will appear in a future work (M. Pourrahmani et al. 2018 in preparation). As we see in Figure <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" href=\"#apjaaae6af6\">6</a> and Table <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"tabref\" href=\"#apjaaae6at1\">1</a>, after normalizing these single-channeled images, <span class=\"small-caps\">LensFlow</span> applies an average-pooling of a kernel of size 5\u00a0<b>&#x00d7;</b>\u00a05 and a stride of 1 without padding. The hyperbolic tangent function introduces nonlinearity to the convolution layer. The common choice is often a rectified linear unit (ReLU), which sets pixels smaller than a self-learned threshold to zero. ReLU is ideal for edge detection but since astronomical images do not have hard edges, an smoother function like the hyperbolic tangent is suited. The output of this layer is fed to a pooling layer with a kernel of size 2\u00a0<b>&#x00d7;</b>\u00a02 and a stride of 1, outputting the largest pixel value as it convolves its input for all channels. The result of this layer is a set of 30 downsampled (48 <b>&#x00d7;</b> 48) feature maps. The next two convolution layers are identical to the first set described above except that the second convolution layer has 60 and the last convolution layer has 90 filters. The output of the last convolution layer is a set of 90\u00a0<b>&#x00d7;</b>\u00a09\u00a0<b>&#x00d7;</b>\u00a09 feature maps, which are flattened from a tensor to a 1D vector with 7290 rows, which is fed to the fully connected layers. The first fully connected layer has 1000 linear neurons (identity function as <em>f</em> in Equation (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"eqnref\" href=\"#apjaaae6aeqn1\">1</a>)). This layer is followed by a dropout layer where the output of 50% of the neurons is set to zero. Dropout layers prevent overfitting in early stages of training. Two more linear layers of size 800 and 600 follow this layer. Finally, all inputs are fed to a linear layer of size two with a softmax nonlinearity. These two layers act as a classifying layer where the softmax layer converts the output of the linear layer to probabilities:</p><div xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"display-eqn\" id=\"apjaaae6aeqn4\"><span class=\"tex\"><span class=\"texImage\"><img src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6aeqn4.gif\" alt=\"Equation (4)\"></img></span><script type=\"math/tex; mode=display\">\\begin{eqnarray}&&{\\sigma }_{c}({\\boldsymbol{Z}})=\\displaystyle \\frac{{e}^{{Z}_{c}}}{{e}^{{Z}_{\\mathrm{non} \\mbox{-} \\mathrm{lens}}}+{e}^{{Z}_{\\mathrm{lens}}}}.\\end{eqnarray}\n\t\t\t\t\\tag{\n\t\t\t\t4\n\t\t\t\t}\n\t\t\t</script></span></div><p>Here, each component of <span xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"inline-eqn\"><span class=\"tex\"><span class=\"texImage\"><img src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6aieqn12.gif\" alt=\"${\\boldsymbol{Z}}$\" align=\"top\"></img></span><script type=\"math/tex\">{\\boldsymbol{Z}}</script></span></span> is the output of the last linear layer (i.e., output of Layer 20) with two components. <em>c</em> specifies whether we are talking about the neuron corresponding to lens or non-lens images. The softmax function ensures the output sums to one and when used with the cross-entropy loss function, these outputs are interpreted as class probabilities. We use these probabilities to rank images from most probable lens candidates to least probable.</p><figure xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"apjaaae6af6\" tabindex=\"-1\" role=\"group\" class=\"boxout boxout-bdr-grey keyboard-focus-only\" data-toolbar-type=\"figure\" data-toolbar-link=\"apjaaae6af6\" data-toolbar-img=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6af6_lr.jpg\" data-toolbar-title=\"Figure 6.\"><figure><div class=\"panzoom-container\"><div class=\"panzoom-parent\" style=\"overflow: hidden; position: relative;\"><img class=\"panzoom\" alt=\"Figure 6.\" src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6af6_lr.jpg\" style=\"transform: matrix(1, 0, 0, 1, 0, 0); backface-visibility: hidden; transform-origin: 50% 50% 0px; cursor: move; transition: transform 200ms ease-in-out 0s;\"></img></div><div class=\"buttons zoom-tools\"><button class=\"zoom-in\"><span class=\"icon-zoomin\"></span>\n\t                 Zoom In\n\t\t\t\t</button><button class=\"zoom-out\"><span class=\"icon-zoomout\"></span>\n\t                 Zoom Out\n\t\t\t\t</button><span class=\"mobile-block\"><button class=\"reset\"><span class=\"icon-loop\"></span>\n\t                     Reset image size\n\t\t\t\t\t</button></span></div></div><figcaption><div class=\"article-text figure-caption\"><p><strong>Figure 6.</strong>\u00a0Representation of data flow through the ConvNet layers. The data is downsampled and fed to three convolutional-max-pooling layers. The data is then flattened into an array and is fed to three fully connected linear layers, which are then connected to the classifying layers consisting of a linear layer with two neurons followed by a sofmax layer. The convolution layers are responsible for feature extraction and the fully connected layers learn the difference between non-lens and lens images.</p></div><p class=\"mb-05 print-hide\">Download figure:</p><span class=\"btn-multi-block print-hide\"><a class=\"btn btn-primary fig-dwnld-std-img\" id=\"wd-jnl-art-btn-std-img-apjaaae6af6\" href=\"/0004-637X/856/1/68/downloadFigure/figure/apjaaae6af6\"><span class=\"icon-image\"></span> Standard image\n\t\t\t\t\t</a><a class=\"btn btn-primary fig-dwnld-hi-img\" id=\"wd-jnl-art-btn-hires-img-apjaaae6af6\" href=\"/0004-637X/856/1/68/downloadHRFigure/figure/apjaaae6af6\"><span class=\"icon-image\"></span> High-resolution image\n\t\t\t\t\t</a></span></figcaption></figure></figure><div tabindex=\"-1\" id=\"apjaaae6at1\" class=\"boxout boxout-bdr-grey keyboard-focus-only\"><p><b>Table 1.</b>\u00a0\nTabulated Architecture of the <span class=\"small-caps\">LensFlow</span> ConvNet\n</p><table cellpadding=\"0\" cellspacing=\"0\" border=\"0\" data-toolbar-link=\"apjaaae6at1\" data-toolbar-img=\"/0004-637X/856/1/68/suppdata/apjaaae6at1_lr.gif\" data-toolbar-type=\"table\" data-toolbar-title=\"Table 1\"><colgroup><col align=\"left\"></col><col align=\"left\"></col><col align=\"left\"></col></colgroup><thead>\n<tr valign=\"top\">\n<th scope=\"col\" colspan=\"1\" rowspan=\"1\" align=\"left\">Layer</th>\n<th scope=\"col\" colspan=\"1\" rowspan=\"1\" align=\"left\">Type</th>\n<th scope=\"col\" colspan=\"1\" rowspan=\"1\" align=\"center\">Data Dimensionality</th>\n</tr>\n</thead><tbody>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">\u00a0</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">input</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">1\u00a0<b>&#x00d7;</b>\u00a0100\u00a0<b>&#x00d7;</b>\u00a0100</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">1</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">convolution</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">30\u00a0<b>&#x00d7;</b>\u00a096\u00a0<b>&#x00d7;</b>\u00a096</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">2</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">tanh</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">30\u00a0<b>&#x00d7;</b>\u00a096\u00a0<b>&#x00d7;</b>\u00a096</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">3</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">pooling</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">30\u00a0<b>&#x00d7;</b>\u00a048\u00a0<b>&#x00d7;</b>\u00a048</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">4</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">convolution</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">60\u00a0<b>&#x00d7;</b>\u00a044\u00a0<b>&#x00d7;</b>\u00a044</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">5</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">tanh</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">60\u00a0<b>&#x00d7;</b>\u00a044\u00a0<b>&#x00d7;</b>\u00a044</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">6</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">pooling</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">60\u00a0<b>&#x00d7;</b>\u00a022\u00a0<b>&#x00d7;</b>\u00a022</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">7</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">convolution</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">90\u00a0<b>&#x00d7;</b>\u00a018\u00a0<b>&#x00d7;</b>\u00a018</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">8</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">tanh</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">90\u00a0<b>&#x00d7;</b>\u00a018\u00a0<b>&#x00d7;</b>\u00a018</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">9</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">pooling</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">90\u00a0<b>&#x00d7;</b>\u00a09\u00a0<b>&#x00d7;</b>\u00a09</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">10</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">flatten</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">7290</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">11</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">linear</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">1000</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">12</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">ReLU</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">1000</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">13</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">dropout</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">1000</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">14</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">linear</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">800</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">15</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">ReLU</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">800</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">16</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">dropout</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">800</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">17</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">linear</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">600</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">18</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">ReLU</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">600</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">19</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">dropout</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">600</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">20</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">linear</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">2</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">21</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">softmax</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">2</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">\u00a0</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">output</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">2</td>\n</tr>\n</tbody></table><p class=\"franklin fs-16\">\n\t\t\tDownload table as:\u00a0\n            <span class=\"btn-multi-block\"><a class=\"btn btn-primary wd-jnl-art-btn-ascii\" href=\"/0004-637X/856/1/68/suppdata/apjaaae6at1_ascii.txt?doi=10.3847/1538-4357/aaae6a\" target=\"_blank\">ASCII</a><a class=\"btn btn-primary wd-jnl-art-btn-typeset typeset-table-img\" href=\"/0004-637X/856/1/68/suppdata/apjaaae6at1_lr.gif\" target=\"_blank\">Typeset image</a></span></p></div><p>To optimize our ConvNet, we have chosen a cross-entropy function as our loss function, which we minimize using the Adam Optimizer. This adaptive optimizer algorithm computes individual adaptive learning rates for different parameters from estimates of first and second moments of the gradients for the loss function (Kingma &amp; Ba <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib23\" id=\"fnref-apjaaae6abib23\">2014</a>). During the training phase, 64 non-lens and 64 lens images were placed in a batch of 128 images. This combination technique will prevent under- or over-representation of classes even if the training size for different classes contains a different number of examples.</p><p>A common practice for training a neural net on a smaller data set is to first pretrain it on a different but larger data set and later, retrain it on the main but smaller data set in hand, while keeping the weights and biases in the convolution layers stiff or fixed by dampening the learning rate. This is valid since these layers are used for general feature extraction. On the other hand, these parameters are relaxed in the fully connected layers where the main task of classification takes place. This technique is known as transfer learning. We have selected two classes from the CIFAR data set, a famous data set used for testing computer vision algorithms. After reducing the images to grayscale and changing their size to 100\u00a0<b>&#x00d7;</b>\u00a0100 pixels, we applied the image normalization explained above. Before training, it is important to properly initialize the weights and biases. While setting all biases to zero, we use the Xavier method (Glorot &amp; Bengio <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib15\" id=\"fnref-apjaaae6abib15\">2010</a>) where the neuron weights in layer <em>L</em> are sampled from a normal distribution with a mean of zero and a variance of 2/(<em>N</em><sup><em>L</em></sup>\u00a0+\u00a0<em>N</em><sup><em>L</em>+1</sup>), where <em>N</em><sup><em>L</em></sup> is the size of layer <em>L</em>. Xavier weight initialization addresses the vanishing gradient problem and prevents the existence of overly strong or overly weak weights resulting in a steady signal throughout the network. After initializing, an initial learning rate of <span xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"inline-eqn\"><span class=\"tex\"><span class=\"texImage\"><img src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6aieqn13.gif\" alt=\"$8.\\times {10}^{-4}$\" align=\"top\"></img></span><script type=\"math/tex\">8.\\times {10}^{-4}</script></span></span> was chosen and the network was trained for a total of eight rounds. The number of iteration rounds is determined by the deviation of the loss function for training and test data sets. It is an indication of overfitting if the average loss function for the training data set drops while it remains the same or increases for the test data set. In simpler terms, overfitting means the net is memorizing the training data set rather than learning generalizable feature extraction and classification. Similarly, we determine the number of iteration rounds for other training phases discussed in the following two subsections. Pretraining is crucial for our data set without which no learning occurs. We suspect that having soft edges as well as a central dominant object are the main causes of the trouble here, preventing the network from learning edge detection and picking up on arc-like features. Techniques such as reducing the brightness of central pixels were tested that triggered the learning process even though with a poor performance. However, by using a pretrained net, the need for masking the central bright pixels was eliminated and a much better performance was achieved.</p></div><h3 id=\"apjaaae6as3-4\" name=\"apjaaae6as3-4\">3.4.\u00a0Coarse Classification Phase (Phase 1)</h3><div class=\"article-text\"><p>The training data set for this phase consists of 3200 lenses created by augmenting the 200 simulated lenses and randomly selecting 3200 images from COSMOS. It is possible that these randomly selected images contain actual lenses, but a few misclassified examples will not affect the training process in a noticeable way. To generate a validation and a testing data set, we have selected 52 out of 67 discovered lens candidates by Faure et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib12\" id=\"fnref-apjaaae6abib12\">2008</a>) and have applied image augmentation (rotations and reflections only) to increase their number to 464, which were accompanied by 464 randomly selected images from COSMOS labeled as non-lens images. Among the lens candidates that were not selected, three were larger than 3 arcseconds in diameter, one did not have an i-band image, and the rest did not have any arc features in the i-band and were classified as lenses by Faure et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib12\" id=\"fnref-apjaaae6abib12\">2008</a>) by mainly relying on other bands.</p><p>Since the convolution layers of the pretrained net (layers 1 to 10 in Table <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"tabref\" href=\"#apjaaae6at1\">1</a>) are used for feature extraction and are transferable from one data set to another, during the training process on COSMOS data, the learning rate of those layers were reduced to 10 %. On the other hand, the main purpose of the fully connected layers are to classify based on the extracted features and are not transferable. Hence, their learning rate was unaltered during the training process.</p><p>After 20 training epochs, we conducted two main performance tests. The first test is obtaining the receiver operating characteristic curve, i.e., plotting the ROC curve, which is a standard measure of the performance of a classifier. As plotted in Figure <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" href=\"#apjaaae6af7\">7</a>, the horizontal and the vertical axes indicate the false positive rate (FPR) and the true positive rate (TPR) respectively. The ROC curve is obtained by evaluating FPR and TPR for different classification thresholds (i.e., the minimum lens probability for an image to be categorized as lens). Even though ROC curves are very useful for most classifiers, we suggest a different performance measure that is more appropriate for the field of astronomy where thousands or millions of images have to be scanned to identify desired sources. In our case, after training the net, we have placed the 52 selected lenses as tracers among the entire 236,000 source images extracted from COSMOS. The assigned lens probability by this net has been used to rank the images from the most likely lens candidates to the least likely. The number of recovered tracer lenses as a function of relative ranks (i.e., rank of an image divided by the total number of images) are plotted in Figure <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" href=\"#apjaaae6af8\">8</a>. We will refer to this curve as the tracer rank curve (TRC). We see that 100% of tracer lenses fall in the top 6% of the sorted images. A TRC can be quantified by one number, which we refer to as the ranking performance. We define the ranking performance as the area between a TRC (the solid black line in Figure <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" href=\"#apjaaae6af8\">8</a>) and the line of no discrimination (the dashed red line in the same figure) divided by the TRC for a perfect classifier (i.e., approximately one-half when the number of scanned images is much larger than the number of tracer images). Therefore, a ranking performance of 1 corresponds to placing all tracer lenses in the highest ranks, while a ranking performance of 0 corresponds to dispersing tracer lenses among all images, which is a sign of no learning. A negative ranking performance, on the other hand, means the classifier is systematically misclassifying images. The ranking performance of our ConvNet during this phase is 0.97 which is quite good for such a simple ConvNet applied on a data set with one color channel. However, placing all the tracer lenses in the top 6% means lenses have to be recovered among 14,000 images. Even though this is a massive reduction from 236,000, examining 14,000 images by eye is not very practical and would be impossible for larger surveys. For this reason, we have introduced another phase that specializes in finding lenses among the remaining 14,000 images by retraining our net on the top 6% images, as discussed in the following subsection.</p><figure xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"apjaaae6af7\" tabindex=\"-1\" role=\"group\" class=\"boxout boxout-bdr-grey keyboard-focus-only\" data-toolbar-type=\"figure\" data-toolbar-link=\"apjaaae6af7\" data-toolbar-img=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6af7_lr.jpg\" data-toolbar-title=\"Figure 7.\"><figure><div class=\"panzoom-container\"><div class=\"panzoom-parent\" style=\"overflow: hidden; position: relative;\"><img class=\"panzoom\" alt=\"Figure 7.\" src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6af7_lr.jpg\" style=\"transform: matrix(1, 0, 0, 1, 0, 0); backface-visibility: hidden; transform-origin: 50% 50% 0px; cursor: move; transition: transform 200ms ease-in-out 0s;\"></img></div><div class=\"buttons zoom-tools\"><button class=\"zoom-in\"><span class=\"icon-zoomin\"></span>\n\t                 Zoom In\n\t\t\t\t</button><button class=\"zoom-out\"><span class=\"icon-zoomout\"></span>\n\t                 Zoom Out\n\t\t\t\t</button><span class=\"mobile-block\"><button class=\"reset\"><span class=\"icon-loop\"></span>\n\t                     Reset image size\n\t\t\t\t\t</button></span></div></div><figcaption><div class=\"article-text figure-caption\"><p><strong>Figure 7.</strong>\u00a0Receiver operating characteristic (ROC) diagram. The black curve shows the trend of the true positive rate verses the false positive rate of LensFlow, while the red dashed curve shows an untrained classifier.</p></div><p class=\"mb-05 print-hide\">Download figure:</p><span class=\"btn-multi-block print-hide\"><a class=\"btn btn-primary fig-dwnld-std-img\" id=\"wd-jnl-art-btn-std-img-apjaaae6af7\" href=\"/0004-637X/856/1/68/downloadFigure/figure/apjaaae6af7\"><span class=\"icon-image\"></span> Standard image\n\t\t\t\t\t</a><a class=\"btn btn-primary fig-dwnld-hi-img\" id=\"wd-jnl-art-btn-hires-img-apjaaae6af7\" href=\"/0004-637X/856/1/68/downloadHRFigure/figure/apjaaae6af7\"><span class=\"icon-image\"></span> High-resolution image\n\t\t\t\t\t</a></span></figcaption></figure></figure><figure xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"apjaaae6af8\" tabindex=\"-1\" role=\"group\" class=\"boxout boxout-bdr-grey keyboard-focus-only\" data-toolbar-type=\"figure\" data-toolbar-link=\"apjaaae6af8\" data-toolbar-img=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6af8_lr.jpg\" data-toolbar-title=\"Figure 8.\"><figure><div class=\"panzoom-container\"><div class=\"panzoom-parent\" style=\"overflow: hidden; position: relative;\"><img class=\"panzoom\" alt=\"Figure 8.\" src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6af8_lr.jpg\" style=\"transform: matrix(1, 0, 0, 1, 0, 0); backface-visibility: hidden; transform-origin: 50% 50% 0px; cursor: move; transition: transform 200ms ease-in-out 0s;\"></img></div><div class=\"buttons zoom-tools\"><button class=\"zoom-in\"><span class=\"icon-zoomin\"></span>\n\t                 Zoom In\n\t\t\t\t</button><button class=\"zoom-out\"><span class=\"icon-zoomout\"></span>\n\t                 Zoom Out\n\t\t\t\t</button><span class=\"mobile-block\"><button class=\"reset\"><span class=\"icon-loop\"></span>\n\t                     Reset image size\n\t\t\t\t\t</button></span></div></div><figcaption><div class=\"article-text figure-caption\"><p><strong>Figure 8.</strong>\u00a0Normalized ranking of tracer lenses by <span class=\"small-caps\">LensFlow</span>. Ranking performance is defined as the area between the black tracer rank curve (TRC) and the dashed red line of no discrimination divided by the area between a perfect TRC and the line of no discrimination (approximately one-half for large data sets). Left: 100% of the tracer lenses are in the top 6%. The ranking performance of Phase 1 is 0.97. Right: during Phase 2, the ConvNet was trained on the top 6% images from Phase 1. The ranking of the tracer lenses has been shown. 80% of the tracer lenses are in the top 30%. The ranking performance of Phase 2 is 0.60.</p></div><p class=\"mb-05 print-hide\">Download figure:</p><span class=\"btn-multi-block print-hide\"><a class=\"btn btn-primary fig-dwnld-std-img\" id=\"wd-jnl-art-btn-std-img-apjaaae6af8\" href=\"/0004-637X/856/1/68/downloadFigure/figure/apjaaae6af8\"><span class=\"icon-image\"></span> Standard image\n\t\t\t\t\t</a><a class=\"btn btn-primary fig-dwnld-hi-img\" id=\"wd-jnl-art-btn-hires-img-apjaaae6af8\" href=\"/0004-637X/856/1/68/downloadHRFigure/figure/apjaaae6af8\"><span class=\"icon-image\"></span> High-resolution image\n\t\t\t\t\t</a></span></figcaption></figure></figure></div><h3 id=\"apjaaae6as3-5\" name=\"apjaaae6as3-5\">3.5.\u00a0Fine Classification Phase (Phase 2)</h3><div class=\"article-text\"><p>In order to further reduce the number of images that have to be examined by eye, we have constructed a data set by randomly selecting 3200 images from the remaining COSMOS images from Phase 1. The same 3200 augmented simulated lens images were added to complete the data set. The ConvNet was trained over 25 iterations and the remaining images from Phase 1 were scanned and ranked using this net. The first 300 images were examined, which included some lenses but mostly artifacts, spiral galaxies, and satellite galaxies (see Figure <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" href=\"#apjaaae6af9\">9</a>). Lens images were removed and the remaining were augmented and added to the training data set for retraining to eliminate most probable false classifications. The TRC for this net is plotted in the right panel of Figure <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" href=\"#apjaaae6af8\">8</a> with a ranking performance of 0.60. The same net with the same methodology could do extremely better if images had color information, which is not present in our data. Other ways to improve the results is to create a more diverse and larger data set, which is very time consuming. Using more complex nets such as GoogLeNet with perception models might improve the results, which we will investigate in a future study. The results of Phase 1 show that simple and fast deep learning algorithms, such as ours, are sufficient enough to reduce the data by a factor of 17 since both training and scanning are more time consuming with complex nets such as GoogLeNet.</p><figure xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"apjaaae6af9\" tabindex=\"-1\" role=\"group\" class=\"boxout boxout-bdr-grey keyboard-focus-only\" data-toolbar-type=\"figure\" data-toolbar-link=\"apjaaae6af9\" data-toolbar-img=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6af9_lr.jpg\" data-toolbar-title=\"Figure 9.\"><figure><div class=\"panzoom-container\"><div class=\"panzoom-parent\" style=\"overflow: hidden; position: relative;\"><img class=\"panzoom\" alt=\"Figure 9.\" src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6af9_lr.jpg\" style=\"transform: matrix(1, 0, 0, 1, 0, 0); backface-visibility: hidden; transform-origin: 50% 50% 0px; cursor: move; transition: transform 200ms ease-in-out 0s;\"></img></div><div class=\"buttons zoom-tools\"><button class=\"zoom-in\"><span class=\"icon-zoomin\"></span>\n\t                 Zoom In\n\t\t\t\t</button><button class=\"zoom-out\"><span class=\"icon-zoomout\"></span>\n\t                 Zoom Out\n\t\t\t\t</button><span class=\"mobile-block\"><button class=\"reset\"><span class=\"icon-loop\"></span>\n\t                     Reset image size\n\t\t\t\t\t</button></span></div></div><figcaption><div class=\"article-text figure-caption\"><p><strong>Figure 9.</strong>\u00a0Examples of common misclassified images. These images were used to retrain <span class=\"small-caps\">LensFlow</span> to improve its ranking performance.</p></div><p class=\"mb-05 print-hide\">Download figure:</p><span class=\"btn-multi-block print-hide\"><a class=\"btn btn-primary fig-dwnld-std-img\" id=\"wd-jnl-art-btn-std-img-apjaaae6af9\" href=\"/0004-637X/856/1/68/downloadFigure/figure/apjaaae6af9\"><span class=\"icon-image\"></span> Standard image\n\t\t\t\t\t</a><a class=\"btn btn-primary fig-dwnld-hi-img\" id=\"wd-jnl-art-btn-hires-img-apjaaae6af9\" href=\"/0004-637X/856/1/68/downloadHRFigure/figure/apjaaae6af9\"><span class=\"icon-image\"></span> High-resolution image\n\t\t\t\t\t</a></span></figcaption></figure></figure></div><h3 id=\"apjaaae6as3-6\" name=\"apjaaae6as3-6\">3.6.\u00a0Search Phase (Phase 3)</h3><div class=\"article-text\"><p>This phase is identical to the previous phase with the exception of including augmented tracer lenses in the training data set in order to increase the size of the data set to improve the chances of finding new lens candidates. The previous phase was necessary to obtain the maximum number of training epochs and to test the performance of <span class=\"small-caps\">LensFlow</span>. After training this ConvNet, we examined 2000 images and identified 46 new lens candidates that were not mentioned in Faure et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib12\" id=\"fnref-apjaaae6abib12\">2008</a>; the examination process took roughly 20 minutes). These lens candidates are shown in Figure <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" href=\"#apjaaae6af10\">10</a> and their coordinates are listed in Table <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"tabref\" href=\"#apjaaae6at2\">2</a> (see Appendix <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"secref\" href=\"#apjaaae6aapp2\">B</a>). Classification algorithms like ours can benefit from Citizen Science projects such as the <span class=\"small-caps\">SPACE WARPS</span> project (Marshall et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib31\" id=\"fnref-apjaaae6abib31\">2015</a>; More et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib34\" id=\"fnref-apjaaae6abib34\">2016</a>), where volunteers are presented with real and simulated gravitational lenses in order to obtain a measure of their classification performance, while identifying new lenses. Citizen Science projects such as <span class=\"small-caps\">SPACE WARPS</span> can help with classification of images with high lensing probabilities assigned by automated classifiers.</p><figure xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"apjaaae6af10\" tabindex=\"-1\" role=\"group\" class=\"boxout boxout-bdr-grey keyboard-focus-only\" data-toolbar-type=\"figure\" data-toolbar-link=\"apjaaae6af10\" data-toolbar-img=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6af10_lr.jpg\" data-toolbar-title=\"Figure 10.\"><figure><div class=\"panzoom-container\"><div class=\"panzoom-parent\" style=\"overflow: hidden; position: relative;\"><img class=\"panzoom\" alt=\"Figure 10.\" src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6af10_lr.jpg\" style=\"transform: matrix(1, 0, 0, 1, 0, 0); backface-visibility: hidden; transform-origin: 50% 50% 0px; cursor: move; transition: transform 200ms ease-in-out 0s;\"></img></div><div class=\"buttons zoom-tools\"><button class=\"zoom-in\"><span class=\"icon-zoomin\"></span>\n\t                 Zoom In\n\t\t\t\t</button><button class=\"zoom-out\"><span class=\"icon-zoomout\"></span>\n\t                 Zoom Out\n\t\t\t\t</button><span class=\"mobile-block\"><button class=\"reset\"><span class=\"icon-loop\"></span>\n\t                     Reset image size\n\t\t\t\t\t</button></span></div></div><figcaption><div class=\"article-text figure-caption\"><p><strong>Figure 10.</strong>\u00a0Identified COSMSOS lens candidates by <span class=\"small-caps\">LensFlow</span>. These candidates are cataloged in Table <a class=\"tabref\" href=\"#apjaaae6at2\">2</a>.</p></div><p class=\"mb-05 print-hide\">Download figure:</p><span class=\"btn-multi-block print-hide\"><a class=\"btn btn-primary fig-dwnld-std-img\" id=\"wd-jnl-art-btn-std-img-apjaaae6af10\" href=\"/0004-637X/856/1/68/downloadFigure/figure/apjaaae6af10\"><span class=\"icon-image\"></span> Standard image\n\t\t\t\t\t</a><a class=\"btn btn-primary fig-dwnld-hi-img\" id=\"wd-jnl-art-btn-hires-img-apjaaae6af10\" href=\"/0004-637X/856/1/68/downloadHRFigure/figure/apjaaae6af10\"><span class=\"icon-image\"></span> High-resolution image\n\t\t\t\t\t</a></span></figcaption></figure></figure><div tabindex=\"-1\" id=\"apjaaae6at2\" class=\"boxout boxout-bdr-grey keyboard-focus-only\"><p><b>Table 2.</b>\u00a0\nCatalog of Identified Lenses by <span class=\"small-caps\">LensFlow</span>\n</p><table cellpadding=\"0\" cellspacing=\"0\" border=\"0\" data-toolbar-link=\"apjaaae6at2\" data-toolbar-img=\"/0004-637X/856/1/68/suppdata/apjaaae6at2_lr.gif\" data-toolbar-type=\"table\" data-toolbar-title=\"Table 2\"><colgroup><col align=\"left\" char=\"\"></col><col align=\"left\" char=\"\"></col><col align=\"left\" char=\"\"></col><col align=\"left\" char=\"\"></col><col align=\"left\" char=\"\"></col><col align=\"left\" char=\"\"></col><col align=\"left\" char=\"\"></col></colgroup><thead>\n<tr valign=\"top\">\n<th scope=\"col\" colspan=\"1\" rowspan=\"1\" align=\"left\">Lens</th>\n<th scope=\"col\" colspan=\"1\" rowspan=\"1\" align=\"center\">R.A.</th>\n<th scope=\"col\" colspan=\"1\" rowspan=\"1\" align=\"center\">Decl.</th>\n<th scope=\"col\" colspan=\"1\" rowspan=\"1\" align=\"center\">Einstein Radius</th>\n<th scope=\"col\" colspan=\"1\" rowspan=\"1\" align=\"center\">Magnitude</th>\n<th scope=\"col\" colspan=\"1\" rowspan=\"1\" align=\"center\">Absolute Rank</th>\n<th scope=\"col\" colspan=\"1\" rowspan=\"1\" align=\"center\">Average Grade<sup>a</sup>\n</th>\n</tr>\n<tr valign=\"top\">\n<th scope=\"col\" colspan=\"1\" rowspan=\"1\" align=\"left\">\u00a0</th>\n<th scope=\"col\" colspan=\"1\" rowspan=\"1\" align=\"center\">(deg)</th>\n<th scope=\"col\" colspan=\"1\" rowspan=\"1\" align=\"center\">(deg)</th>\n<th scope=\"col\" colspan=\"1\" rowspan=\"1\" align=\"center\">(arcsec)</th>\n<th scope=\"col\" colspan=\"1\" rowspan=\"1\" align=\"center\">(AB)</th>\n<th scope=\"col\" colspan=\"1\" rowspan=\"1\" align=\"center\">In 236,000</th>\n<th scope=\"col\" colspan=\"1\" rowspan=\"1\" align=\"center\">A/B/C</th>\n</tr>\n</thead><tbody>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">1</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.545323</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+1.614164</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.82</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">22.16</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1211</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">2</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.440339</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+1.754854</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.36</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.90</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">204</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">A</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">3</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.180910</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+1.714817</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.90</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">22.22</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">383</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">4</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.066345</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+1.772114</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2.11</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">19.85</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">7</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">5</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.489741</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+1.736721</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.08</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.18</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1744</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">6</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.646190</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+1.840283</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.91</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.28</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1018</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">7</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.091078</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+1.935850</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2.53</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.13</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">136</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">8</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.632091</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+1.882368</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2.38</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.41</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">260</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">9</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.670701</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.091367</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.30</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.19</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">458</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">10</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.894802</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.109357</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.72</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.44</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">845</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">11</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.856184</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.112118</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2.33</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.61</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1321</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">12</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.549644</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.140845</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.91</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">22.61</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">584</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">13</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.259607</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.209858</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.88</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.16</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1275</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">14</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.117743</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.266765</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.86</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.34</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1597</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">15</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.730719</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.147258</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.82</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.62</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">16</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.644851</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.135518</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.74</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.55</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">189</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">17</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.656039</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.447838</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.51</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.81</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">308</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">A</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">18</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.411971</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.308876</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.86</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">19.93</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1069</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">19</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.095108</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.300498</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.43</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">18.57</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1593</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">20</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.085701</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.297656</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.91</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.86</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">300</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">21</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.085616</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.364097</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.79</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">18.72</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">506</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">22</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.106308</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.432955</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.82</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.34</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1674</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">23</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.961446</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.349389</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.16</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.60</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">208</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">24</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.628310</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.354862</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.88</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.82</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1820</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">25</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.722715</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.428631</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.19</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.60</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">359</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">26</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.571395</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.506658</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.55</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.18</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">66</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">27</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.624611</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.540319</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.88</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">18.97</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">910</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">28</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.694125</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.547939</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.87</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.52</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">292</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">29</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.317117</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.531471</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2.71</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.62</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1451</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">30</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.141624</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.464563</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.65</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.82</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">86</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">31</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.063881</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.605824</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.47</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.50</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">979</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">32</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.878942</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.574346</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.97</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.78</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">573</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">A</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">33</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.542116</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.495012</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2.23</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">19.03</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1505</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">34</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.747020</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.666027</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.96</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.36</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">153</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">35</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.548642</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.766168</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.84</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">18.91</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1595</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">36</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.329391</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.671669</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2.44</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.72</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1027</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">37</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.284903</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.674951</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.53</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">19.08</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">321</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">A</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">38</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.250216</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.763947</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.60</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.72</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1515</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">39</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.101284</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.703268</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.74</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">22.58</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">932</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">40</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.217548</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.659542</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.11</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">23.18</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1567</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">41</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.855932</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.650953</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.87</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.97</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1345</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">42</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.621847</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.733148</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2.33</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.31</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1319</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">43</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.644507</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.808898</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.02</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.94</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1098</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">44</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.443480</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.847808</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.55</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.66</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1442</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">45</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.104053</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.844371</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2.24</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.66</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">222</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">46</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.611769</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.809775</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2.21</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">22.29</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">328</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">47<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.052500</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.337500</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.90</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">19.28</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2470</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">A</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">48<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.057917</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.380278</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.65</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">18.89</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">910</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">49<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.076667</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.645833</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.40</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">23.60</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">392</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">A</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">50<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.159167</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.692500</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.74</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.39</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">13610</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">A</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">51<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.198333</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+1.839722</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.70</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.65</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2916</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">A</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">52<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.205000</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+1.857778</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2.22</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">19.61</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">693</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">53<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.210833</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.816944</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.90</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.72</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">5333</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">A</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">54<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.236250</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.207222</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.20</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">18.70</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">4041</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">55<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.352083</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+1.855833</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.84</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">22.43</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">5125</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">56<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.570000</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.498611</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.96</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">19.98</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">3521</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">57<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.614583</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.080833</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.62</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.94</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1495</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">58<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.725000</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.241667</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.54</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">18.85</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">5783</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">59<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.494167</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.256944</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.35</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">22.27</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">3868</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">60<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.737500</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+1.996944</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2.15</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.05</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1164</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">61<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.811250</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.205278</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.86</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">23.25</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">4700</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">62<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.840417</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.110556</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.80</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.34</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">9218</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">A</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">63<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.949167</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.797778</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2.55</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">19.83</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">64<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.040417</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.415278</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2.63</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">19.49</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">8071</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">65<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.196250</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.491944</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2.00</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">19.56</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">13476</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">A</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">66<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.211667</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.065833</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.66</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">22.31</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1197</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">67<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.232083</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+1.639167</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.05</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.86</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">616</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">A</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">68<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.272083</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.758611</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.00</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.38</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">3204</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">69<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.334167</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+1.764167</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.28</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.31</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1300</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">70<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.450417</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.390278</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.43</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">18.81</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">216</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">71<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.535417</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.239444</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.59</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.06</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">8647</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">72<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.584167</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.393056</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.04</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.99</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">283</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">73<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.587917</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.577778</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.57</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">19.35</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">9564</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">74<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.650000</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.801944</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.27</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.15</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">3865</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">75<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.450000</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+1.923333</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2.21</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">22.15</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1236</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">A</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">76<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.461250</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+1.938611</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.73</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">19.19</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">9936</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">77<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.467083</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.349167</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.98</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.27</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">5965</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">78<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.475417</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+1.997778</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.33</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">22.23</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">204</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">79<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.523333</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.070278</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.61</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">23.00</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">3764</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">80<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.528333</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+1.969167</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.50</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">19.14</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2442</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">81<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.624583</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+1.626111</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2.97</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">19.95</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">12066</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">82<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.629167</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+1.725556</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.17</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.06</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2092</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">A</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">83<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.672500</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.779444</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.93</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">19.65</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">177</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">84<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.733750</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.798611</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2.97</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">19.54</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">5951</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">85<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.870833</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+1.764722</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.56</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">19.99</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">200</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">86<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.879583</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.041389</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.48</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">19.20</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">894</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">87<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.883333</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.171667</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.68</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.92</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">51</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">88<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.902917</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.605833</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2.40</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">19.14</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">7344</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">89<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.912917</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.512222</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.70</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.08</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">93</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">90<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.918333</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.548056</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.53</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">19.45</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">186</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">91<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.929583</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.471111</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.64</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">19.43</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2684</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">92<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.998750</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.063333</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.20</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.62</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">44</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n</tbody></table><p><small>\n<p><strong>Notes.</strong> The first column corresponds to the image number in Figure <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" href=\"#apjaaae6af10\">10</a>.</p>\n<a name=\"apjaaae6at1fna\" id=\"apjaaae6at1fna\"></a><sup> a</sup>Grade A corresponds to images that are clearly a strong gravitational lens. Grade B lenses correspond to images that are most likely a lens, but there is a chance they could also be artifacts, noise, structures in elliptical galaxies, satellite galaxies, tidally interacting galaxies, etc. Grade C lenses consist of images that are most likely not a lens, but there is a chance they might be gravitationally lensed.\n<a name=\"apjaaae6at1fnb\" id=\"apjaaae6at1fnb\"></a><sup> b</sup>These marked lenses were previously cataloged by Faure et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib12\" id=\"fnref-apjaaae6abib12\">2008</a>).\n</small></p><p class=\"franklin fs-16\">\n\t\t\tDownload table as:\u00a0\n            <span class=\"btn-multi-block\"><a class=\"btn btn-primary wd-jnl-art-btn-ascii\" href=\"/0004-637X/856/1/68/suppdata/apjaaae6at2_ascii.txt?doi=10.3847/1538-4357/aaae6a\" target=\"_blank\">ASCII</a>Typeset images: <a class=\"btn btn-primary wd-jnl-art-btn-typeset-multiple typeset-table-img\" href=\"/0004-637X/856/1/68/suppdata/apjaaae6at2_lr.gif\" target=\"_blank\">1</a> <a class=\"btn btn-primary wd-jnl-art-btn-typeset-multiple typeset-table-img\" href=\"/0004-637X/856/1/68/suppdata/apjaaae6at2a_lr.gif\" target=\"_blank\">2</a> </span></p></div></div></div>\n<h2 class=\"header-anchor\" id=\"apjaaae6as4\" name=\"apjaaae6as4\">4.\u00a0Discussion</h2><div class=\"article-text\" data-mobile-collapse=\"\"><p>Non-ML computer algorithms have been previously used for finding gravitationally lensed arcs (Lenzen et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib29\" id=\"fnref-apjaaae6abib29\">2004</a>; Alard <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib3\" id=\"fnref-apjaaae6abib3\">2006</a>; More et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib32\" id=\"fnref-apjaaae6abib32\">2012</a>) and rings (Gavazzi et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib14\" id=\"fnref-apjaaae6abib14\">2014</a>). As discussed in More et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib32\" id=\"fnref-apjaaae6abib32\">2012</a>) and Gavazzi et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib14\" id=\"fnref-apjaaae6abib14\">2014</a>), <span class=\"small-caps\">ringfinder</span> is an algorithm that uses color information and <span class=\"small-caps\">ArcFinder</span> detects arc-like pixels. In more detail, <span class=\"small-caps\">ArcFinder</span> starts by polishing the images by convolving a smoothing kernel. For each pixel, an estimator of elongation is calculated by taking the ratio between the sum of the flux of a few pixels along the horizontal line and the maximum value of a few nearby pixels along the vertical line, which passes through the pixel in hand. This process is repeated for all pixels and those with smaller than an specified elongation threshold are set to zero to create a sharp arc map. An arc map that satisfies thresholds on the arc properties such as the size and surface brightness will be selected as an arc candidate for further visual inspection. Such techniques can be used as complementary methods to deep learning. Currently, both techniques may suffer from many false positive detections, which commonly include tidally interacting galaxies, artifacts, and ring and spiral galaxies. The hope is that with more developed training data sets, deep learning algorithms can resolve such false positive cases (see Figure <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" href=\"#apjaaae6af9\">9</a> and Section <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"secref\" href=\"#apjaaae6as3-5\">3.5</a>).</p><p>Other researchers (Jacobs et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib20\" id=\"fnref-apjaaae6abib20\">2017</a>; Lanusse et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib28\" id=\"fnref-apjaaae6abib28\">2018</a>; Petrillo et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib42\" id=\"fnref-apjaaae6abib42\">2017</a>) also find deep learning to be a suitable solution for finding gravitational lenses. Lanusse et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib28\" id=\"fnref-apjaaae6abib28\">2018</a>) use residual ConvNets with 46 layers. Residual ConvNets are modified ConvNets that do not suffer from layer saturation like ordinary ConvNets do. After adding more than 50 layers, the accuracy of ordinary ConvNets no longer improves and the training becomes more challenging. He et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib18\" id=\"fnref-apjaaae6abib18\">2016</a>) were able to overcome this issue by providing residual maps in between layers, which has been employed by Lanusse et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib28\" id=\"fnref-apjaaae6abib28\">2018</a>). They have simulated LSST mock observations in a single band and have trained and tested their network on these images. Jacobs et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib20\" id=\"fnref-apjaaae6abib20\">2017</a>) have trained their ConvNet using multiple color bands and have applied it to the Canada\u2013France\u2013Hawaii Telescope Legacy Survey. Petrillo et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib42\" id=\"fnref-apjaaae6abib42\">2017</a>) have searched for lenses in Kilo Degree Survey by training their ConvNet on cataloged luminous red galaxies.</p><p>In our independently developed work, we focus on the morphology of the lenses and only rely on one color band, similar to Petrillo et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib42\" id=\"fnref-apjaaae6abib42\">2017</a>) and Lanusse et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib28\" id=\"fnref-apjaaae6abib28\">2018</a>). Our lens simulation method is very similar to that of Petrillo et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib42\" id=\"fnref-apjaaae6abib42\">2017</a>), as we both merge simulated arcs with real images of galaxies to preserve the complexity of the physical data. In contrast to others, we do not discriminate against different sources found in the COSMOS field. That is, artifacts, stars, and other sources have been included in our training data set so <span class=\"small-caps\">LensFlow</span> can be directly applied to fields without a need for a catalog with galaxy type information. The deepness of our ConvNet is comparable to Petrillo et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib42\" id=\"fnref-apjaaae6abib42\">2017</a>) and Jacobs et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib20\" id=\"fnref-apjaaae6abib20\">2017</a>) but it is shallower than Lanusse et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib28\" id=\"fnref-apjaaae6abib28\">2018</a>). As mentioned in Jacobs et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib20\" id=\"fnref-apjaaae6abib20\">2017</a>), the morphology of lenses are much simpler than the morphology of daily objects and human faces, which extremely deep ConvNets are developed for. However, the cost to performance ratio of ConvNets with varying deepness has not been studied yet. The effectiveness of deeper ConvNets cannot be compared between ours (and Petrillo et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib42\" id=\"fnref-apjaaae6abib42\">2017</a> ) and Lanusse et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib28\" id=\"fnref-apjaaae6abib28\">2018</a>) since this work did not apply their algorithm to physical data. However, Lanusse et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib28\" id=\"fnref-apjaaae6abib28\">2018</a>) studied the change in the performance of their ConvNet by varying the Einstein radii and signal-to-noise ratio of their lenses.</p><p>A catalog of the strong gravitational lenses in the COSMOS field has previously been generated (Faure et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib12\" id=\"fnref-apjaaae6abib12\">2008</a>) by looking at early-type bright galaxies in the redshift range of <span xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"inline-eqn\"><span class=\"tex\"><span class=\"texImage\"><img src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6aieqn14.gif\" alt=\"$0.2\\leqslant z\\leqslant 1.0$\" align=\"top\"></img></span><script type=\"math/tex\">0.2\\leqslant z\\leqslant 1.0</script></span></span> in specific environments and by visually inspecting and cataloging 60 high- and low-quality lens candidates. In contrast, we have examined 236,000 sources in the <em>HST</em>/ACS i-band of the COSMOS field. In this paper, we reported our sample of gravitational lenses and presented an introduction to neural networks including ConvNets. Furthermore, we laid out the procedure for constructing simulated images for training and testing <span class=\"small-caps\">LensFlow</span>. The architecture of <span class=\"small-caps\">LensFlow</span> and its performance on test data constructed from real lenses were also presented. Finally, we used <span class=\"small-caps\">LensFlow</span> to identify new lens candidates using <em>HST</em> data. Scanning all of the <em>HST</em>/ACS images in the COSMOS field roughly took 140 seconds on one GPU with 3840 NVIDIA CUDA cores. This corresponds to scanning 1.7 thousand 100\u00a0<b>&#x00d7;</b>\u00a0100-pixel images per second (or equivalently <span xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"inline-eqn\"><span class=\"tex\"><span class=\"texImage\"><img src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6aieqn15.gif\" alt=\"$4.2\\ {\\mathrm{arcmin}}^{2}\\,{{\\rm{s}}}^{-1}$\" align=\"top\"></img></span><script type=\"math/tex\">4.2\\ {\\mathrm{arcmin}}^{2}\\,{{\\rm{s}}}^{-1}</script></span></span> for the <em>Hubble ACS</em> camera). This speed is suitable for all-sky surveys and the computation time can be reduced further by increasing the number of employed GPUs.</p></div> <div class=\"article-text\" data-mobile-collapse=\"\"><p>We wish to thank the referee for reading the original manuscript and providing useful feedback. Financial support for this paper was provided by NSF grant AST-1313319 and GAANN P200A150121. We are also thankful for the donated GPU by NVIDIA Grant Program. Figures <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" href=\"#apjaaae6af1\">1</a> and <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" href=\"#apjaaae6af6\">6</a> were generated using\u00a0<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"webref\" target=\"_blank\" href=\"http://www.draw.io\">http://www.draw.io</a>. The backbone of our algorithm was initially inspired by Hvass Laboratories on Github (Pedersen <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib40\" id=\"fnref-apjaaae6abib40\">2016</a>). Figure <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" href=\"#apjaaae6af2\">2</a> was plotted using his code as well. We would like to thank Dr. Emre Neftci, Dr. Charless Fowlkes, Dr. Pierre Baldi for their valuable feedback. We would also like to thank Noah Ghotbi and Aroosa Ansari for their assistance.</p></div><h2 class=\"header-anchor\" id=\"apjaaae6aapp1\" name=\"apjaaae6aapp1\">Appendix A: Remarks on the <span class=\"small-caps\">LensFlow</span> Code</h2><div class=\"article-text\" data-mobile-collapse=\"\"><p>We have developed <span class=\"small-caps\">LensFlow</span> (Pourrahmani et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib44\" id=\"fnref-apjaaae6abib44\">2018</a>) in the Wolram Language (a.k.a <span class=\"small-caps\">Mathematica</span>), using its image processing and state-of-the-art ML functionalities and it can be accessed on Github (see footnote 2). The main notebook is called <span class=\"small-caps\">LensFlow</span>, which contains all the deep learning portions of the code. Other notebooks are used for lens simulation, image normalization, etc. If the user does not have access to <span class=\"small-caps\">Mathematica</span>, they can download CDF Player for free to view the code. We will also provide a PDF of the main notebook with documentation alongside the code. From a practical perspective, it is important to store the images as <span class=\"small-caps\">JPEG</span> files or other compressed formats since non-compressed image formants such as FITS occupy a significantly larger memory and storage volume and loading these images to memory will require much longer time. Training <span class=\"small-caps\">LensFlow</span> during each phase on a GPU with 3840 NVIDIA CUDA cores takes less than 5 minutes for the training data set discussed in this paper. <span class=\"small-caps\">Mathematica</span> uses <span class=\"small-caps\">MXNet</span>, so a trained network can be easily transferred to other languages. We initially developed our algorithm using <span class=\"small-caps\">TensorFlow</span>, later, with the adoption of <span class=\"small-caps\">Keras</span> in Python 3.5.2 in Jupyter notebooks. These codes will be provided as extras. Even though they are not polished or fully developed, the codes is briefly documented in the Jupyter notebooks and may contain useful functions for data curation, helping the user to go from tiles to cutouts around extracted sources or automatically generating random arcs using <span class=\"small-caps\">LensTool</span>.</p></div><h2 class=\"header-anchor\" id=\"apjaaae6aapp2\" name=\"apjaaae6aapp2\">Appendix B: Identified and Recovered Lenses</h2><div class=\"article-text\" data-mobile-collapse=\"\"><p><span class=\"small-caps\">LensFlow</span> was able to identify 92 lenses in the COSMOS field, 46 of which were new and the rest were previously reported in Faure et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib12\" id=\"fnref-apjaaae6abib12\">2008</a>). The coordinates, Einstein radii, magnitudes of the brightest object, the <span class=\"small-caps\">LensFlow</span> rankings of the lens among 236,000 images, and their grades are reported in Table <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"tabref\" href=\"#apjaaae6at2\">2</a>. The corresponding images are shown in Figure <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" href=\"#apjaaae6af10\">10</a>.</p></div></div><!-- End article full text -->\n<!-- Start Footnotes -->\n\t<h2 id=\"footnotes\">Footnotes</h2>\n\t\t<div data-mobile-collapse=\"\">\n\t\t\t<ul class=\"clear-list wd-content-footnotes\">\n\t\t\t\t<li class=\"indices-list\"><div class=\"indices-id\" name=\"apjaaae6afn2\" id=\"apjaaae6afn2\">2\u00a0</div><div class=\"indices-content\"><p class=\"mb-0\"><p>\n<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"webref\" target=\"_blank\" href=\"https://github.com/Miladiouss/LensFlow\">https://github.com/Miladiouss/LensFlow</a>\n</p></p></div></li><li class=\"indices-list\"><div class=\"indices-id\" name=\"apjaaae6afn3\" id=\"apjaaae6afn3\">3\u00a0</div><div class=\"indices-content\"><p class=\"mb-0\"><p>In this paper and in our code, we have adapted the <span xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"inline-eqn\"><span class=\"tex\"><span class=\"texImage\"><img src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6aieqn2.gif\" alt=\"$N\\times C\\times H\\times W$\" align=\"top\"></img></span><script type=\"math/tex\">N\\times C\\times H\\times W</script></span></span> where <em>N</em>, <em>C</em>, <em>H</em>, and <em>W</em> stand for number of input images in a batch, number of color or feature channels, height, and width respectively.</p></p></div></li></ul>\n\t\t</div>\n\t<!-- End Footnotes -->\t\n<!-- Start References List -->\n\n<div class=\"reveal-container reveal-closed reveal-plus-icon exp-w-hash references\">\n                <div class=\"replica-h3 bdt-1 article-references__title\">\n                <a href=\"#\" class=\"reveal-trigger article-references\" data-reveal-label-alt=\"Hide&nbsp;references\"\n                   data-reveal-text=\"Show&nbsp;references\" aria-expanded=\"false\" id=\"references\">Show&nbsp;references</a>\n            </div>\n                <div class=\"reveal-content\" id=\"references-wrapper\">\n                    <div class=\"rss-feed__spinner-wrapper\"><span class=\"offscreen-hidden\">Please wait&hellip; references are loading.</span><span\n                            class=\"spinner icon-spinner rss-feed__spinner\"></span></div>\n                </div>\n            </div>\n        <!-- End References List -->\n</div>\n</div>\n            <div class=\"da2 ta2\">\n                <!-- Start Content nav and Back to top link -->\n<aside class=\"content-nav show-w-js\">\n\t<ul class=\"content-nav-ul wd-content-nav\">\n\t</ul>\n\t<a data-footer-backtotop class=\"btn btn-bottom back-top pl-0\" href=\"#back-to-top-target\"><span class=\"icon-arrow-up2\"></span> Back to top</a>\n</aside>\n<!-- End Content nav and Back to top link --></div>\n        </div>\n    </main>\n    <div class=\"da3 ta1\">\n        <div class=\"side-and-below\">\n            <!-- Start Related articles -->\n<!-- Note: the contents this span tag are necessary for the JavaScript that retrieves the related content and figure sets-->\n<span id=\"doi\" class=\"hide\">10.3847/1538-4357/aaae6a</span>\n<aside class=\"boxout bdt-6 related wd-related-articles\">\n            <span class=\"replica-h3\">Related content</span>\n        <div class=\"related-content-lists\">\n\n        <h3 class=\"related-article-hd replica-h4\">Journal articles</h3>\n            <div class=\"related-article-list\">\n                <ul class=\"\">\n                    <li>\n                            <a href=\"/article/10.1088/0004-637X/807/2/138\">Chitah: Strong-gravitational-lens Hunter in Imaging Surveys</a>\n                        </li>\n                    <li>\n                            <a href=\"/article/10.3847/1538-4365/aa7333\">Classifying Radio Galaxies with the Convolutional Neural Network</a>\n                        </li>\n                    <li>\n                            <a href=\"/article/10.1088/1748-0221/13/08/P08015\">Three-dimensional convolutional neural networks for neutrinoless double-beta decay signal/background discrimination in high-pressure gaseous Time Projection Chamber</a>\n                        </li>\n                    <li>\n                            <a href=\"/article/10.3847/1538-4357/837/1/97\">The Frontier Fields: Survey Design and Initial Results</a>\n                        </li>\n                    <li>\n                            <a href=\"/article/10.3847/1538-4357/aabfed\">Deep Learning Identifies High-<I>z</I> Galaxies in a Central Blue Nugget Phase in a Characteristic Mass Range</a>\n                        </li>\n                    <li>\n                            <a href=\"/article/10.1088/0004-637X/785/2/144\"><span class=\"small-caps\">RINGFINDER</span>: Automated Detection of Galaxy-scale Gravitational Lenses in Ground-based Multi-filter Imaging Data</a>\n                        </li>\n                    </ul>\n            </div>\n        </div>\n</aside>\n<!-- End Related articles -->\n</div>\n    </div>\n</div></div>\n\n    <div data-scroll-header=\"\" class=\"data-header-anchor\" id=\"exp\"></div>\n<!-- Footer tile starts -->\n<footer role=\"contentinfo\" data-footer-content>\n    <div class=\"iops-footer cf\">\n        <div class=\"wrapper\">\n            <nav role=\"navigation\" aria-label=\"Footer\">\n       \t\t<a class=\"iops-footer-logo\" id=\"wd-iops-footer-logo\" itemprop=\"url\" href=\"/\">\n\t\t\t\t\t<meta content=\"IOPscience\" itemprop=\"name\">\n\t\t\t\t\t<svg height=\"13\" width=\"90\">\n\t\t\t\t\t  <image xlink:href=\"https://static.iopscience.com/2.44.0/img/iops-logo.svg\" src=\"https://static.iopscience.com/2.44.0/img/iops-logo.png\" border=\"0\" height=\"13\" width=\"90\"/>\n\t\t\t\t\t</svg>\n                    <span class=\"offscreen-hidden\">IOP Science home</span>\n\t\t\t</a>\n            <small>\n                <ul>\n                    <li><a href=\"/journals\">Journals</a></li>\n                    <li><a href=\"/books\">Books</a></li>\n                    <li><a href=\"/page/aboutiopscience\">About IOPscience</a></li>\n                    <li><a href=\"/contact\">Contact us</a></li>\n                    <li><a href=\"/info/page/developing-countries-access\">Developing countries access</a></li>\n                    <li><a href=\"/info/page/openaccess\">IOP Publishing open access policy</a></li>\n                </ul>\n            </small>\n        </nav>\n        </div> <!-- end wrapper -->\n    </div> <!-- end iopp-footer -->\n\n    <div class=\"iopp-footer cf\">\n        <div class=\"wrapper\">\n            <div class=\"media mar-0 \">\n                <nav role=\"navigation\" aria-label=\"Further information about IOP Publishing\">\n\t\t\t\t<a class=\"iopp-footer-logo\" id=\"wd-iopp-footer-logo\" itemprop=\"url\" href=\"http://ioppublishing.org\">\n\t\t\t\t\t<meta content=\"IOPscience\" itemprop=\"name\">\n\t\t\t\t\t<svg width=\"100\" height=\"15\">\n\t\t\t\t\t  <image xlink:href=\"https://static.iopscience.com/2.44.0/img/iopp-logo-white.svg\" src=\"https://static.iopscience.com/2.44.0/img/iopp-logo.png\" border=\"0\" width=\"100\" height=\"15\"/>\n\t\t\t\t\t</svg>\n                    <span class=\"offscreen-hidden\">IOP Publishing home</span>\n\t\t\t\t</a>\n                <div class=\"media-body mar-0\">\n                    <ul>\n                        <li class=\"small\"><a href=\"/page/copyright_notice\">&copy; Copyright 2020 IOP Publishing</a></li>\n                        <li class=\"small\"><a href=\"/page/terms\">Terms &amp; conditions</a></li>\n                        <li class=\"small\"><a href=\"/page/disclaimer\">Disclaimer</a></li>\n                        <li class=\"small\"><a href=\"http://ioppublishing.org/privacyPolicy\" target=\"_blank\">Privacy &amp; cookie policy <span class=\"icon-newtab white-text\"></span></a></li>\n                        <li class=\"small\"><small>This site uses cookies. By continuing to use this site you agree to our use of cookies.</small></li>\n                    </ul>\n                </div>\n            </nav>\n            </div>\n        </div> <!-- end wrapper -->\n    </div> <!-- end iopp-footer -->\n</footer>\n<!-- Footer tile ends -->\n<script>\n  var imgBase = \"https://static.iopscience.com/2.44.0/img\";\n  /*  Cutting the mustard - http://responsivenews.co.uk/post/18948466399/cutting-the-mustard */\n\n  /* This is the original if statement, from the link above. I have amended it to turn of JS on all IE browsers less than 10.\n\tThis is due to a function in the iop.jquery.toolbar.js line 35/36. Uses .remove which is not native js supported in IE9 or lower */\n  /* if('querySelector' in document \n\t&& 'localStorage' in window\n\t&& 'addEventListener' in window) { */\n\n  /* This is the updated selector, taken from: https://justmarkup.com/log/2015/02/26/cut-the-mustard-revisited/ */\n\tif('visibilityState' in document) {\n\n\t/*! loadJS: load a JS file asynchronously. [c]2014 @scottjehl, Filament Group, Inc. (Based on http://goo.gl/REQGQ by Paul Irish).. Licensed MIT */\n\tfunction loadJS( src, cb ){\n\t  \"use strict\";\n\t  var ref = window.document.getElementsByTagName( \"script\" )[ 0 ];\n\t  var script = window.document.createElement( \"script\" );\n\t  script.src = src;\n\t  script.async = true;\n\t  ref.parentNode.insertBefore( script, ref );\n\t  if (cb && typeof(cb) === \"function\") {\n\t\tscript.onload = cb;\n\t  }\n\t  return script;\n\t}\n\n\tloadJS( \"https://static.iopscience.com/2.44.0/js/scripts.min.js\" );\n\n  }\n</script>\n\n<script type=\"text/javascript\">window.NREUM||(NREUM={});NREUM.info={\"errorBeacon\":\"bam-cell.nr-data.net\",\"licenseKey\":\"b2bfaae1b6\",\"agent\":\"\",\"beacon\":\"bam-cell.nr-data.net\",\"applicationTime\":737,\"applicationID\":\"723879338\",\"transactionName\":\"NAAHMUBVCENSABFZXg1KLzZiGzF1cU4sfndMDxYVQRsFX14OCl4eDwQcCkdASFpAEw==\",\"queueTime\":0}</script></body>\n</html>", "Status": "Complete", "Table meta data": {"Table set 2": {"Response": "Table 1 \nTabulated Architecture of the LENSFLOW ConvNet\n\n\nLayer\tType\tData Dimensionality\t\n\tinput\t1 x 100 x 100\t\n1\tconvolution\t30 x 96 x 96\t\n2\ttanh\t30 x 96 x 96\t\n3\tpooling\t30 x 48 x 48\t\n4\tconvolution\t60 x 44 x 44\t\n5\ttanh\t60 x 44 x 44\t\n6\tpooling\t60 x 22 x 22\t\n7\tconvolution\t90 x 18 x 18\t\n8\ttanh\t90 x 18 x 18\t\n9\tpooling\t90 x 9 x 9\t\n10\tflatten\t7290\t\n11\tlinear\t1000\t\n12\tReLU\t1000\t\n13\tdropout\t1000\t\n14\tlinear\t800\t\n15\tReLU\t800\t\n16\tdropout\t800\t\n17\tlinear\t600\t\n18\tReLU\t600\t\n19\tdropout\t600\t\n20\tlinear\t2\t\n21\tsoftmax\t2\t\n\toutput\t2\t\n", "Action": "Scanned all subtables", "Table captions or footers": {"Overview": "Table 1 \nTabulated Architecture of the LENSFLOW ConvNet", "Info after table 1": ""}, "Status": "Complete", "Link": "https://iopscience.iop.org/0004-637X/856/1/68/suppdata/apjaaae6at1_ascii.txt?doi=10.3847/1538-4357/aaae6a", "Pandas format": {"Table 2": {"Action": "Processed via pandas", "Status": "Complete", "Inspection": {"Notes": {"Skip cause table not important": ""}}}}}, "Table set 1": {"Response": "Table 2 \nCatalog of Identified Lenses by LENSFLOW\n\n\nLens\tR.A.\tDecl.\tEinstein Radius\tMagnitude\tAbsolute Rank\tAverage Grade^a\t\n\t(deg)\t(deg)\t(arcsec)\t(AB)\tIn 236,000\tA/B/C\t\n1\t+149.545323\t+1.614164\t1.82\t22.16\t1211\tB\t\n2\t+150.440339\t+1.754854\t1.36\t21.90\t204\tA\t\n3\t+150.180910\t+1.714817\t1.90\t22.22\t383\tC\t\n4\t+150.066345\t+1.772114\t2.11\t19.85\t7\tC\t\n5\t+149.489741\t+1.736721\t1.08\t21.18\t1744\tC\t\n6\t+150.646190\t+1.840283\t1.91\t20.28\t1018\tB\t\n7\t+150.091078\t+1.935850\t2.53\t21.13\t136\tB\t\n8\t+149.632091\t+1.882368\t2.38\t20.41\t260\tB\t\n9\t+150.670701\t+2.091367\t1.30\t21.19\t458\tB\t\n10\t+149.894802\t+2.109357\t0.72\t20.44\t845\tB\t\n11\t+149.856184\t+2.112118\t2.33\t21.61\t1321\tB\t\n12\t+150.549644\t+2.140845\t0.91\t22.61\t584\tB\t\n13\t+150.259607\t+2.209858\t0.88\t20.16\t1275\tB\t\n14\t+150.117743\t+2.266765\t0.86\t20.34\t1597\tB\t\n15\t+149.730719\t+2.147258\t1.82\t20.62\t21\tB\t\n16\t+149.644851\t+2.135518\t1.74\t21.55\t189\tB\t\n17\t+150.656039\t+2.447838\t1.51\t20.81\t308\tA\t\n18\t+150.411971\t+2.308876\t1.86\t19.93\t1069\tB\t\n19\t+150.095108\t+2.300498\t0.43\t18.57\t1593\tC\t\n20\t+150.085701\t+2.297656\t0.91\t21.86\t300\tB\t\n21\t+150.085616\t+2.364097\t1.79\t18.72\t506\tB\t\n22\t+150.106308\t+2.432955\t1.82\t21.34\t1674\tC\t\n23\t+149.961446\t+2.349389\t1.16\t21.60\t208\tB\t\n24\t+149.628310\t+2.354862\t0.88\t21.82\t1820\tB\t\n25\t+149.722715\t+2.428631\t1.19\t21.60\t359\tC\t\n26\t+150.571395\t+2.506658\t1.55\t20.18\t66\tC\t\n27\t+150.624611\t+2.540319\t0.88\t18.97\t910\tC\t\n28\t+150.694125\t+2.547939\t1.87\t21.52\t292\tC\t\n29\t+150.317117\t+2.531471\t2.71\t20.62\t1451\tB\t\n30\t+150.141624\t+2.464563\t1.65\t20.82\t86\tB\t\n31\t+150.063881\t+2.605824\t1.47\t21.50\t979\tB\t\n32\t+149.878942\t+2.574346\t0.97\t21.78\t573\tA\t\n33\t+149.542116\t+2.495012\t2.23\t19.03\t1505\tB\t\n34\t+150.747020\t+2.666027\t1.96\t21.36\t153\tC\t\n35\t+150.548642\t+2.766168\t0.84\t18.91\t1595\tB\t\n36\t+150.329391\t+2.671669\t2.44\t21.72\t1027\tB\t\n37\t+150.284903\t+2.674951\t1.53\t19.08\t321\tA\t\n38\t+150.250216\t+2.763947\t1.60\t20.72\t1515\tB\t\n39\t+150.101284\t+2.703268\t1.74\t22.58\t932\tB\t\n40\t+150.217548\t+2.659542\t1.11\t23.18\t1567\tC\t\n41\t+149.855932\t+2.650953\t0.87\t21.97\t1345\tB\t\n42\t+149.621847\t+2.733148\t2.33\t21.31\t1319\tB\t\n43\t+150.644507\t+2.808898\t1.02\t21.94\t1098\tB\t\n44\t+150.443480\t+2.847808\t1.55\t21.66\t1442\tC\t\n45\t+150.104053\t+2.844371\t2.24\t20.66\t222\tB\t\n46\t+149.611769\t+2.809775\t2.21\t22.29\t328\tB\t\n47^b\t+150.052500\t+2.337500\t0.90\t19.28\t2470\tA\t\n48^b\t+150.057917\t+2.380278\t1.65\t18.89\t910\tB\t\n49^b\t+150.076667\t+2.645833\t0.40\t23.60\t392\tA\t\n50^b\t+150.159167\t+2.692500\t0.74\t20.39\t13610\tA\t\n51^b\t+150.198333\t+1.839722\t0.70\t20.65\t2916\tA\t\n52^b\t+150.205000\t+1.857778\t2.22\t19.61\t693\tC\t\n53^b\t+150.210833\t+2.816944\t1.90\t21.72\t5333\tA\t\n54^b\t+150.236250\t+2.207222\t1.20\t18.70\t4041\tB\t\n55^b\t+150.352083\t+1.855833\t0.84\t22.43\t5125\tB\t\n56^b\t+150.570000\t+2.498611\t1.96\t19.98\t3521\tB\t\n57^b\t+150.614583\t+2.080833\t1.62\t21.94\t1495\tC\t\n58^b\t+150.725000\t+2.241667\t1.54\t18.85\t5783\tB\t\n59^b\t+149.494167\t+2.256944\t0.35\t22.27\t3868\tB\t\n60^b\t+149.737500\t+1.996944\t2.15\t20.05\t1164\tC\t\n61^b\t+149.811250\t+2.205278\t1.86\t23.25\t4700\tC\t\n62^b\t+149.840417\t+2.110556\t0.80\t20.34\t9218\tA\t\n63^b\t+149.949167\t+2.797778\t2.55\t19.83\t1\tC\t\n64^b\t+150.040417\t+2.415278\t2.63\t19.49\t8071\tB\t\n65^b\t+150.196250\t+2.491944\t2.00\t19.56\t13476\tA\t\n66^b\t+150.211667\t+2.065833\t0.66\t22.31\t1197\tB\t\n67^b\t+150.232083\t+1.639167\t1.05\t20.86\t616\tA\t\n68^b\t+150.272083\t+2.758611\t1.00\t20.38\t3204\tB\t\n69^b\t+150.334167\t+1.764167\t1.28\t21.31\t1300\tB\t\n70^b\t+150.450417\t+2.390278\t1.43\t18.81\t216\tC\t\n71^b\t+150.535417\t+2.239444\t1.59\t20.06\t8647\tB\t\n72^b\t+150.584167\t+2.393056\t1.04\t20.99\t283\tB\t\n73^b\t+150.587917\t+2.577778\t1.57\t19.35\t9564\tC\t\n74^b\t+150.650000\t+2.801944\t1.27\t20.15\t3865\tB\t\n75^b\t+149.450000\t+1.923333\t2.21\t22.15\t1236\tA\t\n76^b\t+149.461250\t+1.938611\t0.73\t19.19\t9936\tB\t\n77^b\t+149.467083\t+2.349167\t0.98\t20.27\t5965\tB\t\n78^b\t+149.475417\t+1.997778\t1.33\t22.23\t204\tB\t\n79^b\t+149.523333\t+2.070278\t1.61\t23.00\t3764\tB\t\n80^b\t+149.528333\t+1.969167\t1.50\t19.14\t2442\tB\t\n81^b\t+149.624583\t+1.626111\t2.97\t19.95\t12066\tB\t\n82^b\t+149.629167\t+1.725556\t1.17\t21.06\t2092\tA\t\n83^b\t+149.672500\t+2.779444\t0.93\t19.65\t177\tB\t\n84^b\t+149.733750\t+2.798611\t2.97\t19.54\t5951\tC\t\n85^b\t+149.870833\t+1.764722\t1.56\t19.99\t200\tB\t\n86^b\t+149.879583\t+2.041389\t1.48\t19.20\t894\tB\t\n87^b\t+149.883333\t+2.171667\t0.68\t21.92\t51\tB\t\n88^b\t+149.902917\t+2.605833\t2.40\t19.14\t7344\tC\t\n89^b\t+149.912917\t+2.512222\t0.70\t20.08\t93\tB\t\n90^b\t+149.918333\t+2.548056\t1.53\t19.45\t186\tB\t\n91^b\t+149.929583\t+2.471111\t1.64\t19.43\t2684\tC\t\n92^b\t+149.998750\t+2.063333\t1.20\t21.62\t44\tB\t\nNotes. The first column corresponds to the image number in Figure 10.\n^a Grade A corresponds to images that are clearly a strong gravitational lens. Grade B lenses correspond to images that are most likely a lens, but there is a chance they could also be artifacts, noise, structures in elliptical galaxies, satellite galaxies, tidally interacting galaxies, etc. Grade C lenses consist of images that are most likely not a lens, but there is a chance they might be gravitationally lensed.\n^b These marked lenses were previously cataloged by Faure et al. (2008).\n", "Action": "Scanned all subtables", "Table captions or footers": {"Overview": "Table 2 \nCatalog of Identified Lenses by LENSFLOW", "Info after table 1": "Notes. The first column corresponds to the image number in Figure 10.\n^a Grade A corresponds to images that are clearly a strong gravitational lens. Grade B lenses correspond to images that are most likely a lens, but there is a chance they could also be artifacts, noise, structures in elliptical galaxies, satellite galaxies, tidally interacting galaxies, etc. Grade C lenses consist of images that are most likely not a lens, but there is a chance they might be gravitationally lensed.\n^b These marked lenses were previously cataloged by Faure et al. (2008).\n"}, "Status": "Complete", "Link": "https://iopscience.iop.org/0004-637X/856/1/68/suppdata/apjaaae6at2_ascii.txt?doi=10.3847/1538-4357/aaae6a", "Pandas format": {"Table 2": {"Action": "Processed via pandas", "Status": "Complete", "Inspection": {"Notes": {"Skip cause table not important": ""}}}}}, "Table set 0": {"Response": "<!DOCTYPE html>\n<html lang=\"en\">\n\t<head>\n\t\t<meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\">\n\t\t\n\t\t\n<script type=\"text/javascript\">(window.NREUM||(NREUM={})).loader_config={licenseKey:\"b2bfaae1b6\",applicationID:\"723879338\"};window.NREUM||(NREUM={}),__nr_require=function(e,t,n){function r(n){if(!t[n]){var i=t[n]={exports:{}};e[n][0].call(i.exports,function(t){var i=e[n][1][t];return r(i||t)},i,i.exports)}return t[n].exports}if(\"function\"==typeof __nr_require)return __nr_require;for(var i=0;i<n.length;i++)r(n[i]);return r}({1:[function(e,t,n){function r(){}function i(e,t,n){return function(){return o(e,[u.now()].concat(c(arguments)),t?null:this,n),t?void 0:this}}var o=e(\"handle\"),a=e(6),c=e(7),f=e(\"ee\").get(\"tracer\"),u=e(\"loader\"),s=NREUM;\"undefined\"==typeof window.newrelic&&(newrelic=s);var d=[\"setPageViewName\",\"setCustomAttribute\",\"setErrorHandler\",\"finished\",\"addToTrace\",\"inlineHit\",\"addRelease\"],p=\"api-\",l=p+\"ixn-\";a(d,function(e,t){s[t]=i(p+t,!0,\"api\")}),s.addPageAction=i(p+\"addPageAction\",!0),s.setCurrentRouteName=i(p+\"routeName\",!0),t.exports=newrelic,s.interaction=function(){return(new r).get()};var m=r.prototype={createTracer:function(e,t){var n={},r=this,i=\"function\"==typeof t;return o(l+\"tracer\",[u.now(),e,n],r),function(){if(f.emit((i?\"\":\"no-\")+\"fn-start\",[u.now(),r,i],n),i)try{return t.apply(this,arguments)}catch(e){throw f.emit(\"fn-err\",[arguments,this,e],n),e}finally{f.emit(\"fn-end\",[u.now()],n)}}}};a(\"actionText,setName,setAttribute,save,ignore,onEnd,getContext,end,get\".split(\",\"),function(e,t){m[t]=i(l+t)}),newrelic.noticeError=function(e,t){\"string\"==typeof e&&(e=new Error(e)),o(\"err\",[e,u.now(),!1,t])}},{}],2:[function(e,t,n){function r(){return c.exists&&performance.now?Math.round(performance.now()):(o=Math.max((new Date).getTime(),o))-a}function i(){return o}var o=(new Date).getTime(),a=o,c=e(8);t.exports=r,t.exports.offset=a,t.exports.getLastTimestamp=i},{}],3:[function(e,t,n){function r(e,t){var n=e.getEntries();n.forEach(function(e){\"first-paint\"===e.name?d(\"timing\",[\"fp\",Math.floor(e.startTime)]):\"first-contentful-paint\"===e.name&&d(\"timing\",[\"fcp\",Math.floor(e.startTime)])})}function i(e,t){var n=e.getEntries();n.length>0&&d(\"lcp\",[n[n.length-1]])}function o(e){e.getEntries().forEach(function(e){e.hadRecentInput||d(\"cls\",[e])})}function a(e){if(e instanceof m&&!g){var t=Math.round(e.timeStamp),n={type:e.type};t<=p.now()?n.fid=p.now()-t:t>p.offset&&t<=Date.now()?(t-=p.offset,n.fid=p.now()-t):t=p.now(),g=!0,d(\"timing\",[\"fi\",t,n])}}function c(e){d(\"pageHide\",[p.now(),e])}if(!(\"init\"in NREUM&&\"page_view_timing\"in NREUM.init&&\"enabled\"in NREUM.init.page_view_timing&&NREUM.init.page_view_timing.enabled===!1)){var f,u,s,d=e(\"handle\"),p=e(\"loader\"),l=e(5),m=NREUM.o.EV;if(\"PerformanceObserver\"in window&&\"function\"==typeof window.PerformanceObserver){f=new PerformanceObserver(r);try{f.observe({entryTypes:[\"paint\"]})}catch(v){}u=new PerformanceObserver(i);try{u.observe({entryTypes:[\"largest-contentful-paint\"]})}catch(v){}s=new PerformanceObserver(o);try{s.observe({type:\"layout-shift\",buffered:!0})}catch(v){}}if(\"addEventListener\"in document){var g=!1,y=[\"click\",\"keydown\",\"mousedown\",\"pointerdown\",\"touchstart\"];y.forEach(function(e){document.addEventListener(e,a,!1)})}l(c)}},{}],4:[function(e,t,n){function r(e,t){if(!i)return!1;if(e!==i)return!1;if(!t)return!0;if(!o)return!1;for(var n=o.split(\".\"),r=t.split(\".\"),a=0;a<r.length;a++)if(r[a]!==n[a])return!1;return!0}var i=null,o=null,a=/Version\\/(\\S+)\\s+Safari/;if(navigator.userAgent){var c=navigator.userAgent,f=c.match(a);f&&c.indexOf(\"Chrome\")===-1&&c.indexOf(\"Chromium\")===-1&&(i=\"Safari\",o=f[1])}t.exports={agent:i,version:o,match:r}},{}],5:[function(e,t,n){function r(e){function t(){e(a&&document[a]?document[a]:document[i]?\"hidden\":\"visible\")}\"addEventListener\"in document&&o&&document.addEventListener(o,t,!1)}t.exports=r;var i,o,a;\"undefined\"!=typeof document.hidden?(i=\"hidden\",o=\"visibilitychange\",a=\"visibilityState\"):\"undefined\"!=typeof document.msHidden?(i=\"msHidden\",o=\"msvisibilitychange\"):\"undefined\"!=typeof document.webkitHidden&&(i=\"webkitHidden\",o=\"webkitvisibilitychange\",a=\"webkitVisibilityState\")},{}],6:[function(e,t,n){function r(e,t){var n=[],r=\"\",o=0;for(r in e)i.call(e,r)&&(n[o]=t(r,e[r]),o+=1);return n}var i=Object.prototype.hasOwnProperty;t.exports=r},{}],7:[function(e,t,n){function r(e,t,n){t||(t=0),\"undefined\"==typeof n&&(n=e?e.length:0);for(var r=-1,i=n-t||0,o=Array(i<0?0:i);++r<i;)o[r]=e[t+r];return o}t.exports=r},{}],8:[function(e,t,n){t.exports={exists:\"undefined\"!=typeof window.performance&&window.performance.timing&&\"undefined\"!=typeof window.performance.timing.navigationStart}},{}],ee:[function(e,t,n){function r(){}function i(e){function t(e){return e&&e instanceof r?e:e?f(e,c,o):o()}function n(n,r,i,o){if(!p.aborted||o){e&&e(n,r,i);for(var a=t(i),c=v(n),f=c.length,u=0;u<f;u++)c[u].apply(a,r);var d=s[w[n]];return d&&d.push([b,n,r,a]),a}}function l(e,t){h[e]=v(e).concat(t)}function m(e,t){var n=h[e];if(n)for(var r=0;r<n.length;r++)n[r]===t&&n.splice(r,1)}function v(e){return h[e]||[]}function g(e){return d[e]=d[e]||i(n)}function y(e,t){u(e,function(e,n){t=t||\"feature\",w[n]=t,t in s||(s[t]=[])})}var h={},w={},b={on:l,addEventListener:l,removeEventListener:m,emit:n,get:g,listeners:v,context:t,buffer:y,abort:a,aborted:!1};return b}function o(){return new r}function a(){(s.api||s.feature)&&(p.aborted=!0,s=p.backlog={})}var c=\"nr@context\",f=e(\"gos\"),u=e(6),s={},d={},p=t.exports=i();p.backlog=s},{}],gos:[function(e,t,n){function r(e,t,n){if(i.call(e,t))return e[t];var r=n();if(Object.defineProperty&&Object.keys)try{return Object.defineProperty(e,t,{value:r,writable:!0,enumerable:!1}),r}catch(o){}return e[t]=r,r}var i=Object.prototype.hasOwnProperty;t.exports=r},{}],handle:[function(e,t,n){function r(e,t,n,r){i.buffer([e],r),i.emit(e,t,n)}var i=e(\"ee\").get(\"handle\");t.exports=r,r.ee=i},{}],id:[function(e,t,n){function r(e){var t=typeof e;return!e||\"object\"!==t&&\"function\"!==t?-1:e===window?0:a(e,o,function(){return i++})}var i=1,o=\"nr@id\",a=e(\"gos\");t.exports=r},{}],loader:[function(e,t,n){function r(){if(!E++){var e=b.info=NREUM.info,t=p.getElementsByTagName(\"script\")[0];if(setTimeout(u.abort,3e4),!(e&&e.licenseKey&&e.applicationID&&t))return u.abort();f(h,function(t,n){e[t]||(e[t]=n)});var n=a();c(\"mark\",[\"onload\",n+b.offset],null,\"api\"),c(\"timing\",[\"load\",n]);var r=p.createElement(\"script\");r.src=\"https://\"+e.agent,t.parentNode.insertBefore(r,t)}}function i(){\"complete\"===p.readyState&&o()}function o(){c(\"mark\",[\"domContent\",a()+b.offset],null,\"api\")}var a=e(2),c=e(\"handle\"),f=e(6),u=e(\"ee\"),s=e(4),d=window,p=d.document,l=\"addEventListener\",m=\"attachEvent\",v=d.XMLHttpRequest,g=v&&v.prototype;NREUM.o={ST:setTimeout,SI:d.setImmediate,CT:clearTimeout,XHR:v,REQ:d.Request,EV:d.Event,PR:d.Promise,MO:d.MutationObserver};var y=\"\"+location,h={beacon:\"bam.nr-data.net\",errorBeacon:\"bam.nr-data.net\",agent:\"js-agent.newrelic.com/nr-1184.min.js\"},w=v&&g&&g[l]&&!/CriOS/.test(navigator.userAgent),b=t.exports={offset:a.getLastTimestamp(),now:a,origin:y,features:{},xhrWrappable:w,userAgent:s};e(1),e(3),p[l]?(p[l](\"DOMContentLoaded\",o,!1),d[l](\"load\",r,!1)):(p[m](\"onreadystatechange\",i),d[m](\"onload\",r)),c(\"mark\",[\"firstbyte\",a.getLastTimestamp()],null,\"api\");var E=0},{}],\"wrap-function\":[function(e,t,n){function r(e){return!(e&&e instanceof Function&&e.apply&&!e[a])}var i=e(\"ee\"),o=e(7),a=\"nr@original\",c=Object.prototype.hasOwnProperty,f=!1;t.exports=function(e,t){function n(e,t,n,i){function nrWrapper(){var r,a,c,f;try{a=this,r=o(arguments),c=\"function\"==typeof n?n(r,a):n||{}}catch(u){p([u,\"\",[r,a,i],c])}s(t+\"start\",[r,a,i],c);try{return f=e.apply(a,r)}catch(d){throw s(t+\"err\",[r,a,d],c),d}finally{s(t+\"end\",[r,a,f],c)}}return r(e)?e:(t||(t=\"\"),nrWrapper[a]=e,d(e,nrWrapper),nrWrapper)}function u(e,t,i,o){i||(i=\"\");var a,c,f,u=\"-\"===i.charAt(0);for(f=0;f<t.length;f++)c=t[f],a=e[c],r(a)||(e[c]=n(a,u?c+i:i,o,c))}function s(n,r,i){if(!f||t){var o=f;f=!0;try{e.emit(n,r,i,t)}catch(a){p([a,n,r,i])}f=o}}function d(e,t){if(Object.defineProperty&&Object.keys)try{var n=Object.keys(e);return n.forEach(function(n){Object.defineProperty(t,n,{get:function(){return e[n]},set:function(t){return e[n]=t,t}})}),t}catch(r){p([r])}for(var i in e)c.call(e,i)&&(t[i]=e[i]);return t}function p(t){try{e.emit(\"internal-error\",t)}catch(n){}}return e||(e=i),n.inPlace=u,n.flag=a,n}},{}]},{},[\"loader\"]);</script><script>\n\t\t\tfunction DeferJS(src) {\n\t\t\tfunction downloadJSAtOnload() {\n\t\t\tvar element = document.createElement(\"script\");\n\t\t\telement.src = src;\n\t\t\tdocument.body.appendChild(element);\n\t\t\t}\n\t\t\tif (window.addEventListener)\n\t\t\twindow.addEventListener(\"load\", downloadJSAtOnload, false);\n\t\t\telse if (window.attachEvent)\n\t\t\twindow.attachEvent(\"onload\", downloadJSAtOnload);\n\t\t\telse window.onload = downloadJSAtOnload;\n\t\t\t}\n\t\t</script>\n\t\t<script>\n\t\t\tDeferJS(\"https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js\");\n\t\t</script>\n\t\t<script>\n\t\t\tDeferJS(\"https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js\");\n\t\t</script>\n\t\t<script>\n                DeferJS(\"https://badge.dimensions.ai/badge.js\");\n\t\t\t</script>\n\t\t<script>\n                DeferJS(\"https://badge.dimensions.ai/badge.js\");\n\t\t\t</script>\n\t\t<script>\n                DeferJS(\"https://badge.dimensions.ai/badge.js\");\n\t\t\t</script>\n\t\t<script>\n\t\t\tvar _urconfig = { sid: \"defc3a7d-4b34-4b6f-ad1c-0716e0a05a65\", aip: 0, usePageProtocol: false };\n\t\t\t(function (d, s)\n\t\t\t\n\t\t\t{ var js = d.createElement(s), sc = d.getElementsByTagName(s)[0]; js.src = \"https://hit.uptrendsdata.com/rum.min.js\"; js.async = \"async\"; sc.parentNode.insertBefore(js, sc); }\n\t\t\t(document, \"script\"));\n\t\t</script>\n\t\t<meta charset=\"utf-8\">\n\t\t<meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n\t\t<meta name=\"robots\" content=\"noarchive\">\n\t\t<title>LensFlow: A Convolutional Neural Network in Search of Strong Gravitational Lenses - IOPscience</title>\n\t\t\t<meta name=\"citation_journal_title\" content=\"The Astrophysical Journal\"></meta><meta name=\"citation_journal_abbrev\" content=\"ApJ\"></meta><meta name=\"citation_issn\" content=\"0004-637X\"></meta><meta name=\"citation_publisher\" content=\"IOP Publishing\"></meta><meta name=\"citation_author\" content=\"Milad Pourrahmani\"></meta><meta name=\"citation_author\" content=\"Hooshang Nayyeri\"></meta><meta name=\"citation_author\" content=\"Asantha Cooray\"></meta><meta name=\"citation_title\" content=\"LensFlow: A Convolutional Neural Network in Search of Strong Gravitational Lenses\"></meta><meta name=\"citation_online_date\" content=\"2018-03-26\"></meta><meta name=\"citation_publication_date\" content=\"2018-03-26\"></meta><meta name=\"citation_volume\" content=\"856\"></meta><meta name=\"citation_issue\" content=\"1\"></meta><meta name=\"citation_firstpage\" content=\"68\"></meta><meta name=\"citation_doi\" content=\"10.3847/1538-4357/aaae6a\"></meta><meta name=\"citation_abstract_html_url\" content=\"https://iopscience.iop.org/article/10.3847/1538-4357/aaae6a/meta\"></meta><meta name=\"citation_pdf_url\" content=\"https://iopscience.iop.org/article/10.3847/1538-4357/aaae6a/pdf\"></meta><meta name=\"citation_xml_url\" content=\"https://iopscience.iop.org/article/10.3847/1538-4357/aaae6a/xml\"></meta><meta name=\"citation_fulltext_html_url\" content=\"https://iopscience.iop.org/article/10.3847/1538-4357/aaae6a\"></meta><meta name=\"citation_language\" content=\"en\"></meta><meta name=\"citation_reference\" content=\"Abadi M., Agarwal A., Barham P. et al 2016 arXiv:1603.04467\"/><meta name=\"citation_reference\" content=\"Agnello A., Lin H., Buckley-Geer L. et al 2017 MNRAS 472 4038\"/><meta name=\"citation_reference\" content=\"Alard C. 2006 arXiv:astro-ph/0606757\"/><meta name=\"citation_reference\" content=\"Atek H., Richard J., Kneib J.-P. et al 2015 ApJ 800 18\"/><meta name=\"citation_reference\" content=\"Blandford R. and Narayan R. 1992 ARA&amp;A 30 311\"/><meta name=\"citation_reference\" content=\"Bolton A. S., Burles S., Koopmans L. V., Treu T. and Moustakas L. A. 2006 ApJ 638 703\"/><meta name=\"citation_reference\" content=\"Broadhurst T., Ben&#237;tez N., Coe D. et al 2005 ApJ 621 53\"/><meta name=\"citation_reference\" content=\"Calanog J. A., Fu H., Cooray A. et al 2014 ApJ 797 138\"/><meta name=\"citation_reference\" content=\"Capak P., Aussel H., Ajiki M. et al 2007 ApJS 172 99\"/><meta name=\"citation_reference\" content=\"Coe D., Zitrin A., Carrasco M. et al 2012 ApJ 762 32\"/><meta name=\"citation_reference\" content=\"Eigenbrod A., Courbin F., Vuissoz C. et al 2005 A&amp;A 436 25\"/><meta name=\"citation_reference\" content=\"Faure C., Kneib J.-P., Covone G. et al 2008 ApJS 176 19\"/><meta name=\"citation_reference\" content=\"Fu H., Jullo E., Cooray A. et al 2012 ApJ 753 134\"/><meta name=\"citation_reference\" content=\"Gavazzi R., Marshall P. J., Treu T. and Sonnenfeld A. 2014 ApJ 785 144\"/><meta name=\"citation_reference\" content=\"Glorot X. and Bengio Y. 2010 Proc. Machine Learning Research 9, Proc. 13th Int. Conf. Artificial Intelligence and Statistics ed Y. W. Teh and M. Titterington (Chia Laguna Resort, Sardinia: PMLR) 249\"/><meta name=\"citation_reference\" content=\"Goobar A., Amanullah R., Kulkarni S. R. et al 2017 Sci 356 291\"/><meta name=\"citation_reference\" content=\"Grogin N. A., Kocevski D. D., Faber S. et al 2011 ApJS 197 35\"/><meta name=\"citation_reference\" content=\"He K., Zhang X., Ren S. and Sun J. 2016 Proc. IEEE Conf. Computer Vision and Pattern Recognition ed R. Bajcsy (Washington, DC: IEEE) 770\"/><meta name=\"citation_reference\" content=\"Heymans C., Van Waerbeke L., Miller L. et al 2012 MNRAS 427 146\"/><meta name=\"citation_reference\" content=\"Jacobs C., Glazebrook K., Collett T., More A. and McCarthy C. 2017 MNRAS 471 167\"/><meta name=\"citation_reference\" content=\"Jullo E., Kneib J.-P., Limousin M. et al 2007 NJPh 9 447\"/><meta name=\"citation_reference\" content=\"Kaiser N. and Squires G. 1993 ApJ 404 441\"/><meta name=\"citation_reference\" content=\"Kingma D. P. and Ba J. 2014 arXiv:1412.6980\"/><meta name=\"citation_reference\" content=\"Koekemoer A. M., Faber S., Ferguson H. C. et al 2011 ApJS 197 36\"/><meta name=\"citation_reference\" content=\"Komatsu E., Dunkley J., Nolta M. et al 2009 ApJS 180 330\"/><meta name=\"citation_reference\" content=\"Krizhevsky A. and Hinton G. 2009 Learning Multiple Layers of Features from Tiny Images (State College, PA: Citeseer)\"/><meta name=\"citation_reference\" content=\"Krizhevsky A., Sutskever I. and Hinton G. E. 2012 Proc. Advances Neural Information Processing Systems 25 Conf. ed F. Pereira et al (La Jolla, CA: NIPS Foundation) https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks\"/><meta name=\"citation_reference\" content=\"Lanusse F., Ma Q., Li N. et al 2018 MNRAS 473 3895\"/><meta name=\"citation_reference\" content=\"Lenzen F., Schindler S. and Scherzer O. 2004 A&amp;A 416 391\"/><meta name=\"citation_reference\" content=\"Lotz J., Koekemoer A., Coe D. et al 2017 ApJ 837 97\"/><meta name=\"citation_reference\" content=\"Marshall P. J., Lintott C. J. and Fletcher L. N. 2015 ARA&amp;A 53 247\"/><meta name=\"citation_reference\" content=\"More A., Cabanac R., More S. et al 2012 ApJ 749 38\"/><meta name=\"citation_reference\" content=\"More A., Suyu S. H., Oguri M., More S. and Lee C.-H. 2017 ApJL 835 L25\"/><meta name=\"citation_reference\" content=\"More A., Verma A., Marshall P. J. et al 2016 MNRAS 455 1191\"/><meta name=\"citation_reference\" content=\"Nayyeri H., Cooray A., Jullo E. et al 2017 ApJ 844 82\"/><meta name=\"citation_reference\" content=\"Nayyeri H., Keele M., Cooray A. et al 2016 ApJ 823 17\"/><meta name=\"citation_reference\" content=\"Nielsen M. 2016 Neural Networks and Deep Learning http://neuralnetworksanddeeplearning.com/chap3.html\"/><meta name=\"citation_reference\" content=\"Oesch P., Bouwens R., Illingworth G. et al 2015 ApJ 808 104\"/><meta name=\"citation_reference\" content=\"Oke J. and Gunn J. 1983 ApJ 266 713\"/><meta name=\"citation_reference\" content=\"Pedersen M. E. H. 2016 Hvass-Labs https://github.com/Hvass-Labs/TensorFlow-Tutorials\"/><meta name=\"citation_reference\" content=\"Peng C. Y., Impey C. D., Rix H.-W. et al 2006 ApJ 649 616\"/><meta name=\"citation_reference\" content=\"Petrillo C. E., Tortora C., Chatterjee S. et al 2017 MNRAS 472 1129\"/><meta name=\"citation_reference\" content=\"Postman M., Coe D., Ben&#237;tez N. et al 2012 ApJS 199 25\"/><meta name=\"citation_reference\" content=\"Pourrahmani M., Nayyeri H. and Cooray A. 2018 LensFlow Zenodo, doi:10.5281/zenodo.1163024\"/><meta name=\"citation_reference\" content=\"Refsdal S. and Bondi H. 1964 MNRAS 128 295\"/><meta name=\"citation_reference\" content=\"Rodney S. A., Strolger L.-G., Kelly P. L. et al 2016 ApJ 820 50\"/><meta name=\"citation_reference\" content=\"Scoville N., Abraham R., Aussel H. et al 2007 ApJS 172 38\"/><meta name=\"citation_reference\" content=\"Spilker J. S., Marrone D. P., Aravena M. et al 2016 ApJ 826 112\"/><meta name=\"citation_reference\" content=\"Suyu S., Auger M., Hilbert S. et al 2013 ApJ 766 70\"/><meta name=\"citation_reference\" content=\"Suyu S., Treu T., Hilbert S. et al 2014 ApJL 788 L35\"/><meta name=\"citation_reference\" content=\"Tegmark M., Strauss M. A., Blanton M. R. et al 2004 PhRvD 69 103501\"/><meta name=\"citation_reference\" content=\"Timmons N., Cooray A., Riechers D. A. et al 2016 ApJ 829 21\"/><meta name=\"citation_reference\" content=\"Treu T. 2010 ARA&amp;A 48 87\"/><meta name=\"citation_reference\" content=\"Treu T. and Marshall P. J. 2016 A&amp;ARv 24 11\"/><meta name=\"citation_reference\" content=\"Treu T., Schmidt K., Brammer G. et al 2015 ApJ 812 114\"/><meta name=\"citation_reference\" content=\"Velander M., van Uitert E., Hoekstra H. et al 2014 MNRAS 437 2111\"/><meta name=\"citation_reference\" content=\"Wardlow J. L., Cooray A., De Bernardis F. et al 2012 ApJ 762 59\"/><meta name=\"citation_reference\" content=\"Weinberg D. H., Mortonson M. J., Eisenstein D. J. et al 2013 PhR 530 87\"/><meta name=\"citation_reference\" content=\"Wilson D., Cooray A., Nayyeri H. et al 2017 ApJ 848 30\"/><meta name=\"dc.publisher\" content=\"IOP Publishing\" lang=\"en\"></meta><meta name=\"dc.date\" content=\"2018 March 20\" scheme=\"W3CDTF\"></meta><meta name=\"dc.type\" content=\"Text\" scheme=\"DCMIType\"></meta><meta name=\"dc.format\" content=\"text/html\" scheme=\"IMT\"></meta><meta name=\"dc.identifier\" content=\"doi:10.3847/1538-4357/aaae6a\"></meta><meta name=\"dc.language\" content=\"en\"></meta><meta name=\"dc.creator\" content=\"Milad Pourrahmani\"></meta><meta name=\"dc.creator\" content=\"Hooshang Nayyeri\"></meta><meta name=\"dc.creator\" content=\"Asantha Cooray\"></meta><meta name=\"viewport\" content=\"width=device-width, initial-scale=1, minimum-scale=1.0\">\n\t\t<!-- Note Gridset ref 35089 -->\n<link rel=\"stylesheet\" href=\"https://static.iopscience.com/2.44.0/css/critical-styles.min.css\" type=\"text/css\" />\n<link rel=\"stylesheet\" href=\"https://static.iopscience.com/2.44.0/css/all-styles.min.css\" media=\"print\" onload=\"this.media='all'\">\n\n<!--[if lte IE 10]>\n<link rel=\"stylesheet\" href=\"https://static.iopscience.com/2.44.0/css/gridset-ie-lte8.css\" type=\"text/css\" />\n<![endif]-->\n<!-- Google Tag Manager -->\n<script type=\"text/javascript\">\n        (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push(\n        {'gtm.start': new Date().getTime(),event:'gtm.js'}\n        );var f=d.getElementsByTagName(s)[0],\n        j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=\n        'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);\n        })(window,document,'script','dataLayer','GTM-M73Z4W');\n    </script>\n<!-- End Google Tag Manager --><!-- Google Scholar Universal Casa -->\n    <script src=\"https://scholar.google.com/scholar_js/casa.js\" async></script>\n    <!-- End Google Scholar Universal Casa -->\n<script>\n\t\t/*  Cutting the mustard - http://responsivenews.co.uk/post/18948466399/cutting-the-mustard */\n\t\t\n\t\t/* Below is the original if statement, from the link above. I have amended it to turn of JS on all IE browsers less than 10.\n\t\tThis is due to a function in the iop.jquery.toolbar line 35/36. Uses .remove which is not native js supported in IE9 or lower */\n\t\t/*if('querySelector' in document\n\t\t&& 'localStorage' in window\n\t\t&& 'addEventListener' in window)*/\n\t\t\n\t\t/* This is the updated selector, taken from: https://justmarkup.com/log/2015/02/26/cut-the-mustard-revisited/ */\n\t\tif('visibilityState' in document) {\n\t\t\n\t\t/*! loadJS: load a JS. We are loading this command straight away, before the body loads, so that IF a user has JS enabled, their show hide panels will automatically be closed. */\n\t\t/* If this isn't here, then these panels appear open while the page is loading, then when the js loads at the bottom of the page, they are shut. So the users sees open content, then hidden after a second or 2 when the js is loaded. Not nice */\n\t\tdocument.write(\"<style>.reveal-content{display:none;}.search-res-filter .reveal-content{display:block;}</style>\");\n\t\t}\n\t\t</script>\n\t\t<script>var __uzdbm_1 = \"3c1c769b-cc1f-4878-8c52-d7f85411c6e4\";var __uzdbm_2 = \"NzEwY2ZmNjMtODQyNy00MjYzLWFjOTAtMTE3N2VkNzkxNTgxJDE1NS4xMDEuMjYuNjY=\";</script> <script>(function(w, d, e, u, c, g, a, b){ w[\"SSJSConnectorObj\"] = {ss_cid : c, domain_info: \"auto\"}; a = d.createElement(e); a.async = true; a.src = u; b = d.getElementsByTagName(e)[0]; b.parentNode.insertBefore(a, b); })(window,document,\"script\",\"https://cdn.perfdrive.com/aperture/aperture.js\",\"a1c3\",\"ssConf\");</script></head>\n\t<body itemscope itemtype=\"http://schema.org/Organization\" class=\"issn-0004-637X\">\n    <a id=\"back-to-top-target\" tabindex=\"-1\"></a>\n    <!-- Google Tag Manager (noscript) -->\n<noscript><iframe src=\"https://www.googletagmanager.com/ns.html?id=GTM-M73Z4W\"\n    height=\"0\" width=\"0\" style=\"display:none;visibility:hidden\"></iframe></noscript>\n<!-- End Google Tag Manager (noscript) --><div class=\"cookies-banner-wrap\" id=\"cookieBanner\">\n    <div class=\"cookies-banner cf\">\n        This site uses cookies. By continuing to use this site you agree to our use of cookies. To find out more, see our\n        <a href=\"http://ioppublishing.org/privacyPolicy\">Privacy and Cookies</a> policy.\n        <div class=\"cookies-banner-close\">\n            <span role=\"button\" tabindex=\"0\" class=\"icon-close large\"><span class=\"offscreen-hidden\">Close this notification</span></span>\n        </div>\n    </div>\n</div><!-- Start Production toolbar -->\n<!-- End Production toolbar --><!-- Start Downtime Banner -->\n<!-- End Downtime Banner --><!-- Header tile starts -->\n<header role=\"banner\" data-nav-group>\n\t<div class=\"accessibility\" style=\"display: none;\">\n\t    <p><strong>Accessibility Links</strong></p>\n\t    <ul>\n\t        <li><a href=\"#page-content\">Skip to content</a></li>\n\t        <li><a href=\"/search#contentCol\">Skip to search IOPscience</a></li>\n\t        <li><a href=\"/journals#contentCol\">Skip to Journals list</a></li>\n\t        <li><a href=\"/page/accessibility#contentCol\">Accessibility help</a></li>\n\t    </ul>\n\t</div>\n    <div class=\"wrapper dgh-showgrid tgh-showgrid cf\" name=\"contentCol\">\n\n        <div id=\"mobile-header\" class=\"ta-hide da-hide wd-mobile-nav\">\n            <a title=\"Menu\" href=\"#sidr-main\" id=\"simple-menu\" class=\"icon-menu\"></a>\n        </div>\n\n        <a href=\"/\" itemprop=\"url\" class=\"header-logo wd-header-graphic\">\n            <meta itemprop=\"name\" content=\"IOPscience\">\n            <svg height=\"15\" width=\"100\">\n                <image xlink:href=\"https://static.iopscience.com/2.44.0/img/iops-logo.svg\" src=\"https://static.iopscience.com/2.44.0/img/iops-logo.png\" height=\"15\" width=\"100\" border=\"0\" itemprop=\"logo\" />\n            </svg>\n            <span class=\"offscreen-hidden\">IOP Science home</span>\n        </a>\n\n        <section role=\"region\" aria-label=\"Accessibility links\">\n            <div class=\"accessibility-skip-links\">\n                <ul>\n                    <li>\n                        <a class=\"btn btn-default\" href=\"#skip-to-content-link-target\">Skip to content</a>\n                    </li>\n                    <li>\n                        <a class=\"btn btn-default\" id=\"accessibility-help\" href=\"/page/accessibility#skip-to-content-link-target\">Accessibility Help</a>\n                    </li>\n                </ul>\n            </div>\n        </section>\n\n        <nav role=\"navigation\" id=\"sidr\" class=\"m-hide wd-main-nav\" aria-label=\"Site\">\n            <button class=\"nav-top-link-drop-down nav-item nav-search\" data-nav-trigger=\"articlelookup\" aria-expanded=\"false\" aria-controls=\"nav-dropdown-articlelookup\">\n                <img src=\"https://static.iopscience.com/2.44.0/img/icon-search.svg\" alt=\"\">\n                <span class=\"offscreen-hidden\">Search</span>\n            </button>\n            <div class=\"nav-journals nav-item wd-nav-journal\">\n                <a class=\"nav-top-link-drop-down\" href=\"/journals\" data-nav-trigger=\"journals\">Journals<span class=\"icon-arrow-down\"></span></a>\n\n                <div class=\"nav-drop-down wd-nav-journal-dd\" data-nav-item=\"journals\">\n                    <a href=\"/journals\">\n                        Journals list\n                        <div class=\"m-hide\">Browse more than 100 science journal titles</div>\n                    </a>\n\n                    <a href=\"/page/subjects\">\n                        Subject collections\n                        <div class=\"m-hide\">Read the very best research published in IOP journals</div>\n                    </a>\n\n                    <a href=\"/journals?type=partner#js-tab-pubpart\">\n                        Publishing partners\n                        <div class=\"m-hide\">Partner organisations and publications</div>\n                    </a>\n\n                    <a href=\"/info/page/openaccess\">\n                        Open access\n                        <div class=\"m-hide\">IOP Publishing open access policy guide</div>\n                    </a>\n\n                    <a href=\"http://conferenceseries.iop.org/\">\n                        IOP Conference Series\n                        <div class=\"m-hide\">Read open access proceedings from science conferences worldwide</div>\n                    </a>\n                </div>\n            </div>\n\n            <div class=\"nav-books nav-item wd-nav-books\">\n                <a href=\"/books\" class=\"nav-top-link\">Books</a>\n            </div>\n\n            <div class=\"nav-publishing-support nav-item wd-publishing-support\">\n                    <a href=\"https://publishingsupport.iopscience.iop.org\" class=\"nav-top-link\">Publishing Support</a>\n                </div>\n            <!-- Header Login tile starts here -->\n           <div class=\"nav-login nav-item wd-nav-login\">\n<a class=\"nav-top-link-drop-down\" id=\"login-drop-down-user\" href=\"https://myiopscience.iop.org/signin?origin=a0&return=https%3A%2F%2Fiopscience.iop.org%2Farticle%2F10.3847%2F1538-4357%2Faaae6a\" data-nav-trigger=\"login\"><span class=\"nav-top-username\">Login</span><span class=\"icon-arrow-down\"></span></a>\n<div class=\"nav-drop-down wd-nav-login-dd\" data-nav-item=\"login\">\n\n    <div class='CMS-content'><p id=\"wd-login-dropdown__heading\" class=\"replica-h3 mt-0\">Reset your password</p>\n            <p id=\"wd-login-dropdown__body\" class=\"small\">If you have a user account, you will need to reset your password the next time you login. You will only need to do this once. <a href=\"/page/improvement-to-the-iopscience-login-process\" aria-label=\"Find out more about the new I O P science login\">Find out more</a>.</p></div><a class=\"btn btn-default mt-05 mb-05 d-b\" href=\"https://myiopscience.iop.org/signin?origin=a0&return=https%3A%2F%2Fiopscience.iop.org%2Farticle%2F10.3847%2F1538-4357%2Faaae6a\" id=\"wd-login-link\">IOPscience login / Sign Up</a>\n        <div class=\"bdt-1\">\n\n        <div class='CMS-content'><div class=\"eyebrow eyebrow--small eyebrow--marg-top-05\"><span class=\"red\">Please note:</span></div>\n<p id=\"wd-login-dropdown__athens-info\" class=\"small mb-0\">You do not need to reset your password if you login via Athens or an Institutional login.</p></div><a class=\"btn btn-primary mt-05 mb-05 d-b\" href=\"https://ticket.iop.org/inst_login?return=https%3A%2F%2Fiopscience.iop.org%2Farticle%2F10.3847%2F1538-4357%2Faaae6a\">Athens / Institution login</a>\n    </div>\n</div>\n</div><!-- Header Login tile ends here -->\n        </nav>\n    </div>\n\n    <div class=\"art-lookup-panel m-hide nav-drop-down\" data-nav-item=\"articlelookup\">\n    <div class=\"wrapper wrapper--search cf\">\n        <a title=\"Close\" class=\"close-icon art-lookup__close\" tabindex=\"0\" role=\"button\" aria-describedby=\"close-search-description\">\n            <span class=\"icon-close\"></span>\n        </a>\n        <p id=\"close-search-description\" class=\"offscreen-hidden\">Click here to close this panel.</p>\n\n        <div id=\"search\" class=\"wd-header-search art-lookup__search\">\n    <form accept-charset=\"utf-8,iso-8859-1\" class=\"primary-search\" method=\"get\" action=\"/nsearch\" role=\"search\">\n        <fieldset aria-labelledby=\"search-legend\">\n            <div class=\"art-lookup__fields-wrapper\">\n                <div id=\"search-legend\" class=\"offscreen-hidden\">Primary search</div>\n                <label for=\"quickSearch\">Search all IOPscience content</label>\n\n            <input type=\"text\" x-webkit-speech=\"\" name=\"terms\" id=\"quickSearch\" class=\"art-lookup__field--grow\"\n                   placeholder=\"Search all IOPscience content\" value=\"\"/>\n            <input type=\"submit\" x-webkit-speech=\"\" value=\"Search\" class=\"btn btn-default hdr-search-btn bd-0 art-lookup__submit\">\n\n            </div>\n        </fieldset>\n    </form>\n</div>\n<div id=\"wd-content-finder\" class=\"art-lookup__content-finder\">\n            <form accept-charset=\"utf-8,iso-8859-1\" method=\"get\" action=\"/findcontent\" name=\"contentFinderForm\"\n      id=\"wd-find-art-form\" class=\"cf find-article-issue-display\" autocomplete=\"OFF\">\n    <fieldset aria-labelledby=\"content-finder-legend\">\n        <div id=\"content-finder-legend\" class=\"eyebrow eyebrow--blue\">Article Lookup</div>\n        <div class=\"art-lookup__fields-wrapper\">\n\n            <label for=\"CF_JOURNAL\" class=\"offscreen-hidden\">Select journal (required)</label>\n            <select name=\"CF_JOURNAL\"\n        id=\"CF_JOURNAL\"class=\"find-article-select art-lookup__content-finder-field art-lookup__field--grow art-lookup__content-finder-field--first\" >\n    <option value=\"none\"  hidden disabled>Select journal (required)</option>\n<option value=\"2053-1583\"   >2D Mater. (2014 - present)</option>\n<option value=\"1004-423X\"   >Acta Phys. Sin. (Overseas Edn) (1992 - 1999)</option>\n<option value=\"2043-6262\"   >Adv. Nat. Sci: Nanosci. Nanotechnol. (2010 - present)</option>\n<option value=\"1882-0786\"   >Appl. Phys. Express (2008 - present)</option>\n<option value=\"1758-5090\"   >Biofabrication (2009 - present)</option>\n<option value=\"1748-3190\"   >Bioinspir. Biomim. (2006 - present)</option>\n<option value=\"1748-605X\"   >Biomed. Mater. (2006 - present)</option>\n<option value=\"2057-1976\"   >Biomed. Phys. Eng. Express (2015 - present)</option>\n<option value=\"0508-3443\"   >Br. J. Appl. Phys. (1950 - 1967)</option>\n<option value=\"1009-9271\"   >Chin. J. Astron. Astrophys. (2001 - 2008)</option>\n<option value=\"1003-7713\"   >Chin. J. Chem. Phys. (1987 - 2007)</option>\n<option value=\"1674-0068\"   >Chin. J. Chem. Phys. (2008 - 2012)</option>\n<option value=\"1009-1963\"   >Chinese Phys. (2000 - 2007)</option>\n<option value=\"1674-1056\"   >Chinese Phys. B (2008 - present)</option>\n<option value=\"1674-1137\"   >Chinese Phys. C (2008 - present)</option>\n<option value=\"0256-307X\"   >Chinese Phys. Lett. (1984 - present)</option>\n<option value=\"0264-9381\"   >Class. Quantum Grav. (1984 - present)</option>\n<option value=\"0143-0815\"   >Clin. Phys. Physiol. Meas. (1980 - 1992)</option>\n<option value=\"0253-6102\"   >Commun. Theor. Phys. (1982 - present)</option>\n<option value=\"1749-4699\"   >Comput. Sci. Disc. (2008 - 2015)</option>\n<option value=\"2057-1739\"   >Converg. Sci. Phys. Oncol. (2015 - 2018)</option>\n<option value=\"0967-1846\"   >Distrib. Syst. Engng. (1993 - 1999)</option>\n<option value=\"2162-8734\"   >ECS Electrochem. Lett. (2012 - 2015)</option>\n<option value=\"2162-8777\"   >ECS J. Solid State Sci. Technol. (2012 - present)</option>\n<option value=\"2162-8750\"   >ECS Solid State Lett. (2012 - 2015)</option>\n<option value=\"1938-5862\"   >ECS Trans. (2005 - present)</option>\n<option value=\"0295-5075\"   >EPL (1986 - present)</option>\n<option value=\"1944-8783\"   >Electrochem. Soc. Interface (1992 - present)</option>\n<option value=\"1944-8775\"   >Electrochem. Solid-State Lett. (1998 - 2012)</option>\n<option value=\"2516-1075\"   >Electron. Struct. (2019 - present)</option>\n<option value=\"2631-8695\"   >Eng. Res. Express (2019 - present)</option>\n<option value=\"2515-7620\"   >Environ. Res. Commun. (2018 - present)</option>\n<option value=\"1748-9326\"   >Environ. Res. Lett. (2006 - present)</option>\n<option value=\"2634-4505\"   >Environ. Res.: Infrastruct. Sustain. (2021 - present)</option>\n<option value=\"0143-0807\"   >Eur. J. Phys. (1980 - present)</option>\n<option value=\"2058-8585\"   >Flex. Print. Electron. (2015 - present)</option>\n<option value=\"1873-7005\"   >Fluid Dyn. Res. (1986 - present)</option>\n<option value=\"2631-6331\"   >Funct. Compos. Struct. (2018 - present)</option>\n<option value=\"1755-1315\"   >IOP Conf. Ser.: Earth Environ. Sci. (2008 - present)</option>\n<option value=\"1757-899X\"   >IOP Conf. Ser.: Mater. Sci. Eng. (2009 - present)</option>\n<option value=\"2633-1357\"   >IOP SciNotes (2020 - present)</option>\n<option value=\"2631-7990\"   >Int. J. Extrem. Manuf. (2019 - present)</option>\n<option value=\"0266-5611\"   >Inverse Problems (1985 - present)</option>\n<option value=\"1064-5632\"   >Izv. Math. (1995 - present)</option>\n<option value=\"1752-7163\"   >J. Breath Res. (2007 - present)</option>\n<option value=\"1475-7516\"   >J. Cosmol. Astropart. Phys. (2003 - present)</option>\n<option value=\"1945-7111\"   >J. Electrochem. Soc. (1902 - present)</option>\n<option value=\"1742-2140\"   >J. Geophys. Eng. (2004 - 2018)</option>\n<option value=\"1126-6708\"   >J. High Energy Phys. (1997 - 2009)</option>\n<option value=\"1748-0221\"   >J. Inst. (2006 - present)</option>\n<option value=\"0960-1317\"   >J. Micromech. Microeng. (1991 - present)</option>\n<option value=\"1741-2552\"   >J. Neural Eng. (2004 - present)</option>\n<option value=\"0368-3281\"   >J. Nucl. Energy, Part C Plasma Phys. (1959 - 1966)</option>\n<option value=\"0150-536X\"   >J. Opt. (1977 - 1998)</option>\n<option value=\"2040-8986\"   >J. Opt. (2010 - present)</option>\n<option value=\"1464-4258\"   >J. Opt. A: Pure Appl. Opt. (1999 - 2009)</option>\n<option value=\"1464-4266\"   >J. Opt. B: Quantum Semiclass. Opt. (1999 - 2005)</option>\n<option value=\"0022-3689\"   >J. Phys. A: Gen. Phys. (1968 - 1972)</option>\n<option value=\"0305-4470\"   >J. Phys. A: Math. Gen. (1975 - 2006)</option>\n<option value=\"0301-0015\"   >J. Phys. A: Math. Nucl. Gen. (1973 - 1974)</option>\n<option value=\"1751-8121\"   >J. Phys. A: Math. Theor. (2007 - present)</option>\n<option value=\"0953-4075\"   >J. Phys. B: At. Mol. Opt. Phys. (1988 - present)</option>\n<option value=\"0022-3700\"   >J. Phys. B: At. Mol. Phys. (1968 - 1987)</option>\n<option value=\"0022-3719\"   >J. Phys. C: Solid State Phys. (1968 - 1988)</option>\n<option value=\"2399-6528\"   >J. Phys. Commun. (2017 - present)</option>\n<option value=\"2632-072X\"   >J. Phys. Complex. (2019 - present)</option>\n<option value=\"0022-3727\"   >J. Phys. D: Appl. Phys. (1968 - present)</option>\n<option value=\"0022-3735\"   >J. Phys. E: Sci. Instrum. (1968 - 1989)</option>\n<option value=\"2515-7655\"   >J. Phys. Energy (2018 - present)</option>\n<option value=\"0305-4608\"   >J. Phys. F: Met. Phys. (1971 - 1988)</option>\n<option value=\"0954-3899\"   >J. Phys. G: Nucl. Part. Phys. (1989 - present)</option>\n<option value=\"0305-4616\"   >J. Phys. G: Nucl. Phys. (1975 - 1988)</option>\n<option value=\"2515-7639\"   >J. Phys. Mater. (2018 - present)</option>\n<option value=\"2515-7647\"   >J. Phys. Photonics (2018 - present)</option>\n<option value=\"0953-8984\"   >J. Phys.: Condens. Matter (1989 - present)</option>\n<option value=\"1742-6596\"   >J. Phys.: Conf. Ser. (2004 - present)</option>\n<option value=\"0952-4746\"   >J. Radiol. Prot. (1988 - present)</option>\n<option value=\"0950-7671\"   >J. Sci. Instrum. (1923 - 1967)</option>\n<option value=\"1674-4926\"   >J. Semicond. (2009 - present)</option>\n<option value=\"0260-2814\"   >J. Soc. Radiol. Prot. (1981 - 1987)</option>\n<option value=\"1742-5468\"   >J. Stat. Mech. (2004 - present)</option>\n<option value=\"1347-4065\"   >Jpn. J. Appl. Phys. (1962 - present)</option>\n<option value=\"1555-6611\"   >Laser Phys. (2013 - present)</option>\n<option value=\"1612-202X\"   >Laser Phys. Lett. (2004 - present)</option>\n<option value=\"2632-2153\"   >Mach. Learn.: Sci. Technol. (2019 - present)</option>\n<option value=\"2633-4356\"   >Mater. Quantum Technol. (2020 - present)</option>\n<option value=\"2053-1591\"   >Mater. Res. Express (2014 - present)</option>\n<option value=\"0025-5726\"   >Math. USSR Izv. (1967 - 1992)</option>\n<option value=\"0025-5734\"   >Math. USSR Sb. (1967 - 1993)</option>\n<option value=\"0957-0233\"   >Meas. Sci. Technol. (1990 - present)</option>\n<option value=\"2151-2043\"   >Meet. Abstr. (2002 - present)</option>\n<option value=\"2050-6120\"   >Methods Appl. Fluoresc. (2013 - present)</option>\n<option value=\"0026-1394\"   >Metrologia (1965 - present)</option>\n<option value=\"0965-0393\"   >Modelling Simul. Mater. Sci. Eng. (1992 - present)</option>\n<option value=\"2399-7532\"   >Multifunct. Mater. (2018 - present)</option>\n<option value=\"2632-959X\"   >Nano Express (2020 - present)</option>\n<option value=\"2399-1984\"   >Nano Futures (2017 - present)</option>\n<option value=\"0957-4484\"   >Nanotechnology (1990 - present)</option>\n<option value=\"2634-4386\"   >Neuromorph. Comput. Eng. (2021 - present)</option>\n<option value=\"1367-2630\"   >New J. Phys. (1998 - present)</option>\n<option value=\"0951-7715\"   >Nonlinearity (1988 - present)</option>\n<option value=\"0335-7368\"   >Nouvelle Revue d'Optique (1973 - 1976)</option>\n<option value=\"0029-4780\"   >Nouvelle Revue d'Optique Appliqu\u00e9e (1970 - 1972)</option>\n<option value=\"0029-5515\"   >Nucl. Fusion (1960 - present)</option>\n<option value=\"1538-3873\"   >PASP (1889 - present)</option>\n<option value=\"1478-3975\"   >Phys. Biol. (2004 - present)</option>\n<option value=\"0031-9112\"   >Phys. Bull. (1950 - 1988)</option>\n<option value=\"0031-9120\"   >Phys. Educ. (1966 - present)</option>\n<option value=\"0031-9155\"   >Phys. Med. Biol. (1956 - present)</option>\n<option value=\"1402-4896\"   >Phys. Scr. (1970 - present)</option>\n<option value=\"2058-7058\"   >Phys. World (1988 - present)</option>\n<option value=\"1063-7869\"   >Phys.-Usp. (1993 - present)</option>\n<option value=\"0305-4624\"   >Physics in Technology (1973 - 1988)</option>\n<option value=\"0967-3334\"   >Physiol. Meas. (1993 - present)</option>\n<option value=\"0032-1028\"   >Plasma Phys. (1967 - 1983)</option>\n<option value=\"0741-3335\"   >Plasma Phys. Control. Fusion (1984 - present)</option>\n<option value=\"2516-1067\"   >Plasma Res. Express (2018 - present)</option>\n<option value=\"1009-0630\"   >Plasma Sci. Technol. (1999 - present)</option>\n<option value=\"0963-0252\"   >Plasma Sources Sci. Technol. (1992 - present)</option>\n<option value=\"2576-1579\"   >Proc. - Electrochem. Soc. (1967 - 2005)</option>\n<option value=\"0959-5309\"   >Proc. Phys. Soc. (1926 - 1948)</option>\n<option value=\"0370-1328\"   >Proc. Phys. Soc. (1958 - 1967)</option>\n<option value=\"0370-1298\"   >Proc. Phys. Soc. A (1949 - 1957)</option>\n<option value=\"0370-1301\"   >Proc. Phys. Soc. B (1949 - 1957)</option>\n<option value=\"1478-7814\"   >Proc. Phys. Soc. London (1874 - 1925)</option>\n<option value=\"2516-1091\"   >Prog. Biomed. Eng. (2018 - present)</option>\n<option value=\"2516-1083\"   >Prog. Energy (2018 - present)</option>\n<option value=\"0963-9659\"   >Pure Appl. Opt. (1992 - 1998)</option>\n<option value=\"1063-7818\"   >Quantum Electron. (1993 - present)</option>\n<option value=\"0954-8998\"   >Quantum Opt. (1989 - 1994)</option>\n<option value=\"2058-9565\"   >Quantum Sci. Technol. (2015 - present)</option>\n<option value=\"1355-5111\"   >Quantum Semiclass. Opt. (1995 - 1998)</option>\n<option value=\"0034-4885\"   >Rep. Prog. Phys. (1934 - present)</option>\n<option value=\"1674-4527\"   >Res. Astron. Astrophys. (2009 - present)</option>\n<option value=\"2515-5172\"   >Research Notes of the AAS (2017 - present)</option>\n<option value=\"0034-6683\"   >Review of Physics in Technology (1970 - 1972)</option>\n<option value=\"1468-4802\"   >Russ. Acad. Sci. Sb. Math. (1993 - 1995)</option>\n<option value=\"0036-021X\"   >Russ. Chem. Rev. (1960 - present)</option>\n<option value=\"0036-0279\"   >Russ. Math. Surv. (1960 - present)</option>\n<option value=\"1468-4810\"   >Russian Acad. Sci. Izv. Math. (1993 - 1995)</option>\n<option value=\"1064-5616\"   >Sb. Math. (1995 - present)</option>\n<option value=\"1468-6996\"   >Sci. Technol. Adv. Mater. (2000 - 2015)</option>\n<option value=\"0268-1242\"   >Semicond. Sci. Technol. (1986 - present)</option>\n<option value=\"0964-1726\"   >Smart Mater. Struct. (1992 - present)</option>\n<option value=\"0049-1748\"   >Sov. J. Quantum Electron. (1971 - 1992)</option>\n<option value=\"0038-5670\"   >Sov. Phys. Usp. (1958 - 1992)</option>\n<option value=\"0953-2048\"   >Supercond. Sci. Technol. (1988 - present)</option>\n<option value=\"2051-672X\"   >Surf. Topogr.: Metrol. Prop. (2013 - present)</option>\n<option value=\"1538-3881\"   >The Astronomical Journal (1849 - present)</option>\n<option value=\"0004-637X\" selected  >The Astrophysical Journal (1996 - present)</option>\n<option value=\"1538-4357\"   >The Astrophysical Journal Letters (1995 - 2009)</option>\n<option value=\"2041-8205\"   >The Astrophysical Journal Letters (2010 - present)</option>\n<option value=\"0067-0049\"   >The Astrophysical Journal Supplement Series (1996 - present)</option>\n<option value=\"2632-3338\"   >The Planetary Science Journal (2020 - present)</option>\n<option value=\"2156-7395\"   >Trans. Am. Electrochem. Soc. (1930 - 1930)</option>\n<option value=\"1945-6859\"   >Trans. Electrochem. Soc. (1931 - 1948)</option>\n<option value=\"1475-4878\"   >Trans. Opt. Soc. (1899 - 1932)</option>\n<option value=\"2053-1613\"   >Transl. Mater. Res. (2014 - 2018)</option>\n</select>\n<label for=\"CF_VOLUME\" class=\"offscreen-hidden\">Volume number:</label>\n            <input type=\"text\" name=\"CF_VOLUME\" id=\"CF_VOLUME\" class=\"art-lookup__content-finder-field\" placeholder=\"Volume\" x-webkit-speech=\"\">\n            <label for=\"CF_ISSUE\" class=\"offscreen-hidden\">Issue number (if known):</label>\n            <input type=\"text\" name=\"CF_ISSUE\" id=\"CF_ISSUE\" class=\"art-lookup__content-finder-field\" placeholder=\"Issue\" x-webkit-speech=\"\">\n            <label for=\"CF_PAGE\" class=\"offscreen-hidden\">Article or page number:</label>\n            <input type=\"text\" name=\"CF_PAGE\" id=\"CF_PAGE\" class=\"art-lookup__content-finder-field art-lookup__content-finder-field--last\" placeholder=\"Article or page\" x-webkit-speech=\"\">\n\n            <input type=\"submit\" class=\"btn btn-default art-lookup__submit\" value=\"Lookup\" name=\"submit\">\n        </div>\n    </fieldset>\n</form></div>\n    </div>\n</div></header>\n<!-- Header tile ends -->\n<div class=\"page-body\" itemscope itemtype=\"http://schema.org/Periodical\">\n        <a name=\"\" id=\"skip-to-content-link-target\" tabindex=\"-1\"></a>\n        <div class=\"wrapper grid-3-col da-showgrid ta-showgrid cf\">\n    <main role=\"main\">\n        <!-- Secondary header starts -->\n<div class=\"secondary-header cf\" id=\"wd-secondary-header\">\n    <!-- Branded journal header starts -->\n<div class=\"big-branded\">\n\n    <div class=\"publication-name\" id=\"wd-pub-name\">\n\t<div class=\"publication-title\" itemprop=\"name\" itemid=\"periodical\">\n\t\t\t\t<!-- Journal image link tile starts -->\n<!-- Logo tile starts -->\n<a href=\"/journal/0004-637X\" itemprop=\"url\">\n    <img src=\"https://cms.iopscience.org/8febf88b-d09c-11e5-b0b6-759f86a2008e/apj-2016.png?guest=true\" alt=\"The Astrophysical Journal\">\n</a>\n<!-- Logo tile ends -->\n<!-- Journal image link tile ends -->\n</div>\n\t\t</div>\n    <div class=\"partner-logos m-hide\" id=\"wd-partner-logos\">\n            <div class=\"partner-logo-alignment\">\n                <!-- Partner logo tile starts -->\n<a href=\"\" class=\"overlay-launch\">\n    <img border=\"0\" src=\"https://cms.iopscience.org/8a2230b8-d09c-11e5-b0b6-759f86a2008e/aas-2018.png?guest=true\" alt=\"The American Astronomical Society, find out more\">\n</a>\n<span class=\"overlay-set\">\n    <div class=\"tint-screen\"></div>\n    <div class=\"overlay-panel\">\n        <a title=\"Close\"  class=\"close-icon close-overlay\" tabindex=\"0\" role=\"button\" aria-describedby=\"close-icon-description\"><span class=\"icon-close\"></span></a>\n        <p id=\"close-icon-description\" class=\"offscreen-hidden\">Click here to close this overlay, or press the \"Escape\" key on your keyboard.</p>\n        <div class=\"overlay-img\">\n            <a href=\"\">\n                <img border=\"0\" src=\"https://cms.iopscience.org/8a2230b8-d09c-11e5-b0b6-759f86a2008e/aas-2018.png?guest=true\" alt=\"The American Astronomical Society, find out more\">\n            </a>\n        </div>\n        <div class=\"overlay-text\">\n            <p>The American Astronomical Society (AAS), established in 1899 and based in Washington, DC, is the major organization of professional astronomers in North America. Its membership of about 7,000 individuals also includes physicists, mathematicians, geologists, engineers, and others whose research and educational interests lie within the broad spectrum of subjects comprising contemporary astronomy. The mission of the AAS is to enhance and share humanity's scientific understanding of the universe.</p> <p><a href=\"https://aas.org/\">https://aas.org/</a></div>\n        <p class=\"ta-c mt-1 mb-2\"><a href=\"\"></a></p>\n    </div>\n</span>\n<!-- Partner logo tile ends -->\n\n<!-- Partner logo tile starts -->\n<a href=\"\" class=\"overlay-launch\">\n    <img border=\"0\" src=\"https://cms.iopscience.org/7ebd1b32-0439-11e9-b401-cfe9679c40e3/iop-2016.png?guest=true\" alt=\"The Institute of Physics, find out more\">\n</a>\n<span class=\"overlay-set\">\n    <div class=\"tint-screen\"></div>\n    <div class=\"overlay-panel\">\n        <a title=\"Close\"  class=\"close-icon close-overlay\" tabindex=\"0\" role=\"button\" aria-describedby=\"close-icon-description\"><span class=\"icon-close\"></span></a>\n        <p id=\"close-icon-description\" class=\"offscreen-hidden\">Click here to close this overlay, or press the \"Escape\" key on your keyboard.</p>\n        <div class=\"overlay-img\">\n            <a href=\"\">\n                <img border=\"0\" src=\"https://cms.iopscience.org/7ebd1b32-0439-11e9-b401-cfe9679c40e3/iop-2016.png?guest=true\" alt=\"The Institute of Physics, find out more\">\n            </a>\n        </div>\n        <div class=\"overlay-text\">\n            <p>The Institute of Physics (IOP) is a leading scientific society promoting physics and bringing physicists together for the benefit of all. It has a worldwide membership of around 50 000 comprising physicists from all sectors, as well as those with an interest in physics. It works to advance physics research, application and education; and engages with policy makers and the public to develop awareness and understanding of physics. Its publishing company, IOP Publishing, is a world leader in professional scientific communications.</p> <p><a href=\"https://www.iop.org\">https://www.iop.org</a></p></div>\n        <p class=\"ta-c mt-1 mb-2\"><a href=\"\"></a></p>\n    </div>\n</span>\n<!-- Partner logo tile ends -->\n\n<p></p>\n                </div>\n        </div>\n    </div>\n<!-- Branded journal header ends -->\n</div> <!-- end secondary-header -->\n<!-- Secondary header ends --><div class=\"da1-da2\" itemscope=\"\" itemtype=\"http://schema.org/ScholarlyArticle\" id=\"page-content\">\n            <div class=\"da1 ta1 article-head\">\n                <!-- Start Eyebrow block, containing Surtitle and Labels -->\n<div class=\"eyebrow\">\n\t<!-- Start Collection Labels -->\n    <!-- End Collection Labels --> </div>\n<!-- End Eyebrow block -->\n\n<h1 itemprop=\"headline\" class=\"wd-jnl-art-title\">LensFlow: A Convolutional Neural Network in Search of Strong Gravitational Lenses</h1>\n\n<p class=\"mb-0\">\n\t<span data-authors=\"\">\n\t\t<span itemtype=\"http://schema.org/Person\" itemprop=\"author\" class=\"nowrap\"><span itemprop=\"name\">Milad Pourrahmani</span><sup>1</sup><a xmlns:xlink=\"http://www.w3.org/1999/xlink\" target=\"_blank\" href=\"https://orcid.org/0000-0003-3351-5986\" title=\"https://orcid.org/0000-0003-3351-5986\"><svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 256 256\" width=\"20\" class=\"orcid-logo\"><path class=\"st0\" d=\"M256 128c0 70.7-57.3 128-128 128C57.3 256 0 198.7 0 128 0 57.3 57.3 0 128 0 198.7 0 256 57.3 256 128z\"></path><path class=\"st1\" d=\"M86.3 186.2H70.9V79.1h15.4v48.4V186.2z\"></path><path class=\"st1\" d=\"M108.9 79.1h41.6c39.6 0 57 28.3 57 53.6 0 27.5-21.5 53.6-56.8 53.6h-41.8V79.1zM124.3 172.4h24.5c34.9 0 42.9-26.5 42.9-39.7 0-21.5-13.7-39.7-43.7-39.7h-23.7V172.4z\"></path><path class=\"st1\" d=\"M88.7 56.8c0 5.5-4.5 10.1-10.1 10.1 -5.6 0-10.1-4.6-10.1-10.1 0-5.6 4.5-10.1 10.1-10.1C84.2 46.7 88.7 51.3 88.7 56.8z\"></path></svg></a></span>, <span itemtype=\"http://schema.org/Person\" itemprop=\"author\" class=\"nowrap\"><span itemprop=\"name\">Hooshang Nayyeri</span><a xmlns:xlink=\"http://www.w3.org/1999/xlink\" target=\"_blank\" href=\"https://orcid.org/0000-0001-8242-9983\" title=\"https://orcid.org/0000-0001-8242-9983\"><svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 256 256\" width=\"20\" class=\"orcid-logo\"><path class=\"st0\" d=\"M256 128c0 70.7-57.3 128-128 128C57.3 256 0 198.7 0 128 0 57.3 57.3 0 128 0 198.7 0 256 57.3 256 128z\"></path><path class=\"st1\" d=\"M86.3 186.2H70.9V79.1h15.4v48.4V186.2z\"></path><path class=\"st1\" d=\"M108.9 79.1h41.6c39.6 0 57 28.3 57 53.6 0 27.5-21.5 53.6-56.8 53.6h-41.8V79.1zM124.3 172.4h24.5c34.9 0 42.9-26.5 42.9-39.7 0-21.5-13.7-39.7-43.7-39.7h-23.7V172.4z\"></path><path class=\"st1\" d=\"M88.7 56.8c0 5.5-4.5 10.1-10.1 10.1 -5.6 0-10.1-4.6-10.1-10.1 0-5.6 4.5-10.1 10.1-10.1C84.2 46.7 88.7 51.3 88.7 56.8z\"></path></svg></a></span>, and <span itemtype=\"http://schema.org/Person\" itemprop=\"author\" class=\"nowrap\"><span itemprop=\"name\">Asantha Cooray</span><a xmlns:xlink=\"http://www.w3.org/1999/xlink\" target=\"_blank\" href=\"https://orcid.org/0000-0002-3892-0190\" title=\"https://orcid.org/0000-0002-3892-0190\"><svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 256 256\" width=\"20\" class=\"orcid-logo\"><path class=\"st0\" d=\"M256 128c0 70.7-57.3 128-128 128C57.3 256 0 198.7 0 128 0 57.3 57.3 0 128 0 198.7 0 256 57.3 256 128z\"></path><path class=\"st1\" d=\"M86.3 186.2H70.9V79.1h15.4v48.4V186.2z\"></path><path class=\"st1\" d=\"M108.9 79.1h41.6c39.6 0 57 28.3 57 53.6 0 27.5-21.5 53.6-56.8 53.6h-41.8V79.1zM124.3 172.4h24.5c34.9 0 42.9-26.5 42.9-39.7 0-21.5-13.7-39.7-43.7-39.7h-23.7V172.4z\"></path><path class=\"st1\" d=\"M88.7 56.8c0 5.5-4.5 10.1-10.1 10.1 -5.6 0-10.1-4.6-10.1-10.1 0-5.6 4.5-10.1 10.1-10.1C84.2 46.7 88.7 51.3 88.7 56.8z\"></path></svg></a></span></span>\n</p>\n\n<p class=\"small\" itemprop=\"isPartOf\" itemscope=\"\" itemtype=\"http://schema.org/PublicationIssue\">\n\t<!--Article Breadcrumb Tile Start-->\n<span class=\"wd-jnl-art-pub-date\">Published 2018 March 26</span> &bull; <!-- Start Copyright-->\n    <span itemprop=\"copyrightHolder\" class=\"wd-jnl-art-copyright\">\n       \t  \u00a9 2018. The American Astronomical Society. All rights reserved.</span><br />\n    <!-- end Copyright -->\n<span itemscope itemtype=\"http://schema.org/Periodical\" itemid=\"periodical\" class=\"wd-jnl-art-breadcrumb-title article-toolbar-anchor\">\n\t<span itemprop=\"name\">\n\t\t<a href=\"/journal/0004-637X\" itemprop=\"url\">The Astrophysical Journal</a></span></span>,\n\t<span itemprop=\"isPartOf\" itemscope itemtype=\"http://schema.org/PublicationVolume\" class=\"wd-jnl-art-breadcrumb-vol nowrap\">\n\t<link itemprop=\"isPartOf\" itemid=\"periodical\" itemscope/>\n\t<span itemprop=\"volumeNumber\"><a href=\"/volume/0004-637X/856\" itemprop=\"url\">Volume 856</a></span></span>,\n<span itemprop=\"issueNumber\" class=\"wd-jnl-art-breadcrumb-issue\"><a href=\"/issue/0004-637X/856/1\" itemprop=\"url\"><!--Issue Number Tile Start-->\nNumber 1<!--Issue Number Tile End--></a></span>\n<!--Article Breadcrumb Tile End-->\n<!-- Start Focus issue title -->\n\t<!-- End focus issue title -->\n\t<span style=\"display: block\"><b>Citation</b> Milad Pourrahmani <em>et al</em> 2018 <em>ApJ</em> <b>856</b> 68</span>\n    </p>\n\n<div class=\"btn-multi-block mb-1\">\n\t\t<a href=\"/article/10.3847/1538-4357/aaae6a/pdf\" class=\"btn btn-large btn-primary content-download btn-full-w-mobile wd-jnl-art-pdf-button-main dupe-buttons\" title=\"LensFlow: A Convolutional Neural Network in Search of Strong Gravitational Lenses\" itemprop=\"sameAs\" target = \"_blank\"><span class=\"icon-file-pdf\"></span><span class=\"offscreen-hidden\"> Download </span><span>Article</span> PDF</a>\n<div class=\"hover-trigger\">\n\t\t<a target=\"_blank\" href=\"/article/10.3847/1538-4357/aaae6a/epub\" class=\"btn btn-large btn-primary content-download btn-full-w-mobile dupe-buttons\" id=\"wd-article-epub-but\">\n\t\t\t<span class=\"icon-epub\"></span><span class=\"offscreen-hidden\">Download</span><span>Article</span> ePub <span></span>\n\t\t\t</a>\n\t\t<div class=\"epub-label hover-item bd-1\">\n\t\t\t<p class=\"small\">You need an eReader or compatible software to experience <a href=\"http://iopscience.iop.org/page/ePub3\">the benefits of the ePub3 file format</a>.</p>\n\t\t</div>\n\t</div>\n</div>\n<!-- Start toolbar -->\n<div class=\"in-page-nav-wrapper\">\n\t<div class=\"nav-in-page m-hide wd-in-pg-toolbar in-page-toolbar-anchor\">\n\t\t<div class=\"nav-in-page-active-wrapper\">\n\t\t\t<div class=\"\">\n\t\t\t\t<div class=\"nav-in-page-active-grid-1\">\n\t\t\t\t\t<nav data-nav-group>\n\t\t\t\t\t\t<div class=\"nav-item wd-in-pg-toolbar-fig\">\n\t\t\t\t\t\t\t<a href=\"\" class=\"nav-top-link-drop-down article-toolbar-dropdown\" data-toolbar-action=\"figures\" data-nav-trigger=\"figures\">Figures<span class=\"icon-arrow-down\"></span></a>\n\t\t\t\t\t\t\t<div class=\"nav-drop-down\" data-nav-item=\"figures\">\n\t\t\t\t\t\t\t\t<div class=\"overflow-x\" data-toolbar-container=\"figures\"></div>\n\t\t\t\t\t\t\t</div>\n\t\t\t\t\t\t</div>\n\t\t\t\t\t\t<div class=\"nav-item wd-in-pg-toolbar-tables\">\n\t\t\t\t\t\t\t<a href=\"\" class=\"nav-top-link-drop-down article-toolbar-dropdown\" data-toolbar-action=\"table\" data-nav-trigger=\"table\">Tables<span class=\"icon-arrow-down\"></span></a>\n\t\t\t\t\t\t\t<div class=\"nav-drop-down\" data-nav-item=\"table\">\n\t\t\t\t\t\t\t\t<div class=\"overflow-x\" data-toolbar-container=\"table\"></div>\n\t\t\t\t\t\t\t</div>\n\t\t\t\t\t\t</div>\n\t\t\t\t\t\t<div class=\"nav-item wd-in-pg-toolbar-ref\">\n\t\t\t\t\t\t\t<a href=\"\" class=\"nav-top-link-drop-down article-toolbar-dropdown\" data-toolbar-action=\"references\" data-nav-trigger=\"references\">References<span class=\"icon-arrow-down\"></span></a>\n\t\t\t\t\t\t\t<div class=\"nav-drop-down\" data-nav-item=\"references\">\n\t\t\t\t\t\t\t\t<div class=\"overflow-y\" data-toolbar-container=\"references\"></div>\n\t\t\t\t\t\t\t</div>\n\t\t\t\t\t\t</div>\n\t\t\t\t\t\t<div class=\"nav-item wd-in-pg-toolbar-artdata\">\n\t\t\t\t\t\t\t\t<a href=\"\" class=\"nav-top-link-drop-down article-toolbar-dropdown\" data-toolbar-action=\"artdata\" data-nav-trigger=\"artdata\">Article data<span class=\"icon-arrow-down\"></span></a>\n\t\t\t\t\t\t\t\t<div class=\"nav-drop-down\" data-nav-item=\"artdata\">\n\t\t\t\t\t\t\t\t\t<div class=\"overflow-x mb-05\" data-toolbar-container=\"artdata\"></div>\n\t\t\t\t\t\t\t\t\t<p class=\"small\"><a target=\"_blank\" href=\"/journal/0004-637X/page/article-data\">What is article data?</a></p>\n\t\t\t\t\t\t\t\t</div>\n\t\t\t\t\t\t\t</div>\n\t\t\t\t\t\t</nav>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"nav-in-page-active-grid-2 d-n\">\n\t\t\t\t\t<aside>\n\t\t\t\t\t\t<div class=\"pdf-button-2nd\">\n\t\t\t\t\t\t</div>\n\t\t\t\t\t</aside>\n\t\t\t\t</div>\n\t\t\t</div>\n\t\t</div>\n\t</div>\n</div>\n<!-- End toolbar --></div>\n            <div class=\"da2 ta2\">\n                <div class=\"print-hide content-tools\">\n\t\t\t<div>\n\t<p>\n\t\t<span id=\"total-downloads\" class=\"wd-jnl-art-total-dwnlds\"><b>1303</b> Total downloads</span>\n\t\t\t<br />\n\t\t</p>\n\t</div>\n\t\n<div class=\"dimensions-altmetric-li\">\n\n        <!-- Start Dimensions display -->\n        <!-- Start Dimensions display -->\n    <span class=\"__dimensions_badge_embed__ dimensions-embed\" data-doi=\"10.3847/1538-4357/aaae6a\" data-style=\"small_rectangle\" data-hide-zero-citations=\"true\" data-legend=\"never\"></span>\n    <!-- End Dimensions display -->\n<!-- End Dimensions display -->\n        <div class=\"clear-fl\"></div>\n    </div>\n<!-- Start MathJax links -->\n\t\t<div>\n\t\t  <a href=\"#\" id=\"mathJaxOff\" style=\"display: none;\">Turn off MathJax</a>\n\t\t  <a href=\"#\" id=\"mathJaxOn\" style=\"display: none;\">Turn on MathJax</a>\n\t\t</div>\t\n\t<!-- End MathJax links -->\n<!-- Start Permission Link -->\n\t<div>\n\t\t\t<p class=\"wd-jnl-art-get-permisssion print-hide\">\n\t\t\t\t<a href=\"https://journals.aas.org/article-charges-and-copyright/#AAS_material\" target=\"_blank\">Get permission to re-use this article</a>\n\t\t\t</p>\n\t\t</div>\n\t<!-- End Permission Link --><div id=\"wd-share-icons\">\n<p>Share this article</p>\n<ul class=\"share-icon-links\">\n\t\t<li id=\"wd-share-icon-email\" class=\"share-icon-link\">\n\t<a href=\"mailto:?subject=LensFlow: A Convolutional Neural Network in Search of Strong Gravitational Lenses&amp;body=LensFlow: A Convolutional Neural Network in Search of Strong Gravitational Lenses - https://doi.org/10.3847/1538-4357/aaae6a\" title=\"Share this content via email. Clicking this link will open your default email client.\" class=\"share-icon-link\">\n\t\t\t<img src=\"https://static.iopscience.com/2.44.0/img/icon-email.svg\" alt=\"Share this content via email\">\n\t</a>\n\t</li>\n\t<li id=\"wd-share-icon-facebook\" class=\"share-icon-link\">\n\t<a href=\"http://www.facebook.com/sharer.php?u=https%3A%2F%2Fdoi.org%2F10.3847%2F1538-4357%2Faaae6a\" title=\"Share a link to this content on your Facebook profile\" class=\"share-icon-link\">\n\t\t\t<img src=\"https://static.iopscience.com/2.44.0/img/icon-facebook.svg\" alt=\"Share on Facebook\">\n\t</a>\n\t</li>\n\t<li id=\"wd-share-icon-twitter\" class=\"share-icon-link\">\t\t\t\t\t\t\t\n\t<a href=\"http://twitter.com/share?url=https%3A%2F%2Fdoi.org%2F10.3847%2F1538-4357%2Faaae6a&amp;text=LensFlow%3A+A+Convolutional+Neural+Network+in+Search+of+Strong+Gravitational+Lenses&amp;via=IOPscience\" title=\"Share a link to this content on your Twitter profile\" class=\"share-icon-link\">\n\t\t\t<img src=\"https://static.iopscience.com/2.44.0/img/icon-twitter.svg\" alt=\"Share on Twitter\">\n\t</a>\n\t</li>\n\t<li id=\"wd-share-icon-google-plus\" class=\"share-icon-link\">\n\t<a href=\"https://plus.google.com/share?url=https%3A%2F%2Fdoi.org%2F10.3847%2F1538-4357%2Faaae6a\" title=\"Share a link to this content on your Google+ profile\" class=\"share-icon-link\">\n\t\t\t<img src=\"https://static.iopscience.com/2.44.0/img/icon-google-plus.svg\" alt=\"Share on Google+\">\n\t</a>\n\t</li>\n\t<li id=\"wd-share-icon-mendeley\" class=\"share-icon-link\">\n\t<a href=\"https://www.mendeley.com/import/?doi=10.3847%2F1538-4357%2Faaae6a\" title=\"Share on Mendeley\" class=\"share-icon-link\">\n\t\t\t<img src=\"https://static.iopscience.com/2.44.0/img/icon-mendeley.svg\" alt=\"Share on Mendeley\">\n\t</a>\n\t</li>\n</ul>\n<div class=\"clear-fl\"></div>\n</div>\n\n</div>\n</div>\n            <div class=\"da1 ta1\">\n                <!-- Start Linked Articles note -->\n\t<!-- End Linked Articles note -->\n<!-- Article information starts. This includes author emails, affiliations, article published date, doi etc. -->\n\t<div class=\"reveal-container reveal-closed reveal-plus-icon bdt-1 wd-jnl-art-article-info-wrapper\">\n      \t<div class=\"replica-h3 mt-0\">\n        \t<a id=\"wd-article-info-accordion\" href=\"#\" class=\"reveal-trigger\" data-reveal-label-alt=\"Hide article information\">Article information</a>\n      \t</div>\n      \t<div class=\"reveal-content\">\n        \t<div class=\"article-meta\">\n          \t\t<!-- Start Affiliations --><div class=\"wd-jnl-art-author-affiliations\"><div class=\"replica-h4\">Author affiliations</div><p class=\"mb-05\">Department of Physics and Astronomy, University of California Irvine, Irvine, CA, USA</p><p class=\"mb-05\"><sup>1</sup> Corresponding author.</p></div><!-- End Affiliations --><!-- Start ORCIDs --><div class=\"wd-jnl-art-author-orcid-list\"><div class=\"replica-h4\">ORCID iDs</div><p class=\"mb-05\"><span itemtype=\"http://schema.org/Person\" itemprop=\"author\" class=\"nowrap\"><span itemprop=\"name\">Milad Pourrahmani</span><a xmlns:xlink=\"http://www.w3.org/1999/xlink\" target=\"_blank\" href=\"https://orcid.org/0000-0003-3351-5986\" title=\"https://orcid.org/0000-0003-3351-5986\"><svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 256 256\" width=\"20\" class=\"orcid-logo\"><path class=\"st0\" d=\"M256 128c0 70.7-57.3 128-128 128C57.3 256 0 198.7 0 128 0 57.3 57.3 0 128 0 198.7 0 256 57.3 256 128z\"></path><path class=\"st1\" d=\"M86.3 186.2H70.9V79.1h15.4v48.4V186.2z\"></path><path class=\"st1\" d=\"M108.9 79.1h41.6c39.6 0 57 28.3 57 53.6 0 27.5-21.5 53.6-56.8 53.6h-41.8V79.1zM124.3 172.4h24.5c34.9 0 42.9-26.5 42.9-39.7 0-21.5-13.7-39.7-43.7-39.7h-23.7V172.4z\"></path><path class=\"st1\" d=\"M88.7 56.8c0 5.5-4.5 10.1-10.1 10.1 -5.6 0-10.1-4.6-10.1-10.1 0-5.6 4.5-10.1 10.1-10.1C84.2 46.7 88.7 51.3 88.7 56.8z\"></path></svg> https://orcid.org/0000-0003-3351-5986</a></span></p><p class=\"mb-05\"><span itemtype=\"http://schema.org/Person\" itemprop=\"author\" class=\"nowrap\"><span itemprop=\"name\">Hooshang Nayyeri</span><a xmlns:xlink=\"http://www.w3.org/1999/xlink\" target=\"_blank\" href=\"https://orcid.org/0000-0001-8242-9983\" title=\"https://orcid.org/0000-0001-8242-9983\"><svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 256 256\" width=\"20\" class=\"orcid-logo\"><path class=\"st0\" d=\"M256 128c0 70.7-57.3 128-128 128C57.3 256 0 198.7 0 128 0 57.3 57.3 0 128 0 198.7 0 256 57.3 256 128z\"></path><path class=\"st1\" d=\"M86.3 186.2H70.9V79.1h15.4v48.4V186.2z\"></path><path class=\"st1\" d=\"M108.9 79.1h41.6c39.6 0 57 28.3 57 53.6 0 27.5-21.5 53.6-56.8 53.6h-41.8V79.1zM124.3 172.4h24.5c34.9 0 42.9-26.5 42.9-39.7 0-21.5-13.7-39.7-43.7-39.7h-23.7V172.4z\"></path><path class=\"st1\" d=\"M88.7 56.8c0 5.5-4.5 10.1-10.1 10.1 -5.6 0-10.1-4.6-10.1-10.1 0-5.6 4.5-10.1 10.1-10.1C84.2 46.7 88.7 51.3 88.7 56.8z\"></path></svg> https://orcid.org/0000-0001-8242-9983</a></span></p><p class=\"mb-05\"><span itemtype=\"http://schema.org/Person\" itemprop=\"author\" class=\"nowrap\"><span itemprop=\"name\">Asantha Cooray</span><a xmlns:xlink=\"http://www.w3.org/1999/xlink\" target=\"_blank\" href=\"https://orcid.org/0000-0002-3892-0190\" title=\"https://orcid.org/0000-0002-3892-0190\"><svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 256 256\" width=\"20\" class=\"orcid-logo\"><path class=\"st0\" d=\"M256 128c0 70.7-57.3 128-128 128C57.3 256 0 198.7 0 128 0 57.3 57.3 0 128 0 198.7 0 256 57.3 256 128z\"></path><path class=\"st1\" d=\"M86.3 186.2H70.9V79.1h15.4v48.4V186.2z\"></path><path class=\"st1\" d=\"M108.9 79.1h41.6c39.6 0 57 28.3 57 53.6 0 27.5-21.5 53.6-56.8 53.6h-41.8V79.1zM124.3 172.4h24.5c34.9 0 42.9-26.5 42.9-39.7 0-21.5-13.7-39.7-43.7-39.7h-23.7V172.4z\"></path><path class=\"st1\" d=\"M88.7 56.8c0 5.5-4.5 10.1-10.1 10.1 -5.6 0-10.1-4.6-10.1-10.1 0-5.6 4.5-10.1 10.1-10.1C84.2 46.7 88.7 51.3 88.7 56.8z\"></path></svg> https://orcid.org/0000-0002-3892-0190</a></span></p></div><!-- End ORCIDs --><!-- Start Dates -->\n<div class=\"col-no-break wd-jnl-art-dates\">\n        <div class=\"replica-h4\">Dates</div>\n        <p>\n            \n                Received <span itemprop=\"dateReceived\">2017 May 23</span><br />\n            \n                Accepted <span itemprop=\"dateAccepted\">2018 February 7</span><br />\n            \n                    Published <span itemprop=\"datePublished\">2018 March 26</span><br />\n                </p>\n    </div>\n<!-- End Dates -->\n\n<!-- Start Crossmark -->\n\t\t\t\t<p class=\"wd-jnl-art-crossmark\">\n\t\t\t\t\t\t<a target=\"_blank\" href=\"http://crossmark.crossref.org/dialog/?doi=10.3847/1538-4357/aaae6a&domain=pdf\">\n\t\t\t\t\t\t\t<img src=\"https://static.iopscience.com/2.44.0/img/CROSSMARK_Color_horizontal.svg\" width=\"130\" alt=\"Check for updates using Crossmark\">\n\t\t\t\t\t\t</a>\n\t\t\t\t\t</p>\n\t\t\t\t<!-- End Crossmark -->\n\n\t\t\t\t<!-- Start Peer Review Metrics -->\n<!-- End Peer Review Metrics -->\n\n<!--  Start Citation -->\n                    <!--  End Citation -->\n\t\t\t\t\n\t\t\t\t<!-- Start DOI -->\n\t\t\t\t<div class=\"col-no-break wd-jnl-art-doi\">\n\t\t\t\t\t<div class=\"replica-h4\">\n\t\t\t\t\t<abbr title=\"digital object identifier\">DOI</abbr>\n\t\t\t\t\t</div>\n\t\t\t\t\t<p><a itemprop=\"sameAs\" href=\"https://doi.org/10.3847/1538-4357/aaae6a\">https://doi.org/10.3847/1538-4357/aaae6a</a></p>\n\t\t\t\t</div>\n\t\t\t\t<!-- End DOI -->\n\t\t\t\t\n\t\t\t\t<!-- Start Accepted manuscript Link -->\n<!-- End Accepted manuscript Link -->\n<!-- Start Annotations -->\n <!-- End Annotations --><div class=\"col-no-break wd-jnl-aas-keywords\">\n\t\t<div class=\"replica-h4\">Keywords</div>\n\t\t<p><a href=\"/searchaaskeyword?source=aas&amp;type=kwd_group&amp;code=2%2F46&amp;code_desc=gravitational+lensing%3A+strong\">gravitational lensing: strong</a>; <a href=\"/searchaaskeyword?source=aas&amp;type=kwd_group&amp;code=3%2F14&amp;code_desc=methods%3A+data+analysis\">methods: data analysis</a>; <a href=\"/searchaaskeyword?source=aas&amp;type=kwd_group&amp;code=3%2F23&amp;code_desc=techniques%3A+image+processing\">techniques: image processing</a></p>\n\t</div>\n<!-- Start Reprint Link -->\n\t<!-- End Reprint Link --><!-- Start Journal RSS feed -->\n                    <div class=\"jnl-notifications-wrapper jnl-notifications-wrapper--rss\">\n                        <a class=\"wd-jnl-rss\" href=\"/journal/rss/0004-637X\"><span\n                                class=\"icon-feed icon-feed--jhp\"></span>Journal RSS</a>\n                    </div>\n\t\t\t\t\t<!-- End Journal RSS feed -->\n\t\t\t\t\t<!-- Start Email Alert -->\n    <!-- Start Email Alert -->\n        <div class=\"jnl-notifications-wrapper\">\n            <a class=\"wd-jnl-email-alert loginRequired\"\n               href=\"https://myiopscience.iop.org/signin?origin=a0&return=https%3A%2F%2Fiopscience.iop.org%2Farticle%2F10.3847%2F1538-4357%2Faaae6a\"\n               id=\"corridors-create-manage\" title=\"Create or edit your corridor alerts\">\n                <span class=\"icon-alarm icon-alarm--jhp\"></span>Create or edit your corridor alerts\n            </a>\n\n<!-- Start TOC Subjects Popup -->\n<span class=\"overlay-set\" id=\"corridor-alerts-overlay\">\n    <div class=\"tint-screen\"></div>\n    <div class=\"overlay-panel two-columns\">\n        <div id=\"innerContainer\">\n            <a class=\"close-icon close-overlay\" title=\"Close\" tabindex=\"0\" role=\"button\" aria-describedby=\"close-icon-description\">\n                <span class=\"icon-close\"></span>\n            </a>\n            <p id=\"close-icon-description\" class=\"offscreen-hidden\">\n                Click here to close this overlay, or press the \"Escape\" key on your keyboard.\n            </p>\n            <form id=\"alertsForm\" class=\"overlay-panel__form\" method=\"post\" action=\"\" role=\"form\" aria-labelledby=\"alerts-box-title\">\n                <div class=\"overlay-panel__header\">\n                    <div class=\"overlay-panel__logo\"></div>\n                    <span id=\"alerts-box-title\" class=\"replica-h2\">Corridor alerts</span>\n                    <p id=\"alerts-box-desc\">\n                        Receive alerts on all new research papers in American Astronomical Society\n                        (<span class=\"abbr__aas\">A&nbsp;A&nbsp;S&nbsp;</span>) journals as soon as they are published.\n                        Select your desired journals and corridors below. You will need to select a minimum of one corridor.\n                    </p>\n                </div>\n                <div class=\"overlay-panel__container\">\n                    <div class=\"overlay-panel__col\">\n                        <fieldset id=\"alerts-corridors-list\">\n                            <legend id=\"corridors-title\" class=\"overlay-panel__heading replica-h3 mb-05\">Corridors</legend>\n                        </fieldset>\n                    </div>\n                    <div class=\"overlay-panel__col\">\n                        <fieldset id=\"alerts-journals-list\">\n                            <legend id=\"journals-title\" class=\"overlay-panel__heading replica-h3 mb-05\">Journals</legend>\n                        </fieldset>\n                    </div>\n                    <div class=\"boxout-bg-blue-light overlay-panel__extra-info\">\n                        <p>\n                            Please note, The Astrophysical Journal Letters (ApJL) and Research Notes of the AAS (RNAAS)\n                            do not currently use the corridors.\n                        </p>\n                    </div>\n                </div>\n                <div class=\"overlay-panel__footer\">\n                    <div class=\"overlay-panel__inner-footer\">\n                        <input id=\"update-alerts\" type=\"submit\" value=\"Create alert\" class=\"btn btn-default overlay-panel__btn\" role=\"button\">\n                        <div class=\"icon-spinner spinner overlay-panel__loading\"></div>\n                    </div>\n                </div>\n            </form>\n        </div>\n    </div>\n</span>\n<!-- End TOC Subjects Popup -->\n            <p class=\"mb-0\"><a class=\"wd-jnl-email-alert jnl-email-alert--corridors-info\" href=\"https://journals.aas.org/corridors.html\"\n               target=\"_blank\" title=\"Find out more about AAS corridors.\">\n                What are corridors? <span class=\"icon-newtab\">\n            </a></p>\n        </div>\n\n    <!-- End Email Alert -->\n<!-- End Email Alert --><!-- Start Citation Alert Link -->\n                        <p>\n<div class=\"jnl-notifications-wrapper\">\n    <a class=\"wd-jnl-email-alert\" href=\"https://myiopscience.iop.org/signin?origin=a0&return=https%3A%2F%2Fiopscience.iop.org%2Fmyiopscience%2Falerts%2Fsubscribe%3FarticleID%3D0004-637X%2F856%2F1%2F68\"><span\n            class=\"icon-alarm icon-alarm--jhp\"></span>Create citation alert</a>\n</div><!-- End Citation Alert Link -->\n                    </div>\n\t\t</div>\n    </div>\n    <!-- Article information ends -->\n<!-- Start Info top-->\n    <!-- end Info top --><div class=\"article-content\">\n\t<span id=\"articleId\" class=\"hide\">0004-637X/856/1/68</span>\n<!-- Start Abstract -->\n    <h2 id=\"artAbst\" class=\"collapse-blocked\">Abstract</h2>\n        <!-- Start article video abstract -->\n\t<!-- End article video abstract -->\n\t<div class=\"article-text wd-jnl-art-abstract cf\" itemprop=\"description\">\n             <P>In this work, we present our machine learning classification algorithm for identifying strong gravitational lenses from wide-area surveys using convolutional neural networks; <span class=\"small-caps\">LensFlow</span>. We train and test the algorithm using a wide variety of strong gravitational lens configurations from simulations of lensing events. Images are processed through multiple convolutional layers that extract feature maps necessary to assign a lens probability to each image. <span class=\"small-caps\">LensFlow</span> provides a ranking scheme for all sources that could be used to identify potential gravitational lens candidates by significantly reducing the number of images that have to be visually inspected. We apply our algorithm to the <I>HST</I>/ACS i-band observations of the COSMOS field and present our sample of identified lensing candidates. The developed machine learning algorithm is more computationally efficient and complimentary to classical lens identification algorithms and is ideal for discovering such events across wide areas from current and future surveys such as LSST and <I>WFIRST</I>.</P> </div>\n    <!-- End abstract -->\n<!-- Start Export citation and abstract tools -->\n\t<p>\n\t\t<small>Export citation and abstract</small>\n\t\t<span class=\"btn-multi-block\">\n\t\t\t<a href=\"/export?articleId=0004-637X/856/1/68&doi=10.3847/1538-4357/aaae6a&exportFormat=iopexport_bib&exportType=abs&navsubmit=Export+abstract\" class=\"btn btn-primary wd-btn-cit-abs-bib\" title=\"Export BibTex\">BibTeX</a>\n\t\t\t<a href=\"/export?articleId=0004-637X/856/1/68&doi=10.3847/1538-4357/aaae6a&exportFormat=iopexport_ris&exportType=abs&navsubmit=Export+abstract\" class=\"btn btn-primary wd-btn-cit-abs-ris\" title=\"Export RIS\">RIS</a>\n\t\t</span>\n\t</p>\n<!-- End Export citation and abstract tools -->\n<!-- Start AAS Related Links -->\n<div class=\"reveal-container reveal-closed reveal-plus-icon bdt-1 mt-2 mb-2 wd-jnl-art-article-aas-related-links\">\n  <div class=\"replica-h3 mt-0\">\n    <a href=\"#\" class=\"reveal-trigger\" data-reveal-label-alt=\"Hide related links\">Related links</a>\n  </div>\n  <div class=\"reveal-content\">\n    <div class=\"article-meta\"> \n      <ul>\n      \t<li><a href=\"http://adsabs.harvard.edu/abs/2018ApJ...856...68P\" target=\"_blank\">NASA ADS Record <span class=\"icon-newtab\"></span></a></li>\n      \t<li><a href=\"http://simbad.u-strasbg.fr/simbad/sim-ref?querymethod=bib&simbo=on&bibcode=2018ApJ...856...68P\" target=\"_blank\">Simbad Objects <span class=\"icon-newtab\"></span></a></li>\n      \t<li><a href=\"/journal/0004-637X/page/About%20Related%20Links\" target=\"_blank\">About Related Links</a></li>\n      \t</ul>\n    </div>\n  </div>\n</div>\n<!-- Start info bottom -->\n    <!-- End info bottom -->\n<!-- Start article full text -->\n\t<div xmlns:book=\"http://api.iop.org/Book/1.0/\" itemprop=\"articleBody\" class=\"wd-jnl-art-full-text article-text\">\n<h2 class=\"header-anchor\" id=\"apjaaae6as1\" name=\"apjaaae6as1\">1.\u00a0Introduction</h2><div class=\"article-text\" data-mobile-collapse=\"\"><p>Gravitational lensing, a prediction of Einstein's general theory of relativity, is a very powerful tool in cosmological studies. It has been used extensively to understand various aspects of galaxy formation and evolution (e.g., Refsdal &amp; Bondi <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib45\" id=\"fnref-apjaaae6abib45\">1964</a>; Blandford &amp; Narayan <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib5\" id=\"fnref-apjaaae6abib5\">1992</a>; Postman et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib43\" id=\"fnref-apjaaae6abib43\">2012</a>; Atek et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib4\" id=\"fnref-apjaaae6abib4\">2015</a>; Nayyeri et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib36\" id=\"fnref-apjaaae6abib36\">2016</a>). This involves accurate cosmological parameter estimation (Treu <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib53\" id=\"fnref-apjaaae6abib53\">2010</a>), studies of dark matter distribution from weak gravitational lensing events (Kaiser &amp; Squires <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib22\" id=\"fnref-apjaaae6abib22\">1993</a>; Velander et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib56\" id=\"fnref-apjaaae6abib56\">2014</a>), black hole physics (Peng et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib41\" id=\"fnref-apjaaae6abib41\">2006</a>), and searches for the most distant galaxies (Coe et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib10\" id=\"fnref-apjaaae6abib10\">2012</a>; Oesch et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib38\" id=\"fnref-apjaaae6abib38\">2015</a>), among others.</p><p>One of the main goals of observational cosmology is to constrain the main cosmological parameters that dictate the evolution of the universe (Tegmark et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib51\" id=\"fnref-apjaaae6abib51\">2004</a>; Komatsu et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib25\" id=\"fnref-apjaaae6abib25\">2009</a>; Weinberg et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib58\" id=\"fnref-apjaaae6abib58\">2013</a>). Strong gravitational lensing has been utilized over the past few years to estimate and constrain these cosmological parameters (Broadhurst et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib7\" id=\"fnref-apjaaae6abib7\">2005</a>; Suyu et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib49\" id=\"fnref-apjaaae6abib49\">2013</a>, <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib50\" id=\"fnref-apjaaae6abib50\">2014</a>; Agnello et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib2\" id=\"fnref-apjaaae6abib2\">2017</a>; Goobar et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib16\" id=\"fnref-apjaaae6abib16\">2017</a>; More et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib33\" id=\"fnref-apjaaae6abib33\">2017</a>). This is achieved through accurate lens modeling of such events and comparing the model predictions with observations (such as with observations of lensing induced time delays (Eigenbrod et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib11\" id=\"fnref-apjaaae6abib11\">2005</a>; Treu <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib53\" id=\"fnref-apjaaae6abib53\">2010</a>; Suyu et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib50\" id=\"fnref-apjaaae6abib50\">2014</a>; Rodney et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib46\" id=\"fnref-apjaaae6abib46\">2016</a>; Treu &amp; Marshall <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib54\" id=\"fnref-apjaaae6abib54\">2016</a>). In a recent study, for example, Suyu et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib49\" id=\"fnref-apjaaae6abib49\">2013</a>) used combined WMAP, Keck, and <em>HST</em> data on gravitational time delays in two lensed sources to constrain the Hubble constant within 4% in a \u039bCDM cosmological framework.</p><p>One of the key aspects of gravitational lensing is its use as natural telescopes through boosting the observed signal and increasing the spatial resolution (Treu <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib53\" id=\"fnref-apjaaae6abib53\">2010</a>). This is quite advantageous in searches for distant and/or faint objects at moderate observing costs and has been utilized extensively in various surveys in searches for such objects, the identification of which would not have been possible without it (Bolton et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib6\" id=\"fnref-apjaaae6abib6\">2006</a>; Heymans et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib19\" id=\"fnref-apjaaae6abib19\">2012</a>). Given that the number of identified lenses for different classes of galaxies rises sufficiently due to better lens finding algorithms, one could study the intrinsic properties of distant galaxies from such searches to understand the physics of star formation and mass assembly (Fu et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib13\" id=\"fnref-apjaaae6abib13\">2012</a>; Timmons et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib52\" id=\"fnref-apjaaae6abib52\">2016</a>; Nayyeri et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib35\" id=\"fnref-apjaaae6abib35\">2017</a>; Wilson et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib59\" id=\"fnref-apjaaae6abib59\">2017</a>). In the past few years, deep diffraction limited observations have also taken advantage of gravitational lensing to extend the faint end of the luminosity function of galaxies by a few orders of magnitude (Atek et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib4\" id=\"fnref-apjaaae6abib4\">2015</a>) to produce the deepest images of the sky ever taken across multiple bands. Strong gravitational lensing events have been observed extensively in such surveys as galaxy\u2013galaxy lensing in field surveys such as the Cosmic Assembly Near-infrared Deep Extragalactic Legacy Survey (CANDELS; Grogin et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib17\" id=\"fnref-apjaaae6abib17\">2011</a>; Koekemoer et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib24\" id=\"fnref-apjaaae6abib24\">2011</a>) and the Cosmological Evolution Survey (COSMOS; Capak et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib9\" id=\"fnref-apjaaae6abib9\">2007</a>; Scoville et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib47\" id=\"fnref-apjaaae6abib47\">2007</a>) or as cluster lensing from observations of nearby massive clusters (Postman et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib43\" id=\"fnref-apjaaae6abib43\">2012</a>; Treu et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib55\" id=\"fnref-apjaaae6abib55\">2015</a>; Lotz et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib30\" id=\"fnref-apjaaae6abib30\">2017</a>) with the <em>Hubble</em> Space Telescope leading to the identification of the first generations of galaxies (out to <em>z</em>\u00a0~\u00a011; Oesch et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib38\" id=\"fnref-apjaaae6abib38\">2015</a>) and studies of galaxy formation and evolution at the epoch of reionization. This was, in fact, one of the main motivations behind <em>Hubble</em> cluster lensing studies such as Cluster Lensing and Supernova Survey with Hubble (CLASH; Postman et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib43\" id=\"fnref-apjaaae6abib43\">2012</a>) and the <em>Hubble</em> Frontier Fields (Lotz et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib30\" id=\"fnref-apjaaae6abib30\">2017</a>). The power of gravitational lensing could also be used in the detection of low surface brightness emission from extended objects such as millimeter and radio emissions from dust and molecular gas at <em>z</em>\u00a0~\u00a02\u22123 as observed with ALMA used to study the physics of the cold ISM (Spilker et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib48\" id=\"fnref-apjaaae6abib48\">2016</a>).</p><p>Strongly lensed galaxies are normally targeted and identified from dedicated surveys (Bolton et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib6\" id=\"fnref-apjaaae6abib6\">2006</a>). Traditionally, these lens identifications are either catalog-based, in which lensing events are identified by looking for objects in a lensing configuration, or pixel based, with the search starting from a set of pixels. These lensing searches are normally computationally challenging in that individual pixels are constantly compared with adjacent ones and they could be biased toward a given population and/or brighter objects. Recent far-infrared wide area observations (such as those with <em>Herschel</em>) advanced searches for lensed galaxies by adopting a simple efficient selection technique of lensed candidates through observations of excessive flux in the far-infrared (as an indication of strong lensing events supported by number count distributions; Wardlow et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib57\" id=\"fnref-apjaaae6abib57\">2012</a>; Nayyeri et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib36\" id=\"fnref-apjaaae6abib36\">2016</a>). However, such surveys are also biased toward populations of red dusty star-forming galaxies (missing any blue lenses) and are not always available across the full sky (the <em>Herschel</em> surveys that were targeted had <span xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"inline-eqn\"><span class=\"tex\"><span class=\"texImage\"><img src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6aieqn1.gif\" alt=\"$\\sim 0.2\\mbox{--}0.4\\,{\\deg }^{-2}$\" align=\"top\"></img></span><script type=\"math/tex\">\\sim 0.2\\mbox{--}0.4\\,{\\deg }^{-2}</script></span></span> lensing events, much lower than expected from optical surveys). Given that tests of cosmological models require simple unbiased selection functions, it is important to have a complete unbiased catalog of lensing events.</p><p>We have entered the era of big data astronomy. Sky surveys such as the LSST, <em>Euclid</em>, and <em>WFIRST</em> will produce more imaging data than humans can ever analyze by eye. The challenges of designing such surveys are no longer merely instrumentational, but they also demand powerful data analysis and classification tools that can identify astronomical objects autonomously. Fortunately, computer vision has drastically improved in the last decade making autonomous astronomy possible. The past couple of years has been the most exciting era in the field of machine learning (ML). Researchers from both the public and the private sectors have achieved landmarks in developing image recognition/classification techniques. One of the most exciting recent events in the ML community was the release of <span class=\"small-caps\">TensorFlow</span> by Google, a parallel processing platform designed for development of fast deep learning algorithms (Abadi et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib1\" id=\"fnref-apjaaae6abib1\">2016</a>). Packages and software, such as <span class=\"small-caps\">Mathematica</span>, <span class=\"small-caps\">TensorFlow</span>, <span class=\"small-caps\">Caffe</span>, and others, alongside cheaper and more powerful Graphics Processing Units (GPUs) have enabled researchers to develop very complex and fast classification algorithms. Among these deep learning programs, ConvNets have deservingly received a lot of attention in many fields of science and industry in the past few years (Krizhevsky et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib27\" id=\"fnref-apjaaae6abib27\">2012</a>). Complex ConvNets such as <span class=\"small-caps\">GoogleNet</span> and <span class=\"small-caps\">AlexNet</span>, which are publicly available, have achieved superhuman performance on the task of image classification. Google's <span class=\"small-caps\">TensorFlow</span> has made it possible to easily develop parallelized deep learning algorithms, which, if integrated with Google's Tensor Processing Units (TPUs), could address the data mining challenges in the field of astronomy. In this work, we introduce and image classification algorithm, <span class=\"small-caps\">LensFlow</span>, which is a ConvNet that can be used to search for strong gravitational lenses with the final version of the code publicly available on Github.<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6afn2\">2</a></sup>\n\n</p><p>This paper is organized as follow. In Section <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"secref\" href=\"#apjaaae6as2\">2</a>, we will explain the principal concepts underlying neural networks, supervised learning, and ConvNets. Before feeding the images to a ConvNet, they must be normalized and should be enhanced. The details data extraction and normalization are discussed in Section <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"secref\" href=\"#apjaaae6as3-1\">3.1</a>. As discussed in Section <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"secref\" href=\"#apjaaae6as3-3\">3.3</a>, we explain the architecture of <span class=\"small-caps\">LensFlow</span> and its pretraining process on CIFAR data (Krizhevsky &amp; Hinton <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib26\" id=\"fnref-apjaaae6abib26\">2009</a>). In Sections <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"secref\" href=\"#apjaaae6as3-4\">3.4</a> and <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"secref\" href=\"#apjaaae6as3-5\">3.5</a>, we discuss training <span class=\"small-caps\">LensFlow</span> on COSMOS data and show its performance on recovering known tracer lenses. In Section <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"secref\" href=\"#apjaaae6as3-6\">3.6</a>, we share a set of new lenses found by <span class=\"small-caps\">LensFlow</span> and we conclude our results in Section <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"secref\" href=\"#apjaaae6as4\">4</a>. Throughout this paper, we assume a standard cosmology with <span xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"inline-eqn\"><span class=\"tex\"><span class=\"texImage\"><img src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6aieqn3.gif\" alt=\"${H}_{0}=70\\,{\\mathrm{kms}}^{-1}\\,{\\mathrm{Mpc}}^{-1}$\" align=\"top\"></img></span><script type=\"math/tex\">{H}_{0}=70\\,{\\mathrm{kms}}^{-1}\\,{\\mathrm{Mpc}}^{-1}</script></span></span>, <span xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"inline-eqn\"><span class=\"tex\"><span class=\"texImage\"><img src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6aieqn4.gif\" alt=\"${{\\rm{\\Omega }}}_{m}=0.3$\" align=\"top\"></img></span><script type=\"math/tex\">{{\\rm{\\Omega }}}_{m}=0.3</script></span></span>, and <span xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"inline-eqn\"><span class=\"tex\"><span class=\"texImage\"><img src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6aieqn5.gif\" alt=\"${{\\rm{\\Omega }}}_{{\\rm{\\Lambda }}}=0.7$\" align=\"top\"></img></span><script type=\"math/tex\">{{\\rm{\\Omega }}}_{{\\rm{\\Lambda }}}=0.7</script></span></span>. Magnitudes are in the AB system where <span xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"inline-eqn\"><span class=\"tex\"><span class=\"texImage\"><img src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6aieqn6.gif\" alt=\"${m}_{\\mathrm{AB}}=23.9-2.5\\times \\mathrm{log}({f}_{\\nu }/1\\mu \\mathrm{Jy})$\" align=\"top\"></img></span><script type=\"math/tex\">{m}_{\\mathrm{AB}}=23.9-2.5\\times \\mathrm{log}({f}_{\\nu }/1\\mu \\mathrm{Jy})</script></span></span> (Oke &amp; Gunn <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib39\" id=\"fnref-apjaaae6abib39\">1983</a>).</p></div>\n<h2 class=\"header-anchor\" id=\"apjaaae6as2\" name=\"apjaaae6as2\">2.\u00a0Deep Learning Algorithms</h2><div class=\"article-text\" data-mobile-collapse=\"\"><p>Artificial neural networks are inspired by biological neurons. Just like biological neurons, artificial neurons receive input signals and send out an output signal to other neurons (see Figure <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" href=\"#apjaaae6af1\">1</a>). The synaptic connections between neurons are known as weights and the output of a neuron is known as its activation. To reduce the computational time and simplify neural network models, neurons are placed in consecutive layers rather than having a connection with every other neuron. This neural network setup is known as the Multi-layer Perception where neurons from one layer cannot talk to each other or to the neurons in arbitrary layers; they may only send their signal to the neurons in the succeeding layer. A neuron receives the weighted sum of the activation of all the neurons in the previous layer, adds an internal parameter known as the bias, and maps this sum to a value computed by an activation function (e.g., sigmoid, hyperbolic tangent, rectilinear, softmax). This model can be stated mathematically by the following equation:</p><div xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"display-eqn\" id=\"apjaaae6aeqn1\"><span class=\"tex\"><span class=\"texImage\"><img src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6aeqn1.gif\" alt=\"Equation (1)\"></img></span><script type=\"math/tex; mode=display\">\\begin{eqnarray}&&{a}_{i}^{l}=f\\left(\\displaystyle \\sum _{j}{a}_{j}^{l-1}{w}_{j\\to i}^{l}+{b}_{i}^{l}\\right).\\end{eqnarray}\n\t\t\t\t\\tag{\n\t\t\t\t1\n\t\t\t\t}\n\t\t\t</script></span></div><p>Here, <em>a</em><sub><em>i</em></sub><sup><em>l</em></sup> is the activation of the neuron in hand (i.e., the <em>i</em>th neuron in the <em>l</em>th layer), <em>f</em> is the activation function of this neuron, <span xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"inline-eqn\"><span class=\"tex\"><span class=\"texImage\"><img src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6aieqn7.gif\" alt=\"${a}_{j}^{l-1}$\" align=\"top\"></img></span><script type=\"math/tex\">{a}_{j}^{l-1}</script></span></span> is the activation of the neuron <em>j</em> in layer <em>l</em>\u00a0\u2212\u00a01 (the previous layer), <span xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"inline-eqn\"><span class=\"tex\"><span class=\"texImage\"><img src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6aieqn8.gif\" alt=\"${w}_{j\\to i}^{l}$\" align=\"top\"></img></span><script type=\"math/tex\">{w}_{j\\to i}^{l}</script></span></span> is the synaptic weight connecting the <em>i</em>th neuron in layer <em>l</em> to the <em>j</em>th neuron in layer <em>l</em>\u00a0\u2212\u00a01, and <em>b</em><sub><em>i</em></sub><sup><em>l</em></sup> is the bias of the neuron to adjust its activation sensitivity. The first layer, i.e., the input layer, in a deep learning neural net acts as a sensory layer, analogous to the retina. As it gets analyzed, the information from the input layer travels through multiple layers until it reaches the final layer, called the classification layer. Each class of images corresponds to a classifying neuron. In our case, we have a neuron corresponding to non-lens and another to lens images. The neuron with the highest output determines which class an input image is placed in.</p><figure xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"apjaaae6af1\" tabindex=\"-1\" role=\"group\" class=\"boxout boxout-bdr-grey keyboard-focus-only\" data-toolbar-type=\"figure\" data-toolbar-link=\"apjaaae6af1\" data-toolbar-img=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6af1_lr.jpg\" data-toolbar-title=\"Figure 1.\"><figure><div class=\"panzoom-container\"><div class=\"panzoom-parent\" style=\"overflow: hidden; position: relative;\"><img class=\"panzoom\" alt=\"Figure 1.\" src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6af1_lr.jpg\" style=\"transform: matrix(1, 0, 0, 1, 0, 0); backface-visibility: hidden; transform-origin: 50% 50% 0px; cursor: move; transition: transform 200ms ease-in-out 0s;\"></img></div><div class=\"buttons zoom-tools\"><button class=\"zoom-in\"><span class=\"icon-zoomin\"></span>\n\t                 Zoom In\n\t\t\t\t</button><button class=\"zoom-out\"><span class=\"icon-zoomout\"></span>\n\t                 Zoom Out\n\t\t\t\t</button><span class=\"mobile-block\"><button class=\"reset\"><span class=\"icon-loop\"></span>\n\t                     Reset image size\n\t\t\t\t\t</button></span></div></div><figcaption><div class=\"article-text figure-caption\"><p><strong>Figure 1.</strong>\u00a0Schematic representation of an artificial neuron. The weighted sum of the neurons in the previous layer (green circles), plus the internal bias of the neuron, are mapped as the output of the neuron by an activation function. This model is captured by Equation (<a class=\"eqnref\" href=\"#apjaaae6aeqn1\">1</a>). During the learning process, weights and biases of the neurons will be adjusted to achieve the desired network output.</p></div><p class=\"mb-05 print-hide\">Download figure:</p><span class=\"btn-multi-block print-hide\"><a class=\"btn btn-primary fig-dwnld-std-img\" id=\"wd-jnl-art-btn-std-img-apjaaae6af1\" href=\"/0004-637X/856/1/68/downloadFigure/figure/apjaaae6af1\"><span class=\"icon-image\"></span> Standard image\n\t\t\t\t\t</a><a class=\"btn btn-primary fig-dwnld-hi-img\" id=\"wd-jnl-art-btn-hires-img-apjaaae6af1\" href=\"/0004-637X/856/1/68/downloadHRFigure/figure/apjaaae6af1\"><span class=\"icon-image\"></span> High-resolution image\n\t\t\t\t\t</a></span></figcaption></figure></figure><p>A neural net learns how to classify images by adjusting the weights between its neurons and the biases within them, having one goal in mind: minimizing the loss function <span xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"inline-eqn\"><span class=\"tex\"><span class=\"texImage\"><img src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6aieqn9.gif\" alt=\"$C({\\boldsymbol{x}},{\\boldsymbol{y}})$\" align=\"top\"></img></span><script type=\"math/tex\">C({\\boldsymbol{x}},{\\boldsymbol{y}})</script></span></span>. The loss function, sometimes called the cost function, can take many forms but it has to capture the misfiring of the classification neurons, i.e., the deviation between the target class versus the predicted class. This is why such algorithms are known as supervised learning algorithms, in contrast to unsupervised techniques. A common choice for the loss function is the cross-entropy loss function with the following form (Nielsen <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib37\" id=\"fnref-apjaaae6abib37\">2016</a>):</p><div xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"display-eqn\" id=\"apjaaae6aeqn2\"><span class=\"tex\"><span class=\"texImage\"><img src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6aeqn2.gif\" alt=\"Equation (2)\"></img></span><script type=\"math/tex; mode=display\">\\begin{eqnarray}&&C({\\boldsymbol{x}},{\\boldsymbol{y}})={\\sum }_{j=\\text{non-lens},\\mathrm{lens}}{y}_{j}\\mathrm{ln}{a}_{j}^{L}+(1-{y}_{j})\\mathrm{ln}(1-{a}_{j}^{L}).\\end{eqnarray}\n\t\t\t\t\\tag{\n\t\t\t\t2\n\t\t\t\t}\n\t\t\t</script></span></div><p><em>a</em><sub><em>j</em></sub><sup><em>L</em></sup> is the activation of neurons in the final (classifying) layer, <span xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"inline-eqn\"><span class=\"tex\"><span class=\"texImage\"><img src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6aieqn10.gif\" alt=\"${\\boldsymbol{x}}$\" align=\"top\"></img></span><script type=\"math/tex\">{\\boldsymbol{x}}</script></span></span> is the input data in the vector form, and <span xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"inline-eqn\"><span class=\"tex\"><span class=\"texImage\"><img src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6aieqn11.gif\" alt=\"${\\boldsymbol{y}}$\" align=\"top\"></img></span><script type=\"math/tex\">{\\boldsymbol{y}}</script></span></span> represents the desired activations of the two classifying neurons. Of course, this function depends on the architecture of the neural net, weights, and biases, but they have not been expressed explicitly. As an example, if an image is a lens, its target output has to be (0.0, 1.0), meaning the activation of the non-lens neuron should be zero and the activation of the lens neuron should be unity. During the training process of a neural net, images from a training data set are presented to the network and the weights and the biases are adjusted to minimize the loss function for those images. The parameter space is massive and a change in one of the parameters of a neuron will affect the activation of a series of neurons in other layers. The first challenge is solved by minimizing algorithms such as the stochastic gradient descent (SGD) and the second one is solved via back-propagation. Since optimizing over the whole training set at once is not possible, because the training data would not fit in memory, stochastic optimization algorithms provide guaranteed convergence even if the gradients are evaluated on a randomly (stochastically) selected subset (batch) of the training data set. They provide a practical way to optimize a model over extremely large data sets. Batches yield noisy approximations to the true gradient, and larger batches can better approximate this quantity while if the batch size is too small, that approximation would be too poor and the algorithm may never converge in practice.</p><p>ConvNets are a class of neural networks with multiple convolutional layers. A convolutional layer consists of a set of convolving neurons (on the order of 10 neurons) that can be connected to a small rectangular region of an image. The set of weights of a convolving neuron is known as a filter and is subject to change as the ConvNet learns. A filter scans an entire image by striding (convolving with specified steps) over the image and assembling its output into an image, which is known as a feature map. Feature maps contain information such as texture and edges. See Figure <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" href=\"#apjaaae6af2\">2</a> as an example of a set of filters in a <span class=\"small-caps\">LensFlow</span> convolutional layer. A few examples of feature maps have been shown in Figure <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" href=\"#apjaaae6af3\">3</a>. These feature maps are bundled together as an image with the same number of channels as the number of feature maps. In this image, we have selected three feature maps and represent them with different colors to display what the neural network sees as the image passes through the layers.</p><figure xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"apjaaae6af2\" tabindex=\"-1\" role=\"group\" class=\"boxout boxout-bdr-grey keyboard-focus-only\" data-toolbar-type=\"figure\" data-toolbar-link=\"apjaaae6af2\" data-toolbar-img=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6af2_lr.jpg\" data-toolbar-title=\"Figure 2.\"><figure><div class=\"panzoom-container\"><div class=\"panzoom-parent\" style=\"overflow: hidden; position: relative;\"><img class=\"panzoom\" alt=\"Figure 2.\" src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6af2_lr.jpg\" style=\"transform: matrix(1, 0, 0, 1, 0, 0); backface-visibility: hidden; transform-origin: 50% 50% 0px; cursor: move; transition: transform 200ms ease-in-out 0s;\"></img></div><div class=\"buttons zoom-tools\"><button class=\"zoom-in\"><span class=\"icon-zoomin\"></span>\n\t                 Zoom In\n\t\t\t\t</button><button class=\"zoom-out\"><span class=\"icon-zoomout\"></span>\n\t                 Zoom Out\n\t\t\t\t</button><span class=\"mobile-block\"><button class=\"reset\"><span class=\"icon-loop\"></span>\n\t                     Reset image size\n\t\t\t\t\t</button></span></div></div><figcaption><div class=\"article-text figure-caption\"><p><strong>Figure 2.</strong>\u00a0Examples of filters used in a convolutional layer. The pixels in each box represent the weights of a convolving neuron that are connected to a 5\u00a0<b>&#x00d7;</b>\u00a05 region input image. As these filters convolve over the entire input image, they generate feature maps. Red pixels have a positive contribution and blue pixels have a negative contribution toward the activation of the convolving neuron. These filters are helpful for edge and texture recognition.</p></div><p class=\"mb-05 print-hide\">Download figure:</p><span class=\"btn-multi-block print-hide\"><a class=\"btn btn-primary fig-dwnld-std-img\" id=\"wd-jnl-art-btn-std-img-apjaaae6af2\" href=\"/0004-637X/856/1/68/downloadFigure/figure/apjaaae6af2\"><span class=\"icon-image\"></span> Standard image\n\t\t\t\t\t</a><a class=\"btn btn-primary fig-dwnld-hi-img\" id=\"wd-jnl-art-btn-hires-img-apjaaae6af2\" href=\"/0004-637X/856/1/68/downloadHRFigure/figure/apjaaae6af2\"><span class=\"icon-image\"></span> High-resolution image\n\t\t\t\t\t</a></span></figcaption></figure></figure><figure xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"apjaaae6af3\" tabindex=\"-1\" role=\"group\" class=\"boxout boxout-bdr-grey keyboard-focus-only\" data-toolbar-type=\"figure\" data-toolbar-link=\"apjaaae6af3\" data-toolbar-img=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6af3_lr.jpg\" data-toolbar-title=\"Figure 3.\"><figure><div class=\"panzoom-container\"><div class=\"panzoom-parent\" style=\"overflow: hidden; position: relative;\"><img class=\"panzoom\" alt=\"Figure 3.\" src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6af3_lr.jpg\" style=\"transform: matrix(1, 0, 0, 1, 0, 0); backface-visibility: hidden; transform-origin: 50% 50% 0px; cursor: move; transition: transform 200ms ease-in-out 0s;\"></img></div><div class=\"buttons zoom-tools\"><button class=\"zoom-in\"><span class=\"icon-zoomin\"></span>\n\t                 Zoom In\n\t\t\t\t</button><button class=\"zoom-out\"><span class=\"icon-zoomout\"></span>\n\t                 Zoom Out\n\t\t\t\t</button><span class=\"mobile-block\"><button class=\"reset\"><span class=\"icon-loop\"></span>\n\t                     Reset image size\n\t\t\t\t\t</button></span></div></div><figcaption><div class=\"article-text figure-caption\"><p><strong>Figure 3.</strong>\u00a0Examples of a convolutional layer feature maps. An image of a normalized physical lens has been shown in (1). ((2)\u2013(4)) Three outputs of the second convolution layer of <span class=\"small-caps\">LensFlow</span>. (5) The superposition of these three maps. As can be seen in (5), these feature maps create a contrast between the upper arc and the foreground source, making it possible for the fully connected layers to decide whether an imaged is a lens or a non-lens.</p></div><p class=\"mb-05 print-hide\">Download figure:</p><span class=\"btn-multi-block print-hide\"><a class=\"btn btn-primary fig-dwnld-std-img\" id=\"wd-jnl-art-btn-std-img-apjaaae6af3\" href=\"/0004-637X/856/1/68/downloadFigure/figure/apjaaae6af3\"><span class=\"icon-image\"></span> Standard image\n\t\t\t\t\t</a><a class=\"btn btn-primary fig-dwnld-hi-img\" id=\"wd-jnl-art-btn-hires-img-apjaaae6af3\" href=\"/0004-637X/856/1/68/downloadHRFigure/figure/apjaaae6af3\"><span class=\"icon-image\"></span> High-resolution image\n\t\t\t\t\t</a></span></figcaption></figure></figure></div>\n<h2 class=\"header-anchor\" id=\"apjaaae6as3\" name=\"apjaaae6as3\">3.\u00a0Methodology</h2><div class=\"article-text\" data-mobile-collapse=\"\"><p>This section covers the image normalization process, simulation of gravitational lenses and training and testing data set creation, architecture of <span class=\"small-caps\">LensFlow</span>, its pretraining on CIFAR data set, and its training on COSMOS data in two sequential steps: course and fine classification phases.</p><h3 id=\"apjaaae6as3-1\" name=\"apjaaae6as3-1\">3.1.\u00a0Data Extraction and Normalization</h3><div class=\"article-text\"><p>We used <em>HST</em>/ACS i-band observations in the full COSMOS field to search for candidate gravitationally lensed sources. In order to prepare the survey data for the neural network, we created 200\u00a0<b>&#x00d7;</b>\u00a0200 pixel cutouts around sources identified by <span class=\"small-caps\">SExtractor</span>, which corresponds to roughly 3\u00a0<b>&#x00d7;</b>\u00a03 square arcseconds. We ignored sources that extended less than 200 pixels total (not to be confused with our cutout size) and were not 1.5<em>\u03c3</em> brighter than the background, totaling 236,000 images. These images were then downsampled to 100\u00a0<b>&#x00d7;</b>\u00a0100 pixels to speed up the training and scanning process.</p><p>Before inputting the images to <span class=\"small-caps\">LensFlow</span>, we normalized and enhanced them, which is a necessary step to ensure a stable training and prevents activation saturation issues. For deep learning purposes, there are different methods of image normalization to choose from. This is due to the fact that raw image pixels come in a wide range of values. As we will discuss in the next section, when lenses are produced by superposing simulated arcs on top of actual sources, it is crucially important to ensure that superposed images are renormalized after the superposition process. If lens images are not renormalized, the net will become sensitive to the total sum of the pixels and achieve a meaningless perfect classification on the training and test data sets with no application for searching for real lens images.</p><p>There are different methods of image normalization used that often involve shifting the mean, normalizing the standard deviation, and bounding the pixels between two fixed values. Though sufficient for classification of daily object photos, we did not find these methods helpful to our algorithm since astronomical images require gamma correction to adjust the image contrast. Gamma correction introduces a nonlinearity according to the following equation:</p><div xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"display-eqn\" id=\"apjaaae6aeqn3\"><span class=\"tex\"><span class=\"texImage\"><img src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6aeqn3.gif\" alt=\"Equation (3)\"></img></span><script type=\"math/tex; mode=display\">\\begin{eqnarray}&&{p}_{\\mathrm{out}}={{Ap}}_{\\mathrm{in}}^{\\gamma },\\end{eqnarray}\n\t\t\t\t\\tag{\n\t\t\t\t3\n\t\t\t\t}\n\t\t\t</script></span></div><p>where <em>A</em> and <em>\u03b3</em> are constants and <em>p</em><sub>in</sub> and <em>p</em><sub>out</sub> are the initial and corrected pixel values. However, applying the same gamma function to different sources is not practical. For instance, the arcs in some lens images might get enhanced, while they are obscured by the foreground in other images. Similar problems happen when cutting off bright and dim pixels. To overcome these issue, we have selected one dim real lens image and have adjusted its brightness, its contrast, and have performed gamma correction so the foreground source and the arcs are clearly separated and visible, while keeping all pixel values between 0 and 1. The image histogram (the histogram of pixel values) of this modified lens image was extracted (See Figure <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" href=\"#apjaaae6af4\">4</a>) and was used as a template histogram to transform the image histogram of all the extracted sources. This method not only enhances the arcs for all the previously known lenses from COSMOS, but it also automates the process of gamma correction and normalization since all pixel values fall between 0 and 1 and their mean and their standard deviation are roughly the same.</p><figure xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"apjaaae6af4\" tabindex=\"-1\" role=\"group\" class=\"boxout boxout-bdr-grey keyboard-focus-only\" data-toolbar-type=\"figure\" data-toolbar-link=\"apjaaae6af4\" data-toolbar-img=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6af4_lr.jpg\" data-toolbar-title=\"Figure 4.\"><figure><div class=\"panzoom-container\"><div class=\"panzoom-parent\" style=\"overflow: hidden; position: relative;\"><img class=\"panzoom\" alt=\"Figure 4.\" src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6af4_lr.jpg\" style=\"transform: matrix(1, 0, 0, 1, 0, 0); backface-visibility: hidden; transform-origin: 50% 50% 0px; cursor: move; transition: transform 200ms ease-in-out 0s;\"></img></div><div class=\"buttons zoom-tools\"><button class=\"zoom-in\"><span class=\"icon-zoomin\"></span>\n\t                 Zoom In\n\t\t\t\t</button><button class=\"zoom-out\"><span class=\"icon-zoomout\"></span>\n\t                 Zoom Out\n\t\t\t\t</button><span class=\"mobile-block\"><button class=\"reset\"><span class=\"icon-loop\"></span>\n\t                     Reset image size\n\t\t\t\t\t</button></span></div></div><figcaption><div class=\"article-text figure-caption\"><p><strong>Figure 4.</strong>\u00a0Template image histogram for image normalization. The histograms of all sources were transformed to match this template histogram, which was obtained by adjusting the brightness and the contrast and by performing gamma correction for a known dim lens image displayed above. This transformation not only normalizes images, but it will also enhance the contrast between the arcs and the foreground source.</p></div><p class=\"mb-05 print-hide\">Download figure:</p><span class=\"btn-multi-block print-hide\"><a class=\"btn btn-primary fig-dwnld-std-img\" id=\"wd-jnl-art-btn-std-img-apjaaae6af4\" href=\"/0004-637X/856/1/68/downloadFigure/figure/apjaaae6af4\"><span class=\"icon-image\"></span> Standard image\n\t\t\t\t\t</a><a class=\"btn btn-primary fig-dwnld-hi-img\" id=\"wd-jnl-art-btn-hires-img-apjaaae6af4\" href=\"/0004-637X/856/1/68/downloadHRFigure/figure/apjaaae6af4\"><span class=\"icon-image\"></span> High-resolution image\n\t\t\t\t\t</a></span></figcaption></figure></figure></div><h3 id=\"apjaaae6as3-2\" name=\"apjaaae6as3-2\">3.2.\u00a0Lens Simulation</h3><div class=\"article-text\"><p>In order to train a neural network, typically a few thousand examples are needed per class. Since the number of known lenses are far more limited than the required number, these lenses have to be simulated. For these simulations, we used <span class=\"small-caps\">lenstool</span> (Jullo et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib21\" id=\"fnref-apjaaae6abib21\">2007</a>) to generate image plane models of lensing systems using realistic models of randomly selected elliptical galaxies within the COSMOS field as deflectors and coadded these to the selected elliptical galaxies to generate the training set. Here, we focus on elliptical galaxies as foreground deflectors. Although known examples of spiral galaxy lensing exist (Calanog et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib8\" id=\"fnref-apjaaae6abib8\">2014</a>), most galaxy\u2013galaxy lensing events occur around massive elliptical galaxies as foreground deflectors. We generated a training set of 200 galaxies using this method. Figure <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" href=\"#apjaaae6af5\">5</a> shows several examples from the generated training set used by <span class=\"small-caps\">LensFlow</span>.</p><figure xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"apjaaae6af5\" tabindex=\"-1\" role=\"group\" class=\"boxout boxout-bdr-grey keyboard-focus-only\" data-toolbar-type=\"figure\" data-toolbar-link=\"apjaaae6af5\" data-toolbar-img=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6af5_lr.jpg\" data-toolbar-title=\"Figure 5.\"><figure><div class=\"panzoom-container\"><div class=\"panzoom-parent\" style=\"overflow: hidden; position: relative;\"><img class=\"panzoom\" alt=\"Figure 5.\" src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6af5_lr.jpg\" style=\"transform: matrix(1, 0, 0, 1, 0, 0); backface-visibility: hidden; transform-origin: 50% 50% 0px; cursor: move; transition: transform 200ms ease-in-out 0s;\"></img></div><div class=\"buttons zoom-tools\"><button class=\"zoom-in\"><span class=\"icon-zoomin\"></span>\n\t                 Zoom In\n\t\t\t\t</button><button class=\"zoom-out\"><span class=\"icon-zoomout\"></span>\n\t                 Zoom Out\n\t\t\t\t</button><span class=\"mobile-block\"><button class=\"reset\"><span class=\"icon-loop\"></span>\n\t                     Reset image size\n\t\t\t\t\t</button></span></div></div><figcaption><div class=\"article-text figure-caption\"><p><strong>Figure 5.</strong>\u00a0Examples of simulated lenses.</p></div><p class=\"mb-05 print-hide\">Download figure:</p><span class=\"btn-multi-block print-hide\"><a class=\"btn btn-primary fig-dwnld-std-img\" id=\"wd-jnl-art-btn-std-img-apjaaae6af5\" href=\"/0004-637X/856/1/68/downloadFigure/figure/apjaaae6af5\"><span class=\"icon-image\"></span> Standard image\n\t\t\t\t\t</a><a class=\"btn btn-primary fig-dwnld-hi-img\" id=\"wd-jnl-art-btn-hires-img-apjaaae6af5\" href=\"/0004-637X/856/1/68/downloadHRFigure/figure/apjaaae6af5\"><span class=\"icon-image\"></span> High-resolution image\n\t\t\t\t\t</a></span></figcaption></figure></figure><p>As discussed in the previous section, simulated lenses must be renormalized to prevent the net from classifying lenses based on the total sum of the pixels since without normalization, the total pixel sum of lens images will always be higher than non-lens images.</p><p>The number of generated lenses is still very low for training purposes. To overcome this, we can use image augmentation to artificially boost the number of training examples. We do this by rotating and reflecting images. In more detail, we use eight transformations that come from eight elements of the symmetry group of the square, namely: 0\u00b0, 90\u00b0, 180\u00b0, and 270\u00b0 rotations, and horizontal, vertical, diagonal, and anti-diagonal reflections. In addition to rotation and to reflection, we take eight 90\u00a0<b>&#x00d7;</b>\u00a090 pixel cutouts at random positions and rescale them to 100\u00a0<b>&#x00d7;</b>\u00a0100 pixels. We will refer to these two processes as image augmentation.</p></div><h3 id=\"apjaaae6as3-3\" name=\"apjaaae6as3-3\">3.3.\u00a0Architecture of <span class=\"small-caps\">LensFlow</span> ConvNet and Pretraining (Phase 0)</h3><div class=\"article-text\"><p>The architecture of the data determines the dimensionality of the ConvNet layers. We use 1\u00a0<b>&#x00d7;</b>\u00a0100\u00a0<b>&#x00d7;</b>\u00a0100 images, where 1 indicates the number of color channels.<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6afn3\">3</a></sup>\n Classifying lenses with multiple color bands will be easier and more accurate since foreground and background sources have a color contrast. However, we have chosen to use one color channel so our algorithm can be sensitive to geometry rather than color contrast in order to expand its applicability to a wider range of bands as well as eliminating its need for multiband images when unavailable. The results of galaxy lens identification from wide-area surveys with color information will appear in a future work (M. Pourrahmani et al. 2018 in preparation). As we see in Figure <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" href=\"#apjaaae6af6\">6</a> and Table <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"tabref\" href=\"#apjaaae6at1\">1</a>, after normalizing these single-channeled images, <span class=\"small-caps\">LensFlow</span> applies an average-pooling of a kernel of size 5\u00a0<b>&#x00d7;</b>\u00a05 and a stride of 1 without padding. The hyperbolic tangent function introduces nonlinearity to the convolution layer. The common choice is often a rectified linear unit (ReLU), which sets pixels smaller than a self-learned threshold to zero. ReLU is ideal for edge detection but since astronomical images do not have hard edges, an smoother function like the hyperbolic tangent is suited. The output of this layer is fed to a pooling layer with a kernel of size 2\u00a0<b>&#x00d7;</b>\u00a02 and a stride of 1, outputting the largest pixel value as it convolves its input for all channels. The result of this layer is a set of 30 downsampled (48 <b>&#x00d7;</b> 48) feature maps. The next two convolution layers are identical to the first set described above except that the second convolution layer has 60 and the last convolution layer has 90 filters. The output of the last convolution layer is a set of 90\u00a0<b>&#x00d7;</b>\u00a09\u00a0<b>&#x00d7;</b>\u00a09 feature maps, which are flattened from a tensor to a 1D vector with 7290 rows, which is fed to the fully connected layers. The first fully connected layer has 1000 linear neurons (identity function as <em>f</em> in Equation (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"eqnref\" href=\"#apjaaae6aeqn1\">1</a>)). This layer is followed by a dropout layer where the output of 50% of the neurons is set to zero. Dropout layers prevent overfitting in early stages of training. Two more linear layers of size 800 and 600 follow this layer. Finally, all inputs are fed to a linear layer of size two with a softmax nonlinearity. These two layers act as a classifying layer where the softmax layer converts the output of the linear layer to probabilities:</p><div xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"display-eqn\" id=\"apjaaae6aeqn4\"><span class=\"tex\"><span class=\"texImage\"><img src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6aeqn4.gif\" alt=\"Equation (4)\"></img></span><script type=\"math/tex; mode=display\">\\begin{eqnarray}&&{\\sigma }_{c}({\\boldsymbol{Z}})=\\displaystyle \\frac{{e}^{{Z}_{c}}}{{e}^{{Z}_{\\mathrm{non} \\mbox{-} \\mathrm{lens}}}+{e}^{{Z}_{\\mathrm{lens}}}}.\\end{eqnarray}\n\t\t\t\t\\tag{\n\t\t\t\t4\n\t\t\t\t}\n\t\t\t</script></span></div><p>Here, each component of <span xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"inline-eqn\"><span class=\"tex\"><span class=\"texImage\"><img src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6aieqn12.gif\" alt=\"${\\boldsymbol{Z}}$\" align=\"top\"></img></span><script type=\"math/tex\">{\\boldsymbol{Z}}</script></span></span> is the output of the last linear layer (i.e., output of Layer 20) with two components. <em>c</em> specifies whether we are talking about the neuron corresponding to lens or non-lens images. The softmax function ensures the output sums to one and when used with the cross-entropy loss function, these outputs are interpreted as class probabilities. We use these probabilities to rank images from most probable lens candidates to least probable.</p><figure xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"apjaaae6af6\" tabindex=\"-1\" role=\"group\" class=\"boxout boxout-bdr-grey keyboard-focus-only\" data-toolbar-type=\"figure\" data-toolbar-link=\"apjaaae6af6\" data-toolbar-img=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6af6_lr.jpg\" data-toolbar-title=\"Figure 6.\"><figure><div class=\"panzoom-container\"><div class=\"panzoom-parent\" style=\"overflow: hidden; position: relative;\"><img class=\"panzoom\" alt=\"Figure 6.\" src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6af6_lr.jpg\" style=\"transform: matrix(1, 0, 0, 1, 0, 0); backface-visibility: hidden; transform-origin: 50% 50% 0px; cursor: move; transition: transform 200ms ease-in-out 0s;\"></img></div><div class=\"buttons zoom-tools\"><button class=\"zoom-in\"><span class=\"icon-zoomin\"></span>\n\t                 Zoom In\n\t\t\t\t</button><button class=\"zoom-out\"><span class=\"icon-zoomout\"></span>\n\t                 Zoom Out\n\t\t\t\t</button><span class=\"mobile-block\"><button class=\"reset\"><span class=\"icon-loop\"></span>\n\t                     Reset image size\n\t\t\t\t\t</button></span></div></div><figcaption><div class=\"article-text figure-caption\"><p><strong>Figure 6.</strong>\u00a0Representation of data flow through the ConvNet layers. The data is downsampled and fed to three convolutional-max-pooling layers. The data is then flattened into an array and is fed to three fully connected linear layers, which are then connected to the classifying layers consisting of a linear layer with two neurons followed by a sofmax layer. The convolution layers are responsible for feature extraction and the fully connected layers learn the difference between non-lens and lens images.</p></div><p class=\"mb-05 print-hide\">Download figure:</p><span class=\"btn-multi-block print-hide\"><a class=\"btn btn-primary fig-dwnld-std-img\" id=\"wd-jnl-art-btn-std-img-apjaaae6af6\" href=\"/0004-637X/856/1/68/downloadFigure/figure/apjaaae6af6\"><span class=\"icon-image\"></span> Standard image\n\t\t\t\t\t</a><a class=\"btn btn-primary fig-dwnld-hi-img\" id=\"wd-jnl-art-btn-hires-img-apjaaae6af6\" href=\"/0004-637X/856/1/68/downloadHRFigure/figure/apjaaae6af6\"><span class=\"icon-image\"></span> High-resolution image\n\t\t\t\t\t</a></span></figcaption></figure></figure><div tabindex=\"-1\" id=\"apjaaae6at1\" class=\"boxout boxout-bdr-grey keyboard-focus-only\"><p><b>Table 1.</b>\u00a0\nTabulated Architecture of the <span class=\"small-caps\">LensFlow</span> ConvNet\n</p><table cellpadding=\"0\" cellspacing=\"0\" border=\"0\" data-toolbar-link=\"apjaaae6at1\" data-toolbar-img=\"/0004-637X/856/1/68/suppdata/apjaaae6at1_lr.gif\" data-toolbar-type=\"table\" data-toolbar-title=\"Table 1\"><colgroup><col align=\"left\"></col><col align=\"left\"></col><col align=\"left\"></col></colgroup><thead>\n<tr valign=\"top\">\n<th scope=\"col\" colspan=\"1\" rowspan=\"1\" align=\"left\">Layer</th>\n<th scope=\"col\" colspan=\"1\" rowspan=\"1\" align=\"left\">Type</th>\n<th scope=\"col\" colspan=\"1\" rowspan=\"1\" align=\"center\">Data Dimensionality</th>\n</tr>\n</thead><tbody>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">\u00a0</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">input</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">1\u00a0<b>&#x00d7;</b>\u00a0100\u00a0<b>&#x00d7;</b>\u00a0100</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">1</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">convolution</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">30\u00a0<b>&#x00d7;</b>\u00a096\u00a0<b>&#x00d7;</b>\u00a096</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">2</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">tanh</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">30\u00a0<b>&#x00d7;</b>\u00a096\u00a0<b>&#x00d7;</b>\u00a096</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">3</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">pooling</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">30\u00a0<b>&#x00d7;</b>\u00a048\u00a0<b>&#x00d7;</b>\u00a048</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">4</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">convolution</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">60\u00a0<b>&#x00d7;</b>\u00a044\u00a0<b>&#x00d7;</b>\u00a044</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">5</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">tanh</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">60\u00a0<b>&#x00d7;</b>\u00a044\u00a0<b>&#x00d7;</b>\u00a044</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">6</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">pooling</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">60\u00a0<b>&#x00d7;</b>\u00a022\u00a0<b>&#x00d7;</b>\u00a022</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">7</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">convolution</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">90\u00a0<b>&#x00d7;</b>\u00a018\u00a0<b>&#x00d7;</b>\u00a018</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">8</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">tanh</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">90\u00a0<b>&#x00d7;</b>\u00a018\u00a0<b>&#x00d7;</b>\u00a018</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">9</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">pooling</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">90\u00a0<b>&#x00d7;</b>\u00a09\u00a0<b>&#x00d7;</b>\u00a09</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">10</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">flatten</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">7290</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">11</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">linear</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">1000</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">12</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">ReLU</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">1000</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">13</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">dropout</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">1000</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">14</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">linear</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">800</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">15</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">ReLU</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">800</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">16</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">dropout</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">800</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">17</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">linear</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">600</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">18</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">ReLU</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">600</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">19</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">dropout</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">600</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">20</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">linear</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">2</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">21</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">softmax</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">2</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">\u00a0</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">output</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">2</td>\n</tr>\n</tbody></table><p class=\"franklin fs-16\">\n\t\t\tDownload table as:\u00a0\n            <span class=\"btn-multi-block\"><a class=\"btn btn-primary wd-jnl-art-btn-ascii\" href=\"/0004-637X/856/1/68/suppdata/apjaaae6at1_ascii.txt?doi=10.3847/1538-4357/aaae6a\" target=\"_blank\">ASCII</a><a class=\"btn btn-primary wd-jnl-art-btn-typeset typeset-table-img\" href=\"/0004-637X/856/1/68/suppdata/apjaaae6at1_lr.gif\" target=\"_blank\">Typeset image</a></span></p></div><p>To optimize our ConvNet, we have chosen a cross-entropy function as our loss function, which we minimize using the Adam Optimizer. This adaptive optimizer algorithm computes individual adaptive learning rates for different parameters from estimates of first and second moments of the gradients for the loss function (Kingma &amp; Ba <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib23\" id=\"fnref-apjaaae6abib23\">2014</a>). During the training phase, 64 non-lens and 64 lens images were placed in a batch of 128 images. This combination technique will prevent under- or over-representation of classes even if the training size for different classes contains a different number of examples.</p><p>A common practice for training a neural net on a smaller data set is to first pretrain it on a different but larger data set and later, retrain it on the main but smaller data set in hand, while keeping the weights and biases in the convolution layers stiff or fixed by dampening the learning rate. This is valid since these layers are used for general feature extraction. On the other hand, these parameters are relaxed in the fully connected layers where the main task of classification takes place. This technique is known as transfer learning. We have selected two classes from the CIFAR data set, a famous data set used for testing computer vision algorithms. After reducing the images to grayscale and changing their size to 100\u00a0<b>&#x00d7;</b>\u00a0100 pixels, we applied the image normalization explained above. Before training, it is important to properly initialize the weights and biases. While setting all biases to zero, we use the Xavier method (Glorot &amp; Bengio <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib15\" id=\"fnref-apjaaae6abib15\">2010</a>) where the neuron weights in layer <em>L</em> are sampled from a normal distribution with a mean of zero and a variance of 2/(<em>N</em><sup><em>L</em></sup>\u00a0+\u00a0<em>N</em><sup><em>L</em>+1</sup>), where <em>N</em><sup><em>L</em></sup> is the size of layer <em>L</em>. Xavier weight initialization addresses the vanishing gradient problem and prevents the existence of overly strong or overly weak weights resulting in a steady signal throughout the network. After initializing, an initial learning rate of <span xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"inline-eqn\"><span class=\"tex\"><span class=\"texImage\"><img src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6aieqn13.gif\" alt=\"$8.\\times {10}^{-4}$\" align=\"top\"></img></span><script type=\"math/tex\">8.\\times {10}^{-4}</script></span></span> was chosen and the network was trained for a total of eight rounds. The number of iteration rounds is determined by the deviation of the loss function for training and test data sets. It is an indication of overfitting if the average loss function for the training data set drops while it remains the same or increases for the test data set. In simpler terms, overfitting means the net is memorizing the training data set rather than learning generalizable feature extraction and classification. Similarly, we determine the number of iteration rounds for other training phases discussed in the following two subsections. Pretraining is crucial for our data set without which no learning occurs. We suspect that having soft edges as well as a central dominant object are the main causes of the trouble here, preventing the network from learning edge detection and picking up on arc-like features. Techniques such as reducing the brightness of central pixels were tested that triggered the learning process even though with a poor performance. However, by using a pretrained net, the need for masking the central bright pixels was eliminated and a much better performance was achieved.</p></div><h3 id=\"apjaaae6as3-4\" name=\"apjaaae6as3-4\">3.4.\u00a0Coarse Classification Phase (Phase 1)</h3><div class=\"article-text\"><p>The training data set for this phase consists of 3200 lenses created by augmenting the 200 simulated lenses and randomly selecting 3200 images from COSMOS. It is possible that these randomly selected images contain actual lenses, but a few misclassified examples will not affect the training process in a noticeable way. To generate a validation and a testing data set, we have selected 52 out of 67 discovered lens candidates by Faure et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib12\" id=\"fnref-apjaaae6abib12\">2008</a>) and have applied image augmentation (rotations and reflections only) to increase their number to 464, which were accompanied by 464 randomly selected images from COSMOS labeled as non-lens images. Among the lens candidates that were not selected, three were larger than 3 arcseconds in diameter, one did not have an i-band image, and the rest did not have any arc features in the i-band and were classified as lenses by Faure et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib12\" id=\"fnref-apjaaae6abib12\">2008</a>) by mainly relying on other bands.</p><p>Since the convolution layers of the pretrained net (layers 1 to 10 in Table <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"tabref\" href=\"#apjaaae6at1\">1</a>) are used for feature extraction and are transferable from one data set to another, during the training process on COSMOS data, the learning rate of those layers were reduced to 10 %. On the other hand, the main purpose of the fully connected layers are to classify based on the extracted features and are not transferable. Hence, their learning rate was unaltered during the training process.</p><p>After 20 training epochs, we conducted two main performance tests. The first test is obtaining the receiver operating characteristic curve, i.e., plotting the ROC curve, which is a standard measure of the performance of a classifier. As plotted in Figure <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" href=\"#apjaaae6af7\">7</a>, the horizontal and the vertical axes indicate the false positive rate (FPR) and the true positive rate (TPR) respectively. The ROC curve is obtained by evaluating FPR and TPR for different classification thresholds (i.e., the minimum lens probability for an image to be categorized as lens). Even though ROC curves are very useful for most classifiers, we suggest a different performance measure that is more appropriate for the field of astronomy where thousands or millions of images have to be scanned to identify desired sources. In our case, after training the net, we have placed the 52 selected lenses as tracers among the entire 236,000 source images extracted from COSMOS. The assigned lens probability by this net has been used to rank the images from the most likely lens candidates to the least likely. The number of recovered tracer lenses as a function of relative ranks (i.e., rank of an image divided by the total number of images) are plotted in Figure <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" href=\"#apjaaae6af8\">8</a>. We will refer to this curve as the tracer rank curve (TRC). We see that 100% of tracer lenses fall in the top 6% of the sorted images. A TRC can be quantified by one number, which we refer to as the ranking performance. We define the ranking performance as the area between a TRC (the solid black line in Figure <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" href=\"#apjaaae6af8\">8</a>) and the line of no discrimination (the dashed red line in the same figure) divided by the TRC for a perfect classifier (i.e., approximately one-half when the number of scanned images is much larger than the number of tracer images). Therefore, a ranking performance of 1 corresponds to placing all tracer lenses in the highest ranks, while a ranking performance of 0 corresponds to dispersing tracer lenses among all images, which is a sign of no learning. A negative ranking performance, on the other hand, means the classifier is systematically misclassifying images. The ranking performance of our ConvNet during this phase is 0.97 which is quite good for such a simple ConvNet applied on a data set with one color channel. However, placing all the tracer lenses in the top 6% means lenses have to be recovered among 14,000 images. Even though this is a massive reduction from 236,000, examining 14,000 images by eye is not very practical and would be impossible for larger surveys. For this reason, we have introduced another phase that specializes in finding lenses among the remaining 14,000 images by retraining our net on the top 6% images, as discussed in the following subsection.</p><figure xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"apjaaae6af7\" tabindex=\"-1\" role=\"group\" class=\"boxout boxout-bdr-grey keyboard-focus-only\" data-toolbar-type=\"figure\" data-toolbar-link=\"apjaaae6af7\" data-toolbar-img=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6af7_lr.jpg\" data-toolbar-title=\"Figure 7.\"><figure><div class=\"panzoom-container\"><div class=\"panzoom-parent\" style=\"overflow: hidden; position: relative;\"><img class=\"panzoom\" alt=\"Figure 7.\" src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6af7_lr.jpg\" style=\"transform: matrix(1, 0, 0, 1, 0, 0); backface-visibility: hidden; transform-origin: 50% 50% 0px; cursor: move; transition: transform 200ms ease-in-out 0s;\"></img></div><div class=\"buttons zoom-tools\"><button class=\"zoom-in\"><span class=\"icon-zoomin\"></span>\n\t                 Zoom In\n\t\t\t\t</button><button class=\"zoom-out\"><span class=\"icon-zoomout\"></span>\n\t                 Zoom Out\n\t\t\t\t</button><span class=\"mobile-block\"><button class=\"reset\"><span class=\"icon-loop\"></span>\n\t                     Reset image size\n\t\t\t\t\t</button></span></div></div><figcaption><div class=\"article-text figure-caption\"><p><strong>Figure 7.</strong>\u00a0Receiver operating characteristic (ROC) diagram. The black curve shows the trend of the true positive rate verses the false positive rate of LensFlow, while the red dashed curve shows an untrained classifier.</p></div><p class=\"mb-05 print-hide\">Download figure:</p><span class=\"btn-multi-block print-hide\"><a class=\"btn btn-primary fig-dwnld-std-img\" id=\"wd-jnl-art-btn-std-img-apjaaae6af7\" href=\"/0004-637X/856/1/68/downloadFigure/figure/apjaaae6af7\"><span class=\"icon-image\"></span> Standard image\n\t\t\t\t\t</a><a class=\"btn btn-primary fig-dwnld-hi-img\" id=\"wd-jnl-art-btn-hires-img-apjaaae6af7\" href=\"/0004-637X/856/1/68/downloadHRFigure/figure/apjaaae6af7\"><span class=\"icon-image\"></span> High-resolution image\n\t\t\t\t\t</a></span></figcaption></figure></figure><figure xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"apjaaae6af8\" tabindex=\"-1\" role=\"group\" class=\"boxout boxout-bdr-grey keyboard-focus-only\" data-toolbar-type=\"figure\" data-toolbar-link=\"apjaaae6af8\" data-toolbar-img=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6af8_lr.jpg\" data-toolbar-title=\"Figure 8.\"><figure><div class=\"panzoom-container\"><div class=\"panzoom-parent\" style=\"overflow: hidden; position: relative;\"><img class=\"panzoom\" alt=\"Figure 8.\" src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6af8_lr.jpg\" style=\"transform: matrix(1, 0, 0, 1, 0, 0); backface-visibility: hidden; transform-origin: 50% 50% 0px; cursor: move; transition: transform 200ms ease-in-out 0s;\"></img></div><div class=\"buttons zoom-tools\"><button class=\"zoom-in\"><span class=\"icon-zoomin\"></span>\n\t                 Zoom In\n\t\t\t\t</button><button class=\"zoom-out\"><span class=\"icon-zoomout\"></span>\n\t                 Zoom Out\n\t\t\t\t</button><span class=\"mobile-block\"><button class=\"reset\"><span class=\"icon-loop\"></span>\n\t                     Reset image size\n\t\t\t\t\t</button></span></div></div><figcaption><div class=\"article-text figure-caption\"><p><strong>Figure 8.</strong>\u00a0Normalized ranking of tracer lenses by <span class=\"small-caps\">LensFlow</span>. Ranking performance is defined as the area between the black tracer rank curve (TRC) and the dashed red line of no discrimination divided by the area between a perfect TRC and the line of no discrimination (approximately one-half for large data sets). Left: 100% of the tracer lenses are in the top 6%. The ranking performance of Phase 1 is 0.97. Right: during Phase 2, the ConvNet was trained on the top 6% images from Phase 1. The ranking of the tracer lenses has been shown. 80% of the tracer lenses are in the top 30%. The ranking performance of Phase 2 is 0.60.</p></div><p class=\"mb-05 print-hide\">Download figure:</p><span class=\"btn-multi-block print-hide\"><a class=\"btn btn-primary fig-dwnld-std-img\" id=\"wd-jnl-art-btn-std-img-apjaaae6af8\" href=\"/0004-637X/856/1/68/downloadFigure/figure/apjaaae6af8\"><span class=\"icon-image\"></span> Standard image\n\t\t\t\t\t</a><a class=\"btn btn-primary fig-dwnld-hi-img\" id=\"wd-jnl-art-btn-hires-img-apjaaae6af8\" href=\"/0004-637X/856/1/68/downloadHRFigure/figure/apjaaae6af8\"><span class=\"icon-image\"></span> High-resolution image\n\t\t\t\t\t</a></span></figcaption></figure></figure></div><h3 id=\"apjaaae6as3-5\" name=\"apjaaae6as3-5\">3.5.\u00a0Fine Classification Phase (Phase 2)</h3><div class=\"article-text\"><p>In order to further reduce the number of images that have to be examined by eye, we have constructed a data set by randomly selecting 3200 images from the remaining COSMOS images from Phase 1. The same 3200 augmented simulated lens images were added to complete the data set. The ConvNet was trained over 25 iterations and the remaining images from Phase 1 were scanned and ranked using this net. The first 300 images were examined, which included some lenses but mostly artifacts, spiral galaxies, and satellite galaxies (see Figure <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" href=\"#apjaaae6af9\">9</a>). Lens images were removed and the remaining were augmented and added to the training data set for retraining to eliminate most probable false classifications. The TRC for this net is plotted in the right panel of Figure <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" href=\"#apjaaae6af8\">8</a> with a ranking performance of 0.60. The same net with the same methodology could do extremely better if images had color information, which is not present in our data. Other ways to improve the results is to create a more diverse and larger data set, which is very time consuming. Using more complex nets such as GoogLeNet with perception models might improve the results, which we will investigate in a future study. The results of Phase 1 show that simple and fast deep learning algorithms, such as ours, are sufficient enough to reduce the data by a factor of 17 since both training and scanning are more time consuming with complex nets such as GoogLeNet.</p><figure xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"apjaaae6af9\" tabindex=\"-1\" role=\"group\" class=\"boxout boxout-bdr-grey keyboard-focus-only\" data-toolbar-type=\"figure\" data-toolbar-link=\"apjaaae6af9\" data-toolbar-img=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6af9_lr.jpg\" data-toolbar-title=\"Figure 9.\"><figure><div class=\"panzoom-container\"><div class=\"panzoom-parent\" style=\"overflow: hidden; position: relative;\"><img class=\"panzoom\" alt=\"Figure 9.\" src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6af9_lr.jpg\" style=\"transform: matrix(1, 0, 0, 1, 0, 0); backface-visibility: hidden; transform-origin: 50% 50% 0px; cursor: move; transition: transform 200ms ease-in-out 0s;\"></img></div><div class=\"buttons zoom-tools\"><button class=\"zoom-in\"><span class=\"icon-zoomin\"></span>\n\t                 Zoom In\n\t\t\t\t</button><button class=\"zoom-out\"><span class=\"icon-zoomout\"></span>\n\t                 Zoom Out\n\t\t\t\t</button><span class=\"mobile-block\"><button class=\"reset\"><span class=\"icon-loop\"></span>\n\t                     Reset image size\n\t\t\t\t\t</button></span></div></div><figcaption><div class=\"article-text figure-caption\"><p><strong>Figure 9.</strong>\u00a0Examples of common misclassified images. These images were used to retrain <span class=\"small-caps\">LensFlow</span> to improve its ranking performance.</p></div><p class=\"mb-05 print-hide\">Download figure:</p><span class=\"btn-multi-block print-hide\"><a class=\"btn btn-primary fig-dwnld-std-img\" id=\"wd-jnl-art-btn-std-img-apjaaae6af9\" href=\"/0004-637X/856/1/68/downloadFigure/figure/apjaaae6af9\"><span class=\"icon-image\"></span> Standard image\n\t\t\t\t\t</a><a class=\"btn btn-primary fig-dwnld-hi-img\" id=\"wd-jnl-art-btn-hires-img-apjaaae6af9\" href=\"/0004-637X/856/1/68/downloadHRFigure/figure/apjaaae6af9\"><span class=\"icon-image\"></span> High-resolution image\n\t\t\t\t\t</a></span></figcaption></figure></figure></div><h3 id=\"apjaaae6as3-6\" name=\"apjaaae6as3-6\">3.6.\u00a0Search Phase (Phase 3)</h3><div class=\"article-text\"><p>This phase is identical to the previous phase with the exception of including augmented tracer lenses in the training data set in order to increase the size of the data set to improve the chances of finding new lens candidates. The previous phase was necessary to obtain the maximum number of training epochs and to test the performance of <span class=\"small-caps\">LensFlow</span>. After training this ConvNet, we examined 2000 images and identified 46 new lens candidates that were not mentioned in Faure et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib12\" id=\"fnref-apjaaae6abib12\">2008</a>; the examination process took roughly 20 minutes). These lens candidates are shown in Figure <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" href=\"#apjaaae6af10\">10</a> and their coordinates are listed in Table <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"tabref\" href=\"#apjaaae6at2\">2</a> (see Appendix <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"secref\" href=\"#apjaaae6aapp2\">B</a>). Classification algorithms like ours can benefit from Citizen Science projects such as the <span class=\"small-caps\">SPACE WARPS</span> project (Marshall et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib31\" id=\"fnref-apjaaae6abib31\">2015</a>; More et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib34\" id=\"fnref-apjaaae6abib34\">2016</a>), where volunteers are presented with real and simulated gravitational lenses in order to obtain a measure of their classification performance, while identifying new lenses. Citizen Science projects such as <span class=\"small-caps\">SPACE WARPS</span> can help with classification of images with high lensing probabilities assigned by automated classifiers.</p><figure xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"apjaaae6af10\" tabindex=\"-1\" role=\"group\" class=\"boxout boxout-bdr-grey keyboard-focus-only\" data-toolbar-type=\"figure\" data-toolbar-link=\"apjaaae6af10\" data-toolbar-img=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6af10_lr.jpg\" data-toolbar-title=\"Figure 10.\"><figure><div class=\"panzoom-container\"><div class=\"panzoom-parent\" style=\"overflow: hidden; position: relative;\"><img class=\"panzoom\" alt=\"Figure 10.\" src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6af10_lr.jpg\" style=\"transform: matrix(1, 0, 0, 1, 0, 0); backface-visibility: hidden; transform-origin: 50% 50% 0px; cursor: move; transition: transform 200ms ease-in-out 0s;\"></img></div><div class=\"buttons zoom-tools\"><button class=\"zoom-in\"><span class=\"icon-zoomin\"></span>\n\t                 Zoom In\n\t\t\t\t</button><button class=\"zoom-out\"><span class=\"icon-zoomout\"></span>\n\t                 Zoom Out\n\t\t\t\t</button><span class=\"mobile-block\"><button class=\"reset\"><span class=\"icon-loop\"></span>\n\t                     Reset image size\n\t\t\t\t\t</button></span></div></div><figcaption><div class=\"article-text figure-caption\"><p><strong>Figure 10.</strong>\u00a0Identified COSMSOS lens candidates by <span class=\"small-caps\">LensFlow</span>. These candidates are cataloged in Table <a class=\"tabref\" href=\"#apjaaae6at2\">2</a>.</p></div><p class=\"mb-05 print-hide\">Download figure:</p><span class=\"btn-multi-block print-hide\"><a class=\"btn btn-primary fig-dwnld-std-img\" id=\"wd-jnl-art-btn-std-img-apjaaae6af10\" href=\"/0004-637X/856/1/68/downloadFigure/figure/apjaaae6af10\"><span class=\"icon-image\"></span> Standard image\n\t\t\t\t\t</a><a class=\"btn btn-primary fig-dwnld-hi-img\" id=\"wd-jnl-art-btn-hires-img-apjaaae6af10\" href=\"/0004-637X/856/1/68/downloadHRFigure/figure/apjaaae6af10\"><span class=\"icon-image\"></span> High-resolution image\n\t\t\t\t\t</a></span></figcaption></figure></figure><div tabindex=\"-1\" id=\"apjaaae6at2\" class=\"boxout boxout-bdr-grey keyboard-focus-only\"><p><b>Table 2.</b>\u00a0\nCatalog of Identified Lenses by <span class=\"small-caps\">LensFlow</span>\n</p><table cellpadding=\"0\" cellspacing=\"0\" border=\"0\" data-toolbar-link=\"apjaaae6at2\" data-toolbar-img=\"/0004-637X/856/1/68/suppdata/apjaaae6at2_lr.gif\" data-toolbar-type=\"table\" data-toolbar-title=\"Table 2\"><colgroup><col align=\"left\" char=\"\"></col><col align=\"left\" char=\"\"></col><col align=\"left\" char=\"\"></col><col align=\"left\" char=\"\"></col><col align=\"left\" char=\"\"></col><col align=\"left\" char=\"\"></col><col align=\"left\" char=\"\"></col></colgroup><thead>\n<tr valign=\"top\">\n<th scope=\"col\" colspan=\"1\" rowspan=\"1\" align=\"left\">Lens</th>\n<th scope=\"col\" colspan=\"1\" rowspan=\"1\" align=\"center\">R.A.</th>\n<th scope=\"col\" colspan=\"1\" rowspan=\"1\" align=\"center\">Decl.</th>\n<th scope=\"col\" colspan=\"1\" rowspan=\"1\" align=\"center\">Einstein Radius</th>\n<th scope=\"col\" colspan=\"1\" rowspan=\"1\" align=\"center\">Magnitude</th>\n<th scope=\"col\" colspan=\"1\" rowspan=\"1\" align=\"center\">Absolute Rank</th>\n<th scope=\"col\" colspan=\"1\" rowspan=\"1\" align=\"center\">Average Grade<sup>a</sup>\n</th>\n</tr>\n<tr valign=\"top\">\n<th scope=\"col\" colspan=\"1\" rowspan=\"1\" align=\"left\">\u00a0</th>\n<th scope=\"col\" colspan=\"1\" rowspan=\"1\" align=\"center\">(deg)</th>\n<th scope=\"col\" colspan=\"1\" rowspan=\"1\" align=\"center\">(deg)</th>\n<th scope=\"col\" colspan=\"1\" rowspan=\"1\" align=\"center\">(arcsec)</th>\n<th scope=\"col\" colspan=\"1\" rowspan=\"1\" align=\"center\">(AB)</th>\n<th scope=\"col\" colspan=\"1\" rowspan=\"1\" align=\"center\">In 236,000</th>\n<th scope=\"col\" colspan=\"1\" rowspan=\"1\" align=\"center\">A/B/C</th>\n</tr>\n</thead><tbody>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">1</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.545323</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+1.614164</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.82</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">22.16</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1211</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">2</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.440339</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+1.754854</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.36</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.90</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">204</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">A</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">3</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.180910</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+1.714817</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.90</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">22.22</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">383</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">4</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.066345</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+1.772114</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2.11</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">19.85</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">7</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">5</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.489741</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+1.736721</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.08</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.18</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1744</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">6</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.646190</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+1.840283</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.91</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.28</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1018</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">7</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.091078</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+1.935850</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2.53</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.13</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">136</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">8</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.632091</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+1.882368</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2.38</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.41</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">260</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">9</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.670701</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.091367</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.30</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.19</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">458</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">10</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.894802</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.109357</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.72</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.44</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">845</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">11</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.856184</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.112118</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2.33</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.61</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1321</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">12</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.549644</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.140845</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.91</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">22.61</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">584</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">13</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.259607</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.209858</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.88</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.16</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1275</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">14</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.117743</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.266765</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.86</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.34</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1597</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">15</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.730719</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.147258</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.82</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.62</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">16</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.644851</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.135518</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.74</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.55</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">189</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">17</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.656039</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.447838</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.51</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.81</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">308</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">A</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">18</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.411971</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.308876</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.86</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">19.93</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1069</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">19</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.095108</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.300498</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.43</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">18.57</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1593</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">20</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.085701</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.297656</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.91</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.86</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">300</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">21</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.085616</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.364097</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.79</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">18.72</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">506</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">22</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.106308</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.432955</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.82</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.34</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1674</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">23</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.961446</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.349389</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.16</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.60</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">208</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">24</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.628310</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.354862</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.88</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.82</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1820</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">25</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.722715</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.428631</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.19</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.60</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">359</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">26</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.571395</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.506658</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.55</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.18</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">66</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">27</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.624611</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.540319</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.88</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">18.97</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">910</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">28</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.694125</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.547939</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.87</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.52</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">292</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">29</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.317117</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.531471</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2.71</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.62</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1451</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">30</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.141624</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.464563</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.65</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.82</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">86</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">31</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.063881</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.605824</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.47</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.50</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">979</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">32</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.878942</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.574346</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.97</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.78</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">573</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">A</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">33</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.542116</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.495012</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2.23</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">19.03</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1505</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">34</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.747020</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.666027</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.96</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.36</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">153</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">35</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.548642</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.766168</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.84</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">18.91</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1595</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">36</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.329391</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.671669</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2.44</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.72</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1027</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">37</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.284903</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.674951</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.53</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">19.08</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">321</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">A</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">38</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.250216</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.763947</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.60</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.72</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1515</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">39</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.101284</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.703268</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.74</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">22.58</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">932</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">40</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.217548</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.659542</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.11</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">23.18</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1567</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">41</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.855932</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.650953</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.87</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.97</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1345</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">42</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.621847</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.733148</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2.33</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.31</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1319</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">43</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.644507</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.808898</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.02</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.94</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1098</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">44</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.443480</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.847808</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.55</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.66</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1442</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">45</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.104053</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.844371</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2.24</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.66</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">222</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">46</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.611769</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.809775</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2.21</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">22.29</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">328</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">47<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.052500</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.337500</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.90</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">19.28</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2470</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">A</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">48<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.057917</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.380278</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.65</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">18.89</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">910</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">49<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.076667</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.645833</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.40</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">23.60</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">392</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">A</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">50<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.159167</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.692500</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.74</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.39</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">13610</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">A</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">51<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.198333</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+1.839722</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.70</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.65</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2916</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">A</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">52<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.205000</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+1.857778</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2.22</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">19.61</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">693</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">53<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.210833</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.816944</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.90</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.72</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">5333</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">A</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">54<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.236250</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.207222</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.20</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">18.70</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">4041</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">55<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.352083</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+1.855833</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.84</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">22.43</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">5125</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">56<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.570000</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.498611</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.96</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">19.98</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">3521</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">57<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.614583</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.080833</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.62</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.94</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1495</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">58<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.725000</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.241667</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.54</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">18.85</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">5783</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">59<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.494167</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.256944</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.35</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">22.27</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">3868</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">60<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.737500</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+1.996944</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2.15</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.05</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1164</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">61<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.811250</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.205278</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.86</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">23.25</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">4700</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">62<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.840417</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.110556</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.80</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.34</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">9218</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">A</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">63<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.949167</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.797778</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2.55</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">19.83</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">64<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.040417</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.415278</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2.63</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">19.49</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">8071</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">65<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.196250</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.491944</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2.00</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">19.56</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">13476</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">A</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">66<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.211667</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.065833</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.66</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">22.31</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1197</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">67<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.232083</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+1.639167</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.05</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.86</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">616</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">A</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">68<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.272083</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.758611</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.00</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.38</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">3204</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">69<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.334167</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+1.764167</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.28</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.31</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1300</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">70<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.450417</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.390278</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.43</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">18.81</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">216</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">71<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.535417</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.239444</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.59</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.06</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">8647</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">72<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.584167</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.393056</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.04</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.99</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">283</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">73<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.587917</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.577778</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.57</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">19.35</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">9564</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">74<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+150.650000</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.801944</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.27</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.15</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">3865</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">75<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.450000</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+1.923333</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2.21</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">22.15</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1236</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">A</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">76<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.461250</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+1.938611</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.73</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">19.19</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">9936</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">77<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.467083</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.349167</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.98</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.27</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">5965</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">78<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.475417</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+1.997778</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.33</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">22.23</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">204</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">79<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.523333</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.070278</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.61</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">23.00</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">3764</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">80<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.528333</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+1.969167</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.50</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">19.14</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2442</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">81<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.624583</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+1.626111</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2.97</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">19.95</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">12066</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">82<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.629167</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+1.725556</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.17</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.06</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2092</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">A</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">83<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.672500</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.779444</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.93</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">19.65</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">177</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">84<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.733750</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.798611</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2.97</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">19.54</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">5951</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">85<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.870833</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+1.764722</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.56</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">19.99</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">200</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">86<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.879583</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.041389</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.48</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">19.20</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">894</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">87<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.883333</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.171667</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.68</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.92</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">51</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">88<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.902917</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.605833</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2.40</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">19.14</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">7344</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">89<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.912917</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.512222</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">0.70</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">20.08</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">93</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">90<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.918333</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.548056</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.53</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">19.45</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">186</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">91<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.929583</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.471111</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.64</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">19.43</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">2684</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">C</td>\n</tr>\n<tr valign=\"top\">\n<td colspan=\"1\" rowspan=\"1\" align=\"left\">92<sup xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"fnref\"><a class=\"fnref\" href=\"#apjaaae6at1fnb\">b</a></sup>\n</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+149.998750</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">+2.063333</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">1.20</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">21.62</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"char\" char=\".\">44</td>\n<td colspan=\"1\" rowspan=\"1\" align=\"center\">B</td>\n</tr>\n</tbody></table><p><small>\n<p><strong>Notes.</strong> The first column corresponds to the image number in Figure <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" href=\"#apjaaae6af10\">10</a>.</p>\n<a name=\"apjaaae6at1fna\" id=\"apjaaae6at1fna\"></a><sup> a</sup>Grade A corresponds to images that are clearly a strong gravitational lens. Grade B lenses correspond to images that are most likely a lens, but there is a chance they could also be artifacts, noise, structures in elliptical galaxies, satellite galaxies, tidally interacting galaxies, etc. Grade C lenses consist of images that are most likely not a lens, but there is a chance they might be gravitationally lensed.\n<a name=\"apjaaae6at1fnb\" id=\"apjaaae6at1fnb\"></a><sup> b</sup>These marked lenses were previously cataloged by Faure et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib12\" id=\"fnref-apjaaae6abib12\">2008</a>).\n</small></p><p class=\"franklin fs-16\">\n\t\t\tDownload table as:\u00a0\n            <span class=\"btn-multi-block\"><a class=\"btn btn-primary wd-jnl-art-btn-ascii\" href=\"/0004-637X/856/1/68/suppdata/apjaaae6at2_ascii.txt?doi=10.3847/1538-4357/aaae6a\" target=\"_blank\">ASCII</a>Typeset images: <a class=\"btn btn-primary wd-jnl-art-btn-typeset-multiple typeset-table-img\" href=\"/0004-637X/856/1/68/suppdata/apjaaae6at2_lr.gif\" target=\"_blank\">1</a> <a class=\"btn btn-primary wd-jnl-art-btn-typeset-multiple typeset-table-img\" href=\"/0004-637X/856/1/68/suppdata/apjaaae6at2a_lr.gif\" target=\"_blank\">2</a> </span></p></div></div></div>\n<h2 class=\"header-anchor\" id=\"apjaaae6as4\" name=\"apjaaae6as4\">4.\u00a0Discussion</h2><div class=\"article-text\" data-mobile-collapse=\"\"><p>Non-ML computer algorithms have been previously used for finding gravitationally lensed arcs (Lenzen et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib29\" id=\"fnref-apjaaae6abib29\">2004</a>; Alard <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib3\" id=\"fnref-apjaaae6abib3\">2006</a>; More et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib32\" id=\"fnref-apjaaae6abib32\">2012</a>) and rings (Gavazzi et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib14\" id=\"fnref-apjaaae6abib14\">2014</a>). As discussed in More et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib32\" id=\"fnref-apjaaae6abib32\">2012</a>) and Gavazzi et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib14\" id=\"fnref-apjaaae6abib14\">2014</a>), <span class=\"small-caps\">ringfinder</span> is an algorithm that uses color information and <span class=\"small-caps\">ArcFinder</span> detects arc-like pixels. In more detail, <span class=\"small-caps\">ArcFinder</span> starts by polishing the images by convolving a smoothing kernel. For each pixel, an estimator of elongation is calculated by taking the ratio between the sum of the flux of a few pixels along the horizontal line and the maximum value of a few nearby pixels along the vertical line, which passes through the pixel in hand. This process is repeated for all pixels and those with smaller than an specified elongation threshold are set to zero to create a sharp arc map. An arc map that satisfies thresholds on the arc properties such as the size and surface brightness will be selected as an arc candidate for further visual inspection. Such techniques can be used as complementary methods to deep learning. Currently, both techniques may suffer from many false positive detections, which commonly include tidally interacting galaxies, artifacts, and ring and spiral galaxies. The hope is that with more developed training data sets, deep learning algorithms can resolve such false positive cases (see Figure <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" href=\"#apjaaae6af9\">9</a> and Section <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"secref\" href=\"#apjaaae6as3-5\">3.5</a>).</p><p>Other researchers (Jacobs et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib20\" id=\"fnref-apjaaae6abib20\">2017</a>; Lanusse et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib28\" id=\"fnref-apjaaae6abib28\">2018</a>; Petrillo et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib42\" id=\"fnref-apjaaae6abib42\">2017</a>) also find deep learning to be a suitable solution for finding gravitational lenses. Lanusse et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib28\" id=\"fnref-apjaaae6abib28\">2018</a>) use residual ConvNets with 46 layers. Residual ConvNets are modified ConvNets that do not suffer from layer saturation like ordinary ConvNets do. After adding more than 50 layers, the accuracy of ordinary ConvNets no longer improves and the training becomes more challenging. He et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib18\" id=\"fnref-apjaaae6abib18\">2016</a>) were able to overcome this issue by providing residual maps in between layers, which has been employed by Lanusse et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib28\" id=\"fnref-apjaaae6abib28\">2018</a>). They have simulated LSST mock observations in a single band and have trained and tested their network on these images. Jacobs et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib20\" id=\"fnref-apjaaae6abib20\">2017</a>) have trained their ConvNet using multiple color bands and have applied it to the Canada\u2013France\u2013Hawaii Telescope Legacy Survey. Petrillo et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib42\" id=\"fnref-apjaaae6abib42\">2017</a>) have searched for lenses in Kilo Degree Survey by training their ConvNet on cataloged luminous red galaxies.</p><p>In our independently developed work, we focus on the morphology of the lenses and only rely on one color band, similar to Petrillo et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib42\" id=\"fnref-apjaaae6abib42\">2017</a>) and Lanusse et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib28\" id=\"fnref-apjaaae6abib28\">2018</a>). Our lens simulation method is very similar to that of Petrillo et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib42\" id=\"fnref-apjaaae6abib42\">2017</a>), as we both merge simulated arcs with real images of galaxies to preserve the complexity of the physical data. In contrast to others, we do not discriminate against different sources found in the COSMOS field. That is, artifacts, stars, and other sources have been included in our training data set so <span class=\"small-caps\">LensFlow</span> can be directly applied to fields without a need for a catalog with galaxy type information. The deepness of our ConvNet is comparable to Petrillo et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib42\" id=\"fnref-apjaaae6abib42\">2017</a>) and Jacobs et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib20\" id=\"fnref-apjaaae6abib20\">2017</a>) but it is shallower than Lanusse et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib28\" id=\"fnref-apjaaae6abib28\">2018</a>). As mentioned in Jacobs et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib20\" id=\"fnref-apjaaae6abib20\">2017</a>), the morphology of lenses are much simpler than the morphology of daily objects and human faces, which extremely deep ConvNets are developed for. However, the cost to performance ratio of ConvNets with varying deepness has not been studied yet. The effectiveness of deeper ConvNets cannot be compared between ours (and Petrillo et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib42\" id=\"fnref-apjaaae6abib42\">2017</a> ) and Lanusse et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib28\" id=\"fnref-apjaaae6abib28\">2018</a>) since this work did not apply their algorithm to physical data. However, Lanusse et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib28\" id=\"fnref-apjaaae6abib28\">2018</a>) studied the change in the performance of their ConvNet by varying the Einstein radii and signal-to-noise ratio of their lenses.</p><p>A catalog of the strong gravitational lenses in the COSMOS field has previously been generated (Faure et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib12\" id=\"fnref-apjaaae6abib12\">2008</a>) by looking at early-type bright galaxies in the redshift range of <span xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"inline-eqn\"><span class=\"tex\"><span class=\"texImage\"><img src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6aieqn14.gif\" alt=\"$0.2\\leqslant z\\leqslant 1.0$\" align=\"top\"></img></span><script type=\"math/tex\">0.2\\leqslant z\\leqslant 1.0</script></span></span> in specific environments and by visually inspecting and cataloging 60 high- and low-quality lens candidates. In contrast, we have examined 236,000 sources in the <em>HST</em>/ACS i-band of the COSMOS field. In this paper, we reported our sample of gravitational lenses and presented an introduction to neural networks including ConvNets. Furthermore, we laid out the procedure for constructing simulated images for training and testing <span class=\"small-caps\">LensFlow</span>. The architecture of <span class=\"small-caps\">LensFlow</span> and its performance on test data constructed from real lenses were also presented. Finally, we used <span class=\"small-caps\">LensFlow</span> to identify new lens candidates using <em>HST</em> data. Scanning all of the <em>HST</em>/ACS images in the COSMOS field roughly took 140 seconds on one GPU with 3840 NVIDIA CUDA cores. This corresponds to scanning 1.7 thousand 100\u00a0<b>&#x00d7;</b>\u00a0100-pixel images per second (or equivalently <span xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"inline-eqn\"><span class=\"tex\"><span class=\"texImage\"><img src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6aieqn15.gif\" alt=\"$4.2\\ {\\mathrm{arcmin}}^{2}\\,{{\\rm{s}}}^{-1}$\" align=\"top\"></img></span><script type=\"math/tex\">4.2\\ {\\mathrm{arcmin}}^{2}\\,{{\\rm{s}}}^{-1}</script></span></span> for the <em>Hubble ACS</em> camera). This speed is suitable for all-sky surveys and the computation time can be reduced further by increasing the number of employed GPUs.</p></div> <div class=\"article-text\" data-mobile-collapse=\"\"><p>We wish to thank the referee for reading the original manuscript and providing useful feedback. Financial support for this paper was provided by NSF grant AST-1313319 and GAANN P200A150121. We are also thankful for the donated GPU by NVIDIA Grant Program. Figures <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" href=\"#apjaaae6af1\">1</a> and <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" href=\"#apjaaae6af6\">6</a> were generated using\u00a0<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"webref\" target=\"_blank\" href=\"http://www.draw.io\">http://www.draw.io</a>. The backbone of our algorithm was initially inspired by Hvass Laboratories on Github (Pedersen <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib40\" id=\"fnref-apjaaae6abib40\">2016</a>). Figure <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" href=\"#apjaaae6af2\">2</a> was plotted using his code as well. We would like to thank Dr. Emre Neftci, Dr. Charless Fowlkes, Dr. Pierre Baldi for their valuable feedback. We would also like to thank Noah Ghotbi and Aroosa Ansari for their assistance.</p></div><h2 class=\"header-anchor\" id=\"apjaaae6aapp1\" name=\"apjaaae6aapp1\">Appendix A: Remarks on the <span class=\"small-caps\">LensFlow</span> Code</h2><div class=\"article-text\" data-mobile-collapse=\"\"><p>We have developed <span class=\"small-caps\">LensFlow</span> (Pourrahmani et al. <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib44\" id=\"fnref-apjaaae6abib44\">2018</a>) in the Wolram Language (a.k.a <span class=\"small-caps\">Mathematica</span>), using its image processing and state-of-the-art ML functionalities and it can be accessed on Github (see footnote 2). The main notebook is called <span class=\"small-caps\">LensFlow</span>, which contains all the deep learning portions of the code. Other notebooks are used for lens simulation, image normalization, etc. If the user does not have access to <span class=\"small-caps\">Mathematica</span>, they can download CDF Player for free to view the code. We will also provide a PDF of the main notebook with documentation alongside the code. From a practical perspective, it is important to store the images as <span class=\"small-caps\">JPEG</span> files or other compressed formats since non-compressed image formants such as FITS occupy a significantly larger memory and storage volume and loading these images to memory will require much longer time. Training <span class=\"small-caps\">LensFlow</span> during each phase on a GPU with 3840 NVIDIA CUDA cores takes less than 5 minutes for the training data set discussed in this paper. <span class=\"small-caps\">Mathematica</span> uses <span class=\"small-caps\">MXNet</span>, so a trained network can be easily transferred to other languages. We initially developed our algorithm using <span class=\"small-caps\">TensorFlow</span>, later, with the adoption of <span class=\"small-caps\">Keras</span> in Python 3.5.2 in Jupyter notebooks. These codes will be provided as extras. Even though they are not polished or fully developed, the codes is briefly documented in the Jupyter notebooks and may contain useful functions for data curation, helping the user to go from tiles to cutouts around extracted sources or automatically generating random arcs using <span class=\"small-caps\">LensTool</span>.</p></div><h2 class=\"header-anchor\" id=\"apjaaae6aapp2\" name=\"apjaaae6aapp2\">Appendix B: Identified and Recovered Lenses</h2><div class=\"article-text\" data-mobile-collapse=\"\"><p><span class=\"small-caps\">LensFlow</span> was able to identify 92 lenses in the COSMOS field, 46 of which were new and the rest were previously reported in Faure et al. (<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"cite\" href=\"#apjaaae6abib12\" id=\"fnref-apjaaae6abib12\">2008</a>). The coordinates, Einstein radii, magnitudes of the brightest object, the <span class=\"small-caps\">LensFlow</span> rankings of the lens among 236,000 images, and their grades are reported in Table <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"tabref\" href=\"#apjaaae6at2\">2</a>. The corresponding images are shown in Figure <a xmlns:xlink=\"http://www.w3.org/1999/xlink\" href=\"#apjaaae6af10\">10</a>.</p></div></div><!-- End article full text -->\n<!-- Start Footnotes -->\n\t<h2 id=\"footnotes\">Footnotes</h2>\n\t\t<div data-mobile-collapse=\"\">\n\t\t\t<ul class=\"clear-list wd-content-footnotes\">\n\t\t\t\t<li class=\"indices-list\"><div class=\"indices-id\" name=\"apjaaae6afn2\" id=\"apjaaae6afn2\">2\u00a0</div><div class=\"indices-content\"><p class=\"mb-0\"><p>\n<a xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"webref\" target=\"_blank\" href=\"https://github.com/Miladiouss/LensFlow\">https://github.com/Miladiouss/LensFlow</a>\n</p></p></div></li><li class=\"indices-list\"><div class=\"indices-id\" name=\"apjaaae6afn3\" id=\"apjaaae6afn3\">3\u00a0</div><div class=\"indices-content\"><p class=\"mb-0\"><p>In this paper and in our code, we have adapted the <span xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"inline-eqn\"><span class=\"tex\"><span class=\"texImage\"><img src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6aieqn2.gif\" alt=\"$N\\times C\\times H\\times W$\" align=\"top\"></img></span><script type=\"math/tex\">N\\times C\\times H\\times W</script></span></span> where <em>N</em>, <em>C</em>, <em>H</em>, and <em>W</em> stand for number of input images in a batch, number of color or feature channels, height, and width respectively.</p></p></div></li></ul>\n\t\t</div>\n\t<!-- End Footnotes -->\t\n<!-- Start References List -->\n\n<div class=\"reveal-container reveal-closed reveal-plus-icon exp-w-hash references\">\n                <div class=\"replica-h3 bdt-1 article-references__title\">\n                <a href=\"#\" class=\"reveal-trigger article-references\" data-reveal-label-alt=\"Hide&nbsp;references\"\n                   data-reveal-text=\"Show&nbsp;references\" aria-expanded=\"false\" id=\"references\">Show&nbsp;references</a>\n            </div>\n                <div class=\"reveal-content\" id=\"references-wrapper\">\n                    <div class=\"rss-feed__spinner-wrapper\"><span class=\"offscreen-hidden\">Please wait&hellip; references are loading.</span><span\n                            class=\"spinner icon-spinner rss-feed__spinner\"></span></div>\n                </div>\n            </div>\n        <!-- End References List -->\n</div>\n</div>\n            <div class=\"da2 ta2\">\n                <!-- Start Content nav and Back to top link -->\n<aside class=\"content-nav show-w-js\">\n\t<ul class=\"content-nav-ul wd-content-nav\">\n\t</ul>\n\t<a data-footer-backtotop class=\"btn btn-bottom back-top pl-0\" href=\"#back-to-top-target\"><span class=\"icon-arrow-up2\"></span> Back to top</a>\n</aside>\n<!-- End Content nav and Back to top link --></div>\n        </div>\n    </main>\n    <div class=\"da3 ta1\">\n        <div class=\"side-and-below\">\n            <!-- Start Related articles -->\n<!-- Note: the contents this span tag are necessary for the JavaScript that retrieves the related content and figure sets-->\n<span id=\"doi\" class=\"hide\">10.3847/1538-4357/aaae6a</span>\n<aside class=\"boxout bdt-6 related wd-related-articles\">\n            <span class=\"replica-h3\">Related content</span>\n        <div class=\"related-content-lists\">\n\n        <h3 class=\"related-article-hd replica-h4\">Journal articles</h3>\n            <div class=\"related-article-list\">\n                <ul class=\"\">\n                    <li>\n                            <a href=\"/article/10.1088/0004-637X/807/2/138\">Chitah: Strong-gravitational-lens Hunter in Imaging Surveys</a>\n                        </li>\n                    <li>\n                            <a href=\"/article/10.3847/1538-4365/aa7333\">Classifying Radio Galaxies with the Convolutional Neural Network</a>\n                        </li>\n                    <li>\n                            <a href=\"/article/10.1088/1748-0221/13/08/P08015\">Three-dimensional convolutional neural networks for neutrinoless double-beta decay signal/background discrimination in high-pressure gaseous Time Projection Chamber</a>\n                        </li>\n                    <li>\n                            <a href=\"/article/10.3847/1538-4357/837/1/97\">The Frontier Fields: Survey Design and Initial Results</a>\n                        </li>\n                    <li>\n                            <a href=\"/article/10.3847/1538-4357/aabfed\">Deep Learning Identifies High-<I>z</I> Galaxies in a Central Blue Nugget Phase in a Characteristic Mass Range</a>\n                        </li>\n                    <li>\n                            <a href=\"/article/10.1088/0004-637X/785/2/144\"><span class=\"small-caps\">RINGFINDER</span>: Automated Detection of Galaxy-scale Gravitational Lenses in Ground-based Multi-filter Imaging Data</a>\n                        </li>\n                    </ul>\n            </div>\n        </div>\n</aside>\n<!-- End Related articles -->\n</div>\n    </div>\n</div></div>\n\n    <div data-scroll-header=\"\" class=\"data-header-anchor\" id=\"exp\"></div>\n<!-- Footer tile starts -->\n<footer role=\"contentinfo\" data-footer-content>\n    <div class=\"iops-footer cf\">\n        <div class=\"wrapper\">\n            <nav role=\"navigation\" aria-label=\"Footer\">\n       \t\t<a class=\"iops-footer-logo\" id=\"wd-iops-footer-logo\" itemprop=\"url\" href=\"/\">\n\t\t\t\t\t<meta content=\"IOPscience\" itemprop=\"name\">\n\t\t\t\t\t<svg height=\"13\" width=\"90\">\n\t\t\t\t\t  <image xlink:href=\"https://static.iopscience.com/2.44.0/img/iops-logo.svg\" src=\"https://static.iopscience.com/2.44.0/img/iops-logo.png\" border=\"0\" height=\"13\" width=\"90\"/>\n\t\t\t\t\t</svg>\n                    <span class=\"offscreen-hidden\">IOP Science home</span>\n\t\t\t</a>\n            <small>\n                <ul>\n                    <li><a href=\"/journals\">Journals</a></li>\n                    <li><a href=\"/books\">Books</a></li>\n                    <li><a href=\"/page/aboutiopscience\">About IOPscience</a></li>\n                    <li><a href=\"/contact\">Contact us</a></li>\n                    <li><a href=\"/info/page/developing-countries-access\">Developing countries access</a></li>\n                    <li><a href=\"/info/page/openaccess\">IOP Publishing open access policy</a></li>\n                </ul>\n            </small>\n        </nav>\n        </div> <!-- end wrapper -->\n    </div> <!-- end iopp-footer -->\n\n    <div class=\"iopp-footer cf\">\n        <div class=\"wrapper\">\n            <div class=\"media mar-0 \">\n                <nav role=\"navigation\" aria-label=\"Further information about IOP Publishing\">\n\t\t\t\t<a class=\"iopp-footer-logo\" id=\"wd-iopp-footer-logo\" itemprop=\"url\" href=\"http://ioppublishing.org\">\n\t\t\t\t\t<meta content=\"IOPscience\" itemprop=\"name\">\n\t\t\t\t\t<svg width=\"100\" height=\"15\">\n\t\t\t\t\t  <image xlink:href=\"https://static.iopscience.com/2.44.0/img/iopp-logo-white.svg\" src=\"https://static.iopscience.com/2.44.0/img/iopp-logo.png\" border=\"0\" width=\"100\" height=\"15\"/>\n\t\t\t\t\t</svg>\n                    <span class=\"offscreen-hidden\">IOP Publishing home</span>\n\t\t\t\t</a>\n                <div class=\"media-body mar-0\">\n                    <ul>\n                        <li class=\"small\"><a href=\"/page/copyright_notice\">&copy; Copyright 2020 IOP Publishing</a></li>\n                        <li class=\"small\"><a href=\"/page/terms\">Terms &amp; conditions</a></li>\n                        <li class=\"small\"><a href=\"/page/disclaimer\">Disclaimer</a></li>\n                        <li class=\"small\"><a href=\"http://ioppublishing.org/privacyPolicy\" target=\"_blank\">Privacy &amp; cookie policy <span class=\"icon-newtab white-text\"></span></a></li>\n                        <li class=\"small\"><small>This site uses cookies. By continuing to use this site you agree to our use of cookies.</small></li>\n                    </ul>\n                </div>\n            </nav>\n            </div>\n        </div> <!-- end wrapper -->\n    </div> <!-- end iopp-footer -->\n</footer>\n<!-- Footer tile ends -->\n<script>\n  var imgBase = \"https://static.iopscience.com/2.44.0/img\";\n  /*  Cutting the mustard - http://responsivenews.co.uk/post/18948466399/cutting-the-mustard */\n\n  /* This is the original if statement, from the link above. I have amended it to turn of JS on all IE browsers less than 10.\n\tThis is due to a function in the iop.jquery.toolbar.js line 35/36. Uses .remove which is not native js supported in IE9 or lower */\n  /* if('querySelector' in document \n\t&& 'localStorage' in window\n\t&& 'addEventListener' in window) { */\n\n  /* This is the updated selector, taken from: https://justmarkup.com/log/2015/02/26/cut-the-mustard-revisited/ */\n\tif('visibilityState' in document) {\n\n\t/*! loadJS: load a JS file asynchronously. [c]2014 @scottjehl, Filament Group, Inc. (Based on http://goo.gl/REQGQ by Paul Irish).. Licensed MIT */\n\tfunction loadJS( src, cb ){\n\t  \"use strict\";\n\t  var ref = window.document.getElementsByTagName( \"script\" )[ 0 ];\n\t  var script = window.document.createElement( \"script\" );\n\t  script.src = src;\n\t  script.async = true;\n\t  ref.parentNode.insertBefore( script, ref );\n\t  if (cb && typeof(cb) === \"function\") {\n\t\tscript.onload = cb;\n\t  }\n\t  return script;\n\t}\n\n\tloadJS( \"https://static.iopscience.com/2.44.0/js/scripts.min.js\" );\n\n  }\n</script>\n\n<script type=\"text/javascript\">window.NREUM||(NREUM={});NREUM.info={\"errorBeacon\":\"bam-cell.nr-data.net\",\"licenseKey\":\"b2bfaae1b6\",\"agent\":\"\",\"beacon\":\"bam-cell.nr-data.net\",\"applicationTime\":737,\"applicationID\":\"723879338\",\"transactionName\":\"NAAHMUBVCENSABFZXg1KLzZiGzF1cU4sfndMDxYVQRsFX14OCl4eDwQcCkdASFpAEw==\",\"queueTime\":0}</script></body>\n</html>", "Action": "Scanned all subtables", "Table captions or footers": {"Overview": ">In this paper and in our code, we have adapted the <span xmlns:xlink=\"http://www.w3.org/1999/xlink\" class=\"inline-eqn\"><span class=\"tex\"><span class=\"texImage\"><img src=\"https://static.iopscience.com/2.44.0/img/lazy-loading-placeholder.gif\" data-src=\"https://cdn.iopscience.com/images/0004-637X/856/1/68/Full/apjaaae6aieqn2.gif\" alt=\"$N\\times C\\times H\\times W$\" align=\"top\"></img></span><script type=\"math/tex\">N\\times C\\times H\\times W</script></span></span> where <em>N</em>, <em>C</em>, <em>H</em>, and <em>W</em> stand for number of input images in a batch, number of color or feature channels, height, and width respectively."}, "Status": "Complete", "Link": "https://ui.adsabs.harvard.edu/link_gateway/2018ApJ...856...68P/PUB_HTML", "Pandas format": {"Table 3": {"Action": "Processed via pandas", "Status": "Complete", "Inspection": {"Notes": {"Table correctly loaded": "", "Lens Kind": "1", "Detection table": ""}, "Table map to MasterLens database": {"Dec [\u00b0]": "('Decl.', '(deg)')", "Einstein_R [\"]": "('Einstein Radius', '(arcsec)')@@", "Detection score or grade": "('Average Gradea', 'A/B/C')", "RA [\u00b0]": "('R.A.', '(deg)')"}}}, "Table 2": {"Action": "Processed via pandas", "Status": "Complete", "Inspection": {"Notes": {"Skip cause table not important": ""}}}}}}, "Paper Overview": {"authors": ["Pourrahmani, Milad", "Nayyeri, Hooshang", "Cooray, Asantha"], "journal_name": "The Astrophysical Journal", "type_of_reference": "JOUR", "abstract": "In this work, we present our machine learning classification algorithm for identifying strong gravitational lenses from wide-area surveys using convolutional neural networks; LENSFLOW. We train and test the algorithm using a wide variety of strong gravitational lens configurations from simulations of lensing events. Images are processed through multiple convolutional layers that extract feature maps necessary to assign a lens probability to each image. LENSFLOW provides a ranking scheme for all sources that could be used to identify potential gravitational lens candidates by significantly reducing the number of images that have to be visually inspected. We apply our algorithm to the HST/ACS i-band observations of the COSMOS field and present our sample of identified lensing candidates. The developed machine learning algorithm is more computationally efficient and complimentary to classical lens identification algorithms and is ideal for discovering such events across wide areas from current and future surveys such as LSST and WFIRST.", "doi": "10.3847/1538-4357/aaae6a", "start_page": "68", "number": "1", "publication_year": "2018/03/1", "custom1": "eprint: arXiv:1705.05857", "author_address": ["AA(Department of Physics and Astronomy, University of California Irvine, Irvine, CA, USA), AB(Department of Physics and Astronomy, University of California Irvine, Irvine, CA, USA), AC(Department of Physics and Astronomy, University of California Irvine, Irvine, CA, USA)"], "keywords": ["gravitational lensing: strong", "methods: data analysis", "techniques: image processing", "Astrophysics - Instrumentation and Methods for Astrophysics", "Astrophysics - Astrophysics of Galaxies"], "url": "https://ui.adsabs.harvard.edu/abs/2018ApJ...856...68P", "volume": "856", "Title": "LensFlow: A Convolutional Neural Network in Search of Strong Gravitational Lenses", "issn": "0004-637X"}}